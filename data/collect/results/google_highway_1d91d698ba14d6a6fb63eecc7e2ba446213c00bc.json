{
  "metadata": {
    "collection_date": "2026-01-11T17:45:51.228547",
    "repository": "https://github.com/google/highway",
    "repository_name": "google/highway"
  },
  "commit_info": {
    "old_sha": "730bd63cbcbf60ab5020e2c76b60a8a606c9f3bd",
    "new_sha": "1d91d698ba14d6a6fb63eecc7e2ba446213c00bc",
    "commit_message": [
      "Updated F32 to BF16 demote ops and BF16FromF32"
    ],
    "commit_date": "2024-01-27T22:52:32+00:00",
    "patch": [
      "--- hwy/base.h\n@@ -1633,12 +1633,42 @@ HWY_API HWY_BF16_CONSTEXPR float F32FromBF16(bfloat16_t bf) {\n #endif\n }\n \n+namespace detail {\n+\n+// Returns the increment to add to the bits of a finite F32 value to round a\n+// finite F32 to the nearest BF16 value\n+static HWY_INLINE HWY_MAYBE_UNUSED constexpr uint32_t F32BitsToBF16RoundIncr(\n+    const uint32_t f32_bits) {\n+  return static_cast<uint32_t>(((f32_bits & 0x7FFFFFFFu) < 0x7F800000u)\n+                                   ? (0x7FFFu + ((f32_bits >> 16) & 1u))\n+                                   : 0u);\n+}\n+\n+// Converts f32_bits (which is the bits of a F32 value) to BF16 bits,\n+// rounded to the nearest F16 value\n+static HWY_INLINE HWY_MAYBE_UNUSED constexpr uint16_t F32BitsToBF16Bits(\n+    const uint32_t f32_bits) {\n+  // Round f32_bits to the nearest BF16 by first adding\n+  // F32BitsToBF16RoundIncr(f32_bits) to f32_bits and then right shifting\n+  // f32_bits + F32BitsToBF16RoundIncr(f32_bits) by 16\n+\n+  // If f32_bits is the bit representation of a NaN F32 value, make sure that\n+  // bit 6 of the BF16 result is set to convert SNaN F32 values to QNaN BF16\n+  // values and to prevent NaN F32 values from being converted to an infinite\n+  // BF16 value\n+  return static_cast<uint16_t>(\n+      ((f32_bits + F32BitsToBF16RoundIncr(f32_bits)) >> 16) |\n+      (static_cast<uint32_t>((f32_bits & 0x7FFFFFFFu) > 0x7F800000u) << 6));\n+}\n+\n+}  // namespace detail\n+\n HWY_API HWY_BITCASTSCALAR_CONSTEXPR bfloat16_t BF16FromF32(float f) {\n #if HWY_HAVE_SCALAR_BF16_OPERATORS\n   return static_cast<bfloat16_t>(f);\n #else\n   return bfloat16_t::FromBits(\n-      static_cast<uint16_t>(BitCastScalar<uint32_t>(f) >> 16));\n+      detail::F32BitsToBF16Bits(BitCastScalar<uint32_t>(f)));\n #endif\n }\n \n--- hwy/detect_targets.h\n@@ -62,7 +62,8 @@\n // Bits 0..3 reserved (4 targets)\n #define HWY_AVX3_SPR (1LL << 4)\n // Bit 5 reserved (likely AVX10.2 with 256-bit vectors)\n-// Currently HWY_AVX3_DL plus a special case for CompressStore (10x as fast).\n+// Currently HWY_AVX3_DL plus AVX512BF16 and a special case for CompressStore\n+// (10x as fast).\n // We may later also use VPCONFLICT.\n #define HWY_AVX3_ZEN4 (1LL << 6)  // see HWY_WANT_AVX3_ZEN4 below\n \n@@ -496,7 +497,8 @@\n #define HWY_BASELINE_AVX3_ZEN4 0\n #endif\n \n-#if HWY_BASELINE_AVX3_DL != 0 && defined(__AVX512FP16__)\n+#if HWY_BASELINE_AVX3_DL != 0 && defined(__AVX512BF16__) && \\\n+    defined(__AVX512FP16__)\n #define HWY_BASELINE_AVX3_SPR HWY_AVX3_SPR\n #else\n #define HWY_BASELINE_AVX3_SPR 0\n--- hwy/ops/arm_neon-inl.h\n@@ -4650,15 +4650,6 @@ HWY_API VFromD<D> DemoteTo(D /* tag */, VFromD<Rebind<float, D>> v) {\n \n #endif  // HWY_NEON_HAVE_F16C\n \n-template <class D, HWY_IF_BF16_D(D)>\n-HWY_API VFromD<D> DemoteTo(D dbf16, VFromD<Rebind<float, D>> v) {\n-  const Rebind<int32_t, decltype(dbf16)> di32;\n-  const Rebind<uint32_t, decltype(dbf16)> du32;  // for logical shift right\n-  const Rebind<uint16_t, decltype(dbf16)> du16;\n-  const auto bits_in_32 = BitCast(di32, ShiftRight<16>(BitCast(du32, v)));\n-  return BitCast(dbf16, DemoteTo(du16, bits_in_32));\n-}\n-\n #if HWY_HAVE_FLOAT64\n \n template <class D, HWY_IF_F32_D(D)>\n@@ -6862,13 +6853,6 @@ HWY_API VFromD<D> ReverseBlocks(D /* tag */, VFromD<D> v) {\n \n // ------------------------------ ReorderDemote2To (OddEven)\n \n-template <class D, HWY_IF_V_SIZE_LE_D(D, 16), HWY_IF_BF16_D(D),\n-          class V32 = VFromD<Repartition<float, D>>>\n-HWY_API VFromD<D> ReorderDemote2To(D dbf16, V32 a, V32 b) {\n-  const RebindToUnsigned<decltype(dbf16)> du16;\n-  return BitCast(dbf16, ConcatOdd(du16, BitCast(du16, b), BitCast(du16, a)));\n-}\n-\n template <class D, HWY_IF_I32_D(D)>\n HWY_API Vec128<int32_t> ReorderDemote2To(D d32, Vec128<int64_t> a,\n                                          Vec128<int64_t> b) {\n@@ -7083,11 +7067,6 @@ HWY_API VFromD<D> OrderedDemote2To(D d, V a, V b) {\n   return ReorderDemote2To(d, a, b);\n }\n \n-template <class D, HWY_IF_BF16_D(D), class V32 = VFromD<Repartition<float, D>>>\n-HWY_API VFromD<D> OrderedDemote2To(D dbf16, V32 a, V32 b) {\n-  return ReorderDemote2To(dbf16, a, b);\n-}\n-\n // ================================================== CRYPTO\n \n // (aarch64 or Arm7) and (__ARM_FEATURE_AES or HWY_HAVE_RUNTIME_DISPATCH).\n--- hwy/ops/arm_sve-inl.h\n@@ -99,7 +99,13 @@ namespace detail {  // for code folding\n #define HWY_SVE_FOREACH_BF16(X_MACRO, NAME, OP) \\\n   HWY_SVE_FOREACH_BF16_UNCONDITIONAL(X_MACRO, NAME, OP)\n // We have both f16 and bf16, so nothing is emulated.\n-#define HWY_SVE_IF_EMULATED_D(D) hwy::EnableIf<false>* = nullptr\n+\n+// NOTE: hwy::EnableIf<!hwy::IsSame<D, D>()>* = nullptr is used instead of\n+// hwy::EnableIf<false>* = nullptr to avoid compiler errors since\n+// !hwy::IsSame<D, D>() is always false and as !hwy::IsSame<D, D>() will cause\n+// SFINAE to occur instead of a hard error due to a dependency on the D template\n+// argument\n+#define HWY_SVE_IF_EMULATED_D(D) hwy::EnableIf<!hwy::IsSame<D, D>()>* = nullptr\n #define HWY_SVE_IF_NOT_EMULATED_D(D) hwy::EnableIf<true>* = nullptr\n #else\n #define HWY_SVE_FOREACH_BF16(X_MACRO, NAME, OP)\n@@ -422,29 +428,24 @@ HWY_SVE_FOREACH_UI32(HWY_SVE_CAST, _, reinterpret)\n HWY_SVE_FOREACH_UI64(HWY_SVE_CAST, _, reinterpret)\n HWY_SVE_FOREACH_F(HWY_SVE_CAST, _, reinterpret)\n \n-#undef HWY_SVE_CAST_NOP\n-#undef HWY_SVE_CAST\n-\n+#if HWY_SVE_HAVE_BF16_FEATURE || HWY_SVE_HAVE_BF16_VEC\n+HWY_SVE_FOREACH_BF16_UNCONDITIONAL(HWY_SVE_CAST, _, reinterpret)\n+#else   // !(HWY_SVE_HAVE_BF16_FEATURE || HWY_SVE_HAVE_BF16_VEC)\n template <class V, HWY_SVE_IF_EMULATED_D(DFromV<V>)>\n HWY_INLINE svuint8_t BitCastToByte(V v) {\n-#if HWY_SVE_HAVE_BF16_VEC\n-  return svreinterpret_u8_bf16(v);\n-#else\n   const RebindToUnsigned<DFromV<V>> du;\n   return BitCastToByte(BitCast(du, v));\n-#endif\n }\n \n template <class D, HWY_SVE_IF_EMULATED_D(D)>\n HWY_INLINE VFromD<D> BitCastFromByte(D d, svuint8_t v) {\n-#if HWY_SVE_HAVE_BF16_VEC\n-  (void)d;\n-  return svreinterpret_bf16_u8(v);\n-#else\n   const RebindToUnsigned<decltype(d)> du;\n   return BitCastFromByte(du, v);\n-#endif\n }\n+#endif  // HWY_SVE_HAVE_BF16_FEATURE || HWY_SVE_HAVE_BF16_VEC\n+\n+#undef HWY_SVE_CAST_NOP\n+#undef HWY_SVE_CAST\n \n }  // namespace detail\n \n@@ -463,6 +464,7 @@ HWY_API VFromD<D> BitCast(D d, FromV v) {\n   }\n \n HWY_SVE_FOREACH(HWY_SVE_UNDEFINED, Undefined, undef)\n+HWY_SVE_FOREACH_BF16(HWY_SVE_UNDEFINED, Undefined, undef)\n \n template <class D, HWY_SVE_IF_EMULATED_D(D)>\n VFromD<D> Undefined(D d) {\n@@ -602,17 +604,22 @@ HWY_API svfloat16_t Dup128VecFromValues(D /*d*/, TFromD<D> t0, TFromD<D> t1,\n   return svdupq_n_f16(t0, t1, t2, t3, t4, t5, t6, t7);\n }\n \n-template <class D, HWY_SVE_IF_EMULATED_D(D)>\n+template <class D, HWY_IF_BF16_D(D)>\n HWY_API VBF16 Dup128VecFromValues(D d, TFromD<D> t0, TFromD<D> t1, TFromD<D> t2,\n                                   TFromD<D> t3, TFromD<D> t4, TFromD<D> t5,\n                                   TFromD<D> t6, TFromD<D> t7) {\n+#if HWY_SVE_HAVE_BF16_FEATURE\n+  (void)d;\n+  return svdupq_n_bf16(t0, t1, t2, t3, t4, t5, t6, t7);\n+#else\n   const RebindToUnsigned<decltype(d)> du;\n   return BitCast(\n       d, Dup128VecFromValues(\n              du, BitCastScalar<uint16_t>(t0), BitCastScalar<uint16_t>(t1),\n              BitCastScalar<uint16_t>(t2), BitCastScalar<uint16_t>(t3),\n              BitCastScalar<uint16_t>(t4), BitCastScalar<uint16_t>(t5),\n              BitCastScalar<uint16_t>(t6), BitCastScalar<uint16_t>(t7)));\n+#endif\n }\n \n template <class D, HWY_IF_I32_D(D)>\n@@ -672,6 +679,10 @@ HWY_API V And(const V a, const V b) {\n \n // ------------------------------ Or\n \n+namespace detail {\n+HWY_SVE_FOREACH_UI(HWY_SVE_RETV_ARGPVN, OrN, orr_n)\n+}  // namespace detail\n+\n HWY_SVE_FOREACH_UI(HWY_SVE_RETV_ARGPVV, Or, orr)\n \n template <class V, HWY_IF_FLOAT_V(V)>\n@@ -1264,6 +1275,7 @@ HWY_API size_t FindKnownFirstTrue(D d, svbool_t m) {\n   }\n \n HWY_SVE_FOREACH(HWY_SVE_IF_THEN_ELSE, IfThenElse, sel)\n+HWY_SVE_FOREACH_BF16(HWY_SVE_IF_THEN_ELSE, IfThenElse, sel)\n #undef HWY_SVE_IF_THEN_ELSE\n \n template <class V, class D = DFromV<V>, HWY_SVE_IF_EMULATED_D(D)>\n@@ -2535,10 +2547,46 @@ HWY_API svfloat16_t DemoteTo(Simd<float16_t, N, kPow2> d, const svfloat32_t v) {\n                                 in_even);  // lower half\n }\n \n+#ifdef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#undef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#else\n+#define HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#endif\n+\n+#if !HWY_SVE_HAVE_BF16_FEATURE\n+namespace detail {\n+\n+// Round a F32 value to the nearest BF16 value, with the result returned as the\n+// rounded F32 value bitcasted to an U32\n+\n+// RoundF32ForDemoteToBF16 also converts NaN values to QNaN values to prevent\n+// NaN F32 values from being converted to an infinity\n+HWY_INLINE svuint32_t RoundF32ForDemoteToBF16(svfloat32_t v) {\n+  const DFromV<decltype(v)> df32;\n+  const RebindToUnsigned<decltype(df32)> du32;\n+\n+  const auto is_non_nan = Eq(v, v);\n+  const auto bits32 = BitCast(du32, v);\n+\n+  const auto round_incr =\n+      detail::AddN(detail::AndN(ShiftRight<16>(bits32), 1u), 0x7FFFu);\n+  return MaskedAddOr(detail::OrN(bits32, 0x00400000u), is_non_nan, bits32,\n+                     round_incr);\n+}\n+\n+}  // namespace detail\n+#endif  // !HWY_SVE_HAVE_BF16_FEATURE\n+\n template <size_t N, int kPow2>\n HWY_API VBF16 DemoteTo(Simd<bfloat16_t, N, kPow2> dbf16, svfloat32_t v) {\n-  const svuint16_t in_even = BitCast(ScalableTag<uint16_t>(), v);\n-  return BitCast(dbf16, detail::ConcatOddFull(in_even, in_even));  // lower half\n+#if HWY_SVE_HAVE_BF16_FEATURE\n+  const VBF16 in_even = svcvt_bf16_f32_x(detail::PTrue(dbf16), v);\n+  return detail::ConcatEvenFull(in_even, in_even);\n+#else\n+  const svuint16_t in_odd =\n+      BitCast(ScalableTag<uint16_t>(), detail::RoundF32ForDemoteToBF16(v));\n+  return BitCast(dbf16, detail::ConcatOddFull(in_odd, in_odd));  // lower half\n+#endif\n }\n \n template <size_t N, int kPow2>\n@@ -4168,10 +4216,17 @@ HWY_INLINE VFromD<D> PromoteOddTo(ToTypeTag to_type_tag,\n template <size_t N, int kPow2>\n HWY_API VBF16 ReorderDemote2To(Simd<bfloat16_t, N, kPow2> dbf16, svfloat32_t a,\n                                svfloat32_t b) {\n-  const RebindToUnsigned<decltype(dbf16)> du16;\n-  const Repartition<uint32_t, decltype(dbf16)> du32;\n-  const svuint32_t b_in_even = ShiftRight<16>(BitCast(du32, b));\n-  return BitCast(dbf16, OddEven(BitCast(du16, a), BitCast(du16, b_in_even)));\n+#if HWY_SVE_HAVE_BF16_FEATURE\n+  const VBF16 b_in_even = svcvt_bf16_f32_x(detail::PTrue(dbf16), b);\n+  return svcvtnt_bf16_f32_x(b_in_even, detail::PTrue(dbf16), a);\n+#else\n+  (void)dbf16;\n+  const auto a_in_odd =\n+      BitCast(ScalableTag<uint16_t>(), detail::RoundF32ForDemoteToBF16(a));\n+  const auto b_in_odd =\n+      BitCast(ScalableTag<uint16_t>(), detail::RoundF32ForDemoteToBF16(b));\n+  return BitCast(dbf16, detail::InterleaveOdd(b_in_odd, a_in_odd));\n+#endif\n }\n \n template <size_t N, int kPow2>\n@@ -4319,10 +4374,20 @@ HWY_API VFromD<D> OrderedDemote2To(D dn, V a, V b) {\n   return Combine(dn, demoted_b, demoted_a);\n }\n \n-template <class D, HWY_IF_SPECIAL_FLOAT_D(D)>\n-HWY_API VFromD<D> OrderedDemote2To(D dn, svfloat32_t a, svfloat32_t b) {\n-  const Half<decltype(dn)> dnh;\n-  return Combine(dn, DemoteTo(dnh, b), DemoteTo(dnh, a));\n+template <size_t N, int kPow2>\n+HWY_API VBF16 OrderedDemote2To(Simd<bfloat16_t, N, kPow2> dbf16, svfloat32_t a,\n+                               svfloat32_t b) {\n+#if HWY_SVE_HAVE_BF16_FEATURE\n+  (void)dbf16;\n+  const VBF16 a_in_even = svcvt_bf16_f32_x(detail::PTrue(dbf16), a);\n+  const VBF16 b_in_even = svcvt_bf16_f32_x(detail::PTrue(dbf16), b);\n+  return ConcatEven(dbf16, b_in_even, a_in_even);\n+#else\n+  const RebindToUnsigned<decltype(dbf16)> du16;\n+  const svuint16_t a_in_odd = BitCast(du16, detail::RoundF32ForDemoteToBF16(a));\n+  const svuint16_t b_in_odd = BitCast(du16, detail::RoundF32ForDemoteToBF16(b));\n+  return BitCast(dbf16, ConcatOdd(du16, b_in_odd, a_in_odd));  // lower half\n+#endif\n }\n \n // ------------------------------ I8/U8/I16/U16 Div\n--- hwy/ops/emu128-inl.h\n@@ -1806,6 +1806,12 @@ HWY_API VFromD<D> PromoteTo(D /* tag */, Vec128<bfloat16_t, N> v) {\n   return ret;\n }\n \n+#ifdef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#undef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#else\n+#define HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#endif\n+\n template <class D, HWY_IF_BF16_D(D), size_t N>\n HWY_API VFromD<D> DemoteTo(D /* tag */, Vec128<float, N> v) {\n   VFromD<D> ret;\n--- hwy/ops/generic_ops-inl.h\n@@ -2999,6 +2999,90 @@ HWY_API VFromD<D> DemoteTo(D df16, VFromD<Rebind<float, D>> v) {\n \n #endif  // HWY_NATIVE_F16C\n \n+// ------------------------------ F32 to BF16 DemoteTo\n+#if (defined(HWY_NATIVE_DEMOTE_F32_TO_BF16) == defined(HWY_TARGET_TOGGLE))\n+#ifdef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#undef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#else\n+#define HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#endif\n+\n+namespace detail {\n+\n+// Round a F32 value to the nearest BF16 value, with the result returned as the\n+// rounded F32 value bitcasted to an U32\n+\n+// RoundF32ForDemoteToBF16 also converts NaN values to QNaN values to prevent\n+// NaN F32 values from being converted to an infinity\n+template <class V, HWY_IF_F32(TFromV<V>)>\n+HWY_INLINE VFromD<RebindToUnsigned<DFromV<V>>> RoundF32ForDemoteToBF16(V v) {\n+  const DFromV<decltype(v)> d;\n+  const RebindToUnsigned<decltype(d)> du32;\n+\n+  const auto is_non_nan = Not(IsNaN(v));\n+  const auto bits32 = BitCast(du32, v);\n+\n+  const auto round_incr =\n+      Add(And(ShiftRight<16>(bits32), Set(du32, uint32_t{1})),\n+          Set(du32, uint32_t{0x7FFFu}));\n+  return MaskedAddOr(Or(bits32, Set(du32, uint32_t{0x00400000u})),\n+                     RebindMask(du32, is_non_nan), bits32, round_incr);\n+}\n+\n+}  // namespace detail\n+\n+template <class D, HWY_IF_BF16_D(D)>\n+HWY_API VFromD<D> DemoteTo(D dbf16, VFromD<Rebind<float, D>> v) {\n+  const RebindToUnsigned<decltype(dbf16)> du16;\n+  const Twice<decltype(du16)> dt_u16;\n+\n+  const auto rounded_bits = BitCast(dt_u16, detail::RoundF32ForDemoteToBF16(v));\n+#if HWY_IS_LITTLE_ENDIAN\n+  return BitCast(\n+      dbf16, LowerHalf(du16, ConcatOdd(dt_u16, rounded_bits, rounded_bits)));\n+#else\n+  return BitCast(\n+      dbf16, LowerHalf(du16, ConcatEven(dt_u16, rounded_bits, rounded_bits)));\n+#endif\n+}\n+\n+template <class D, HWY_IF_BF16_D(D)>\n+HWY_API VFromD<D> OrderedDemote2To(D dbf16, VFromD<Repartition<float, D>> a,\n+                                   VFromD<Repartition<float, D>> b) {\n+  const RebindToUnsigned<decltype(dbf16)> du16;\n+\n+  const auto rounded_a_bits32 =\n+      BitCast(du16, detail::RoundF32ForDemoteToBF16(a));\n+  const auto rounded_b_bits32 =\n+      BitCast(du16, detail::RoundF32ForDemoteToBF16(b));\n+#if HWY_IS_LITTLE_ENDIAN\n+  return BitCast(dbf16, ConcatOdd(du16, BitCast(du16, rounded_b_bits32),\n+                                  BitCast(du16, rounded_a_bits32)));\n+#else\n+  return BitCast(dbf16, ConcatEven(du16, BitCast(du16, rounded_b_bits32),\n+                                   BitCast(du16, rounded_a_bits32)));\n+#endif\n+}\n+\n+template <class D, HWY_IF_BF16_D(D)>\n+HWY_API VFromD<D> ReorderDemote2To(D dbf16, VFromD<Repartition<float, D>> a,\n+                                   VFromD<Repartition<float, D>> b) {\n+  const RebindToUnsigned<decltype(dbf16)> du16;\n+\n+#if HWY_IS_LITTLE_ENDIAN\n+  const auto a_in_odd = detail::RoundF32ForDemoteToBF16(a);\n+  const auto b_in_even = ShiftRight<16>(detail::RoundF32ForDemoteToBF16(b));\n+#else\n+  const auto a_in_odd = ShiftRight<16>(detail::RoundF32ForDemoteToBF16(a));\n+  const auto b_in_even = detail::RoundF32ForDemoteToBF16(b);\n+#endif\n+\n+  return BitCast(dbf16,\n+                 OddEven(BitCast(du16, a_in_odd), BitCast(du16, b_in_even)));\n+}\n+\n+#endif  // HWY_NATIVE_DEMOTE_F32_TO_BF16\n+\n // ------------------------------ SumsOf2\n \n #if HWY_TARGET != HWY_SCALAR\n--- hwy/ops/ppc_vsx-inl.h\n@@ -3903,29 +3903,43 @@ HWY_API VFromD<D> DemoteTo(D df16, VFromD<Rebind<float, D>> v) {\n \n #endif  // HWY_PPC_HAVE_9\n \n-template <class D, HWY_IF_V_SIZE_LE_D(D, 8), HWY_IF_BF16_D(D)>\n-HWY_API VFromD<D> DemoteTo(D dbf16, VFromD<Rebind<float, D>> v) {\n-  const Rebind<uint32_t, decltype(dbf16)> du32;  // for logical shift right\n-  const Rebind<uint16_t, decltype(dbf16)> du16;\n-  const auto bits_in_32 = ShiftRight<16>(BitCast(du32, v));\n-  return BitCast(dbf16, TruncateTo(du16, bits_in_32));\n-}\n+#if HWY_PPC_HAVE_10 && HWY_HAS_BUILTIN(__builtin_vsx_xvcvspbf16)\n \n-template <class D, HWY_IF_BF16_D(D), class V32 = VFromD<Repartition<float, D>>>\n-HWY_API VFromD<D> ReorderDemote2To(D dbf16, V32 a, V32 b) {\n-  const RebindToUnsigned<decltype(dbf16)> du16;\n-  const Repartition<uint32_t, decltype(dbf16)> du32;\n-#if HWY_IS_LITTLE_ENDIAN\n-  const auto a_in_odd = a;\n-  const auto b_in_even = ShiftRight<16>(BitCast(du32, b));\n+#ifdef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#undef HWY_NATIVE_DEMOTE_F32_TO_BF16\n #else\n-  const auto a_in_odd = ShiftRight<16>(BitCast(du32, a));\n-  const auto b_in_even = b;\n+#define HWY_NATIVE_DEMOTE_F32_TO_BF16\n #endif\n-  return BitCast(dbf16,\n-                 OddEven(BitCast(du16, a_in_odd), BitCast(du16, b_in_even)));\n+\n+namespace detail {\n+\n+// VsxXvcvspbf16 converts a F32 vector to a BF16 vector, bitcasted to an U32\n+// vector with the resulting BF16 bits in the lower 16 bits of each U32 lane\n+template <class D, HWY_IF_BF16_D(D)>\n+static HWY_INLINE VFromD<Rebind<uint32_t, D>> VsxXvcvspbf16(\n+    D dbf16, VFromD<Rebind<float, D>> v) {\n+  const Rebind<uint32_t, decltype(dbf16)> du32;\n+  const Repartition<uint8_t, decltype(du32)> du32_as_du8;\n+\n+  using VU32 = __vector unsigned int;\n+\n+  // Even though the __builtin_vsx_xvcvspbf16 builtin performs a F32 to BF16\n+  // conversion, the __builtin_vsx_xvcvspbf16 intrinsic expects a\n+  // __vector unsigned char argument (at least as of GCC 13 and Clang 17)\n+  return VFromD<Rebind<uint32_t, D>>{reinterpret_cast<VU32>(\n+      __builtin_vsx_xvcvspbf16(BitCast(du32_as_du8, v).raw))};\n+}\n+\n+}  // namespace detail\n+\n+template <class D, HWY_IF_BF16_D(D)>\n+HWY_API VFromD<D> DemoteTo(D dbf16, VFromD<Rebind<float, D>> v) {\n+  const RebindToUnsigned<decltype(dbf16)> du16;\n+  return BitCast(dbf16, TruncateTo(du16, detail::VsxXvcvspbf16(dbf16, v)));\n }\n \n+#endif  // HWY_PPC_HAVE_10 && HWY_HAS_BUILTIN(__builtin_vsx_xvcvspbf16)\n+\n // Specializations for partial vectors because vec_packs sets lanes above 2*N.\n template <class DN, typename V, HWY_IF_V_SIZE_LE_D(DN, 4), HWY_IF_SIGNED_D(DN),\n           HWY_IF_SIGNED_V(V),\n@@ -4017,6 +4031,18 @@ HWY_API VFromD<DN> ReorderDemote2To(DN /*dn*/, V a, V b) {\n   return VFromD<DN>{vec_packs(a.raw, b.raw)};\n }\n \n+#if HWY_PPC_HAVE_10 && HWY_HAS_BUILTIN(__builtin_vsx_xvcvspbf16)\n+template <class D, class V, HWY_IF_BF16_D(D), HWY_IF_F32(TFromV<V>),\n+          HWY_IF_LANES_D(D, HWY_MAX_LANES_V(V) * 2)>\n+HWY_API VFromD<D> ReorderDemote2To(D dbf16, V a, V b) {\n+  const RebindToUnsigned<decltype(dbf16)> du16;\n+  const Half<decltype(dbf16)> dh_bf16;\n+  return BitCast(dbf16,\n+                 OrderedTruncate2To(du16, detail::VsxXvcvspbf16(dh_bf16, a),\n+                                    detail::VsxXvcvspbf16(dh_bf16, b)));\n+}\n+#endif\n+\n template <class D, HWY_IF_NOT_FLOAT_NOR_SPECIAL(TFromD<D>), class V,\n           HWY_IF_NOT_FLOAT_NOR_SPECIAL_V(V),\n           HWY_IF_T_SIZE_V(V, sizeof(TFromD<D>) * 2),\n@@ -4025,15 +4051,13 @@ HWY_API VFromD<D> OrderedDemote2To(D d, V a, V b) {\n   return ReorderDemote2To(d, a, b);\n }\n \n-template <class D, HWY_IF_BF16_D(D), class V32 = VFromD<Repartition<float, D>>>\n-HWY_API VFromD<D> OrderedDemote2To(D dbf16, V32 a, V32 b) {\n-  const RebindToUnsigned<decltype(dbf16)> du16;\n-#if HWY_IS_LITTLE_ENDIAN\n-  return BitCast(dbf16, ConcatOdd(du16, BitCast(du16, b), BitCast(du16, a)));\n-#else\n-  return BitCast(dbf16, ConcatEven(du16, BitCast(du16, b), BitCast(du16, a)));\n-#endif\n+#if HWY_PPC_HAVE_10 && HWY_HAS_BUILTIN(__builtin_vsx_xvcvspbf16)\n+template <class D, HWY_IF_BF16_D(D), class V, HWY_IF_F32(TFromV<V>),\n+          HWY_IF_LANES_D(D, HWY_MAX_LANES_D(DFromV<V>) * 2)>\n+HWY_API VFromD<D> OrderedDemote2To(D d, V a, V b) {\n+  return ReorderDemote2To(d, a, b);\n }\n+#endif\n \n template <class D, HWY_IF_V_SIZE_D(D, 4), HWY_IF_F32_D(D)>\n HWY_API Vec32<float> DemoteTo(D /* tag */, Vec64<double> v) {\n--- hwy/ops/rvv-inl.h\n@@ -845,6 +845,11 @@ HWY_API V And(const V a, const V b) {\n \n // ------------------------------ Or\n \n+// Non-vector version (ideally immediate) for use with RoundF32ForDemoteToBF16\n+namespace detail {\n+HWY_RVV_FOREACH_UI(HWY_RVV_RETV_ARGVS, OrS, or_vx, _ALL)\n+}  // namespace detail\n+\n HWY_RVV_FOREACH_UI(HWY_RVV_RETV_ARGVV, Or, or, _ALL)\n \n template <class V, HWY_IF_FLOAT_V(V)>\n@@ -2735,12 +2740,39 @@ HWY_RVV_FOREACH_U32(HWY_RVV_DEMOTE_TO_SHR_16, DemoteToShr16, nclipu_wx_,\n }\n #undef HWY_RVV_DEMOTE_TO_SHR_16\n \n+namespace detail {\n+\n+// Round a F32 value to the nearest BF16 value, with the result returned as the\n+// rounded F32 value bitcasted to an U32\n+\n+// RoundF32ForDemoteToBF16 also converts NaN values to QNaN values to prevent\n+// NaN F32 values from being converted to an infinity\n+template <class V, HWY_IF_F32(TFromV<V>)>\n+HWY_INLINE VFromD<RebindToUnsigned<DFromV<V>>> RoundF32ForDemoteToBF16(V v) {\n+  const RebindToUnsigned<DFromV<V>> du32;\n+  const auto is_non_nan = Eq(v, v);\n+  const auto bits32 = BitCast(du32, v);\n+\n+  const auto round_incr =\n+      detail::AddS(detail::AndS(ShiftRight<16>(bits32), 1u), 0x7FFFu);\n+  return MaskedAddOr(detail::OrS(bits32, 0x00400000u), is_non_nan, bits32,\n+                     round_incr);\n+}\n+\n+}  // namespace detail\n+\n+#ifdef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#undef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#else\n+#define HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#endif\n+\n template <size_t N, int kPow2>\n HWY_API VFromD<Simd<bfloat16_t, N, kPow2>> DemoteTo(\n     Simd<bfloat16_t, N, kPow2> d, VFromD<Simd<float, N, kPow2 + 1>> v) {\n   const RebindToUnsigned<decltype(d)> du16;\n-  const Rebind<uint32_t, decltype(d)> du32;\n-  return BitCast(d, detail::DemoteToShr16(du16, BitCast(du32, v)));\n+  return BitCast(\n+      d, detail::DemoteToShr16(du16, detail::RoundF32ForDemoteToBF16(v)));\n }\n \n // ------------------------------ ConvertTo F\n@@ -5165,8 +5197,11 @@ HWY_API VFromD<Simd<bfloat16_t, N, kPow2>> ReorderDemote2To(\n     VFromD<RepartitionToWide<decltype(dbf16)>> b) {\n   const RebindToUnsigned<decltype(dbf16)> du16;\n   const RebindToUnsigned<DFromV<decltype(a)>> du32;\n-  const VFromD<decltype(du32)> b_in_even = ShiftRight<16>(BitCast(du32, b));\n-  return BitCast(dbf16, OddEven(BitCast(du16, a), BitCast(du16, b_in_even)));\n+  const VFromD<decltype(du32)> b_in_even =\n+      ShiftRight<16>(detail::RoundF32ForDemoteToBF16(b));\n+  return BitCast(dbf16,\n+                 OddEven(BitCast(du16, detail::RoundF32ForDemoteToBF16(a)),\n+                         BitCast(du16, b_in_even)));\n }\n \n // If LMUL is not the max, Combine first to avoid another DemoteTo.\n--- hwy/ops/scalar-inl.h\n@@ -1442,6 +1442,12 @@ HWY_API Vec1<float16_t> DemoteTo(D /* tag */, const Vec1<float> v) {\n   return Vec1<float16_t>(F16FromF32(v.raw));\n }\n \n+#ifdef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#undef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#else\n+#define HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#endif\n+\n template <class D, HWY_IF_BF16_D(D)>\n HWY_API Vec1<bfloat16_t> DemoteTo(D d, const Vec1<float> v) {\n   return Set(d, BF16FromF32(v.raw));\n--- hwy/ops/set_macros-inl.h\n@@ -116,7 +116,15 @@\n   \",vpclmulqdq,avx512vbmi,avx512vbmi2,vaes,avx512vnni,avx512bitalg,\" \\\n   \"avx512vpopcntdq,gfni\"\n \n-#define HWY_TARGET_STR_AVX3_SPR HWY_TARGET_STR_AVX3_DL \",avx512fp16\"\n+#if !HWY_COMPILER_CLANGCL &&                                          \\\n+    (HWY_COMPILER_GCC_ACTUAL >= 1000 || HWY_COMPILER_CLANG >= 900) && \\\n+    !defined(HWY_AVX3_DISABLE_AVX512BF16)\n+#define HWY_TARGET_STR_AVX3_ZEN4 HWY_TARGET_STR_AVX3_DL \",avx512bf16\"\n+#else\n+#define HWY_TARGET_STR_AVX3_ZEN4 HWY_TARGET_STR_AVX3_DL\n+#endif\n+\n+#define HWY_TARGET_STR_AVX3_SPR HWY_TARGET_STR_AVX3_ZEN4 \",avx512fp16\"\n \n #if defined(HWY_DISABLE_PPC8_CRYPTO)\n #define HWY_TARGET_STR_PPC8_CRYPTO \"\"\n@@ -271,8 +279,7 @@\n #elif HWY_TARGET == HWY_AVX3_ZEN4\n \n #define HWY_NAMESPACE N_AVX3_ZEN4\n-// Currently the same as HWY_AVX3_DL: both support Icelake.\n-#define HWY_TARGET_STR HWY_TARGET_STR_AVX3_DL\n+#define HWY_TARGET_STR HWY_TARGET_STR_AVX3_ZEN4\n \n #elif HWY_TARGET == HWY_AVX3_SPR\n \n--- hwy/ops/wasm_128-inl.h\n@@ -4131,15 +4131,6 @@ HWY_API VFromD<D> DemoteTo(D du8, VFromD<Rebind<uint16_t, D>> v) {\n   return DemoteTo(du8, BitCast(di16, Min(v, Set(du16, 0x7FFF))));\n }\n \n-template <class D, HWY_IF_V_SIZE_LE_D(D, 8), HWY_IF_BF16_D(D)>\n-HWY_API VFromD<D> DemoteTo(D dbf16, VFromD<Rebind<float, D>> v) {\n-  const Rebind<int32_t, decltype(dbf16)> di32;\n-  const Rebind<uint32_t, decltype(dbf16)> du32;  // for logical shift right\n-  const Rebind<uint16_t, decltype(dbf16)> du16;\n-  const auto bits_in_32 = BitCast(di32, ShiftRight<16>(BitCast(du32, v)));\n-  return BitCast(dbf16, DemoteTo(du16, bits_in_32));\n-}\n-\n template <class D, HWY_IF_V_SIZE_LE_D(D, 8), HWY_IF_I32_D(D)>\n HWY_API VFromD<D> DemoteTo(D /* tag */, VFromD<Rebind<double, D>> v) {\n   return VFromD<D>{wasm_i32x4_trunc_sat_f64x2_zero(v.raw)};\n@@ -4210,15 +4201,6 @@ HWY_API VFromD<D> DemoteTo(D df32, VFromD<Rebind<uint64_t, D>> v) {\n   return DemoteTo(df32, adj_f64_val);\n }\n \n-template <class D, HWY_IF_V_SIZE_LE_D(D, 16), HWY_IF_BF16_D(D),\n-          class V32 = VFromD<Repartition<float, D>>>\n-HWY_API VFromD<D> ReorderDemote2To(D dbf16, V32 a, V32 b) {\n-  const RebindToUnsigned<decltype(dbf16)> du16;\n-  const Repartition<uint32_t, decltype(dbf16)> du32;\n-  const VFromD<decltype(du32)> b_in_even = ShiftRight<16>(BitCast(du32, b));\n-  return BitCast(dbf16, OddEven(BitCast(du16, a), BitCast(du16, b_in_even)));\n-}\n-\n // Specializations for partial vectors because i16x8_narrow_i32x4 sets lanes\n // above 2*N.\n template <class D, HWY_IF_I16_D(D)>\n@@ -4565,12 +4547,6 @@ HWY_API VFromD<D> OrderedDemote2To(D d, V a, V b) {\n   return ReorderDemote2To(d, a, b);\n }\n \n-template <class D, HWY_IF_BF16_D(D), class V32 = VFromD<Repartition<float, D>>>\n-HWY_API VFromD<D> OrderedDemote2To(D dbf16, V32 a, V32 b) {\n-  const RebindToUnsigned<decltype(dbf16)> du16;\n-  return BitCast(dbf16, ConcatOdd(du16, BitCast(du16, b), BitCast(du16, a)));\n-}\n-\n // ------------------------------ ConvertTo\n \n template <class D, HWY_IF_V_SIZE_LE_D(D, 16), HWY_IF_F32_D(D)>\n--- hwy/ops/wasm_256-inl.h\n@@ -1863,14 +1863,6 @@ HWY_API Vec128<float16_t> DemoteTo(D d16, Vec256<float> v) {\n   return Combine(d16, hi, lo);\n }\n \n-template <class D, HWY_IF_BF16_D(D)>\n-HWY_API Vec128<bfloat16_t> DemoteTo(D dbf16, Vec256<float> v) {\n-  const Half<decltype(dbf16)> dbf16h;\n-  const Vec64<bfloat16_t> lo = DemoteTo(dbf16h, v.v0);\n-  const Vec64<bfloat16_t> hi = DemoteTo(dbf16h, v.v1);\n-  return Combine(dbf16, hi, lo);\n-}\n-\n // For already range-limited input [0, 255].\n HWY_API Vec64<uint8_t> U8FromU32(Vec256<uint32_t> v) {\n   const Full64<uint8_t> du8;\n@@ -1923,13 +1915,6 @@ HWY_API Vec128<uint8_t> TruncateTo(D /* tag */, Vec256<uint16_t> v) {\n }\n \n // ------------------------------ ReorderDemote2To\n-template <class DBF16, HWY_IF_BF16_D(DBF16)>\n-HWY_API Vec256<bfloat16_t> ReorderDemote2To(DBF16 dbf16, Vec256<float> a,\n-                                            Vec256<float> b) {\n-  const RebindToUnsigned<decltype(dbf16)> du16;\n-  return BitCast(dbf16, ConcatOdd(du16, BitCast(du16, b), BitCast(du16, a)));\n-}\n-\n template <class DN, typename V, HWY_IF_V_SIZE_D(DN, 32),\n           HWY_IF_NOT_FLOAT_NOR_SPECIAL(TFromD<DN>), HWY_IF_SIGNED_V(V),\n           HWY_IF_T_SIZE_ONE_OF_D(DN, (1 << 1) | (1 << 2) | (1 << 4)),\n--- hwy/ops/x86_128-inl.h\n@@ -54,6 +54,15 @@ namespace detail {\n #define HWY_X86_IF_EMULATED_D(D) HWY_IF_BF16_D(D)\n #endif\n \n+#undef HWY_AVX3_HAVE_F32_TO_BF16C\n+#if HWY_TARGET <= HWY_AVX3_ZEN4 && !HWY_COMPILER_CLANGCL &&           \\\n+    (HWY_COMPILER_GCC_ACTUAL >= 1000 || HWY_COMPILER_CLANG >= 900) && \\\n+    !defined(HWY_AVX3_DISABLE_AVX512BF16)\n+#define HWY_AVX3_HAVE_F32_TO_BF16C 1\n+#else\n+#define HWY_AVX3_HAVE_F32_TO_BF16C 0\n+#endif\n+\n template <typename T>\n struct Raw128 {\n   using type = __m128i;\n@@ -242,6 +251,25 @@ HWY_INLINE __m128i BitCastToInteger(__m128h v) { return _mm_castph_si128(v); }\n HWY_INLINE __m128i BitCastToInteger(__m128 v) { return _mm_castps_si128(v); }\n HWY_INLINE __m128i BitCastToInteger(__m128d v) { return _mm_castpd_si128(v); }\n \n+#if HWY_AVX3_HAVE_F32_TO_BF16C\n+HWY_INLINE __m128i BitCastToInteger(__m128bh v) {\n+  // Need to use reinterpret_cast on GCC/Clang or BitCastScalar on MSVC to\n+  // bit cast a __m128bh to a __m128i as there is currently no intrinsic\n+  // available (as of GCC 13 and Clang 17) that can bit cast a __m128bh vector\n+  // to a __m128i vector\n+\n+#if HWY_COMPILER_GCC || HWY_COMPILER_CLANG\n+  // On GCC or Clang, use reinterpret_cast to bit cast a __m128bh to a __m128i\n+  return reinterpret_cast<__m128i>(v);\n+#else\n+  // On MSVC, use BitCastScalar to bit cast a __m128bh to a __m128i as MSVC does\n+  // not allow reinterpret_cast, static_cast, or a C-style cast to be used to\n+  // bit cast from one SSE/AVX vector type to a different SSE/AVX vector type\n+  return BitCastScalar<__m128i>(v);\n+#endif  // HWY_COMPILER_GCC || HWY_COMPILER_CLANG\n+}\n+#endif  // HWY_AVX3_HAVE_F32_TO_BF16C\n+\n template <typename T, size_t N>\n HWY_INLINE Vec128<uint8_t, N * sizeof(T)> BitCastToByte(Vec128<T, N> v) {\n   return Vec128<uint8_t, N * sizeof(T)>{BitCastToInteger(v.raw)};\n@@ -9250,26 +9278,53 @@ HWY_DIAGNOSTICS(pop)\n \n #endif  // F16C\n \n+// The _mm*_cvtneps_pbh and _mm*_cvtne2ps_pbh intrinsics require GCC 9 or later\n+// or Clang 10 or later\n+\n+// Also need GCC or Clang to bit cast the __m128bh, __m256bh, or __m512bh vector\n+// returned by the _mm*_cvtneps_pbh and _mm*_cvtne2ps_pbh intrinsics to a\n+// __m128i, __m256i, or __m512i as there are currently no intrinsics available\n+// (as of GCC 13 and Clang 17) to bit cast a __m128bh, __m256bh, or __m512bh\n+// vector to a __m128i, __m256i, or __m512i vector\n+\n+#if HWY_AVX3_HAVE_F32_TO_BF16C\n+#ifdef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#undef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#else\n+#define HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#endif\n+\n template <class D, HWY_IF_V_SIZE_LE_D(D, 8), HWY_IF_BF16_D(D)>\n-HWY_API VFromD<D> DemoteTo(D dbf16, VFromD<Rebind<float, D>> v) {\n-  // TODO(janwas): _mm_cvtneps_pbh once we have avx512bf16.\n-  const Rebind<int32_t, decltype(dbf16)> di32;\n-  const Rebind<uint32_t, decltype(dbf16)> du32;  // for logical shift right\n-  const Rebind<uint16_t, decltype(dbf16)> du16;\n-  const auto bits_in_32 = BitCast(di32, ShiftRight<16>(BitCast(du32, v)));\n-  return BitCast(dbf16, DemoteTo(du16, bits_in_32));\n+HWY_API VFromD<D> DemoteTo(D /*dbf16*/, VFromD<Rebind<float, D>> v) {\n+  // The _mm_cvtneps_pbh intrinsic returns a __m128bh vector that needs to be\n+  // bit casted to a __m128i vector\n+  return VFromD<D>{detail::BitCastToInteger(_mm_cvtneps_pbh(v.raw))};\n }\n \n-template <class D, HWY_IF_V_SIZE_LE_D(D, 16), HWY_IF_BF16_D(D),\n-          class V32 = VFromD<Repartition<float, D>>>\n-HWY_API VFromD<D> ReorderDemote2To(D dbf16, V32 a, V32 b) {\n-  // TODO(janwas): _mm_cvtne2ps_pbh once we have avx512bf16.\n-  const RebindToUnsigned<decltype(dbf16)> du16;\n-  const Repartition<uint32_t, decltype(dbf16)> du32;\n-  const VFromD<decltype(du32)> b_in_even = ShiftRight<16>(BitCast(du32, b));\n-  return BitCast(dbf16, OddEven(BitCast(du16, a), BitCast(du16, b_in_even)));\n+template <class D, HWY_IF_V_SIZE_D(D, 16), HWY_IF_BF16_D(D)>\n+HWY_API VFromD<D> ReorderDemote2To(D /*dbf16*/, Vec128<float> a,\n+                                   Vec128<float> b) {\n+  // The _mm_cvtne2ps_pbh intrinsic returns a __m128bh vector that needs to be\n+  // bit casted to a __m128i vector\n+  return VFromD<D>{detail::BitCastToInteger(_mm_cvtne2ps_pbh(b.raw, a.raw))};\n }\n \n+template <class D, HWY_IF_V_SIZE_D(D, 8), HWY_IF_BF16_D(D)>\n+HWY_API VFromD<D> ReorderDemote2To(D /* tag */, Vec64<float> a,\n+                                   Vec64<float> b) {\n+  return VFromD<D>{_mm_shuffle_epi32(\n+      detail::BitCastToInteger(_mm_cvtne2ps_pbh(b.raw, a.raw)),\n+      _MM_SHUFFLE(2, 0, 2, 0))};\n+}\n+\n+template <class D, HWY_IF_V_SIZE_D(D, 4), HWY_IF_BF16_D(D)>\n+HWY_API VFromD<D> ReorderDemote2To(D dbf16, Vec32<float> a, Vec32<float> b) {\n+  const DFromV<decltype(a)> d;\n+  const Twice<decltype(d)> dt;\n+  return DemoteTo(dbf16, Combine(dt, b, a));\n+}\n+#endif  // HWY_AVX3_HAVE_F32_TO_BF16C\n+\n // Specializations for partial vectors because packs_epi32 sets lanes above 2*N.\n template <class D, HWY_IF_V_SIZE_D(D, 4), HWY_IF_I16_D(D)>\n HWY_API VFromD<D> ReorderDemote2To(D dn, Vec32<int32_t> a, Vec32<int32_t> b) {\n@@ -9427,11 +9482,15 @@ HWY_API VFromD<D> OrderedDemote2To(D d, V a, V b) {\n   return ReorderDemote2To(d, a, b);\n }\n \n-template <class D, HWY_IF_BF16_D(D), class V32 = VFromD<Repartition<float, D>>>\n-HWY_API VFromD<D> OrderedDemote2To(D dbf16, V32 a, V32 b) {\n-  const RebindToUnsigned<decltype(dbf16)> du16;\n-  return BitCast(dbf16, ConcatOdd(du16, BitCast(du16, b), BitCast(du16, a)));\n+#if HWY_AVX3_HAVE_F32_TO_BF16C\n+// F32 to BF16 OrderedDemote2To is generic for all vector lengths on targets\n+// that support AVX512BF16\n+template <class D, HWY_IF_BF16_D(D)>\n+HWY_API VFromD<D> OrderedDemote2To(D dbf16, VFromD<Repartition<float, D>> a,\n+                                   VFromD<Repartition<float, D>> b) {\n+  return ReorderDemote2To(dbf16, a, b);\n }\n+#endif  // HWY_AVX3_HAVE_F32_TO_BF16C\n \n template <class D, HWY_IF_V_SIZE_LE_D(D, 8), HWY_IF_F32_D(D)>\n HWY_API VFromD<D> DemoteTo(D /* tag */, VFromD<Rebind<double, D>> v) {\n--- hwy/ops/x86_256-inl.h\n@@ -194,6 +194,25 @@ HWY_INLINE __m256i BitCastToInteger(__m256d v) {\n   return _mm256_castpd_si256(v);\n }\n \n+#if HWY_AVX3_HAVE_F32_TO_BF16C\n+HWY_INLINE __m256i BitCastToInteger(__m256bh v) {\n+  // Need to use reinterpret_cast on GCC/Clang or BitCastScalar on MSVC to\n+  // bit cast a __m256bh to a __m256i as there is currently no intrinsic\n+  // available (as of GCC 13 and Clang 17) that can bit cast a __m256bh vector\n+  // to a __m256i vector\n+\n+#if HWY_COMPILER_GCC || HWY_COMPILER_CLANG\n+  // On GCC or Clang, use reinterpret_cast to bit cast a __m256bh to a __m256i\n+  return reinterpret_cast<__m256i>(v);\n+#else\n+  // On MSVC, use BitCastScalar to bit cast a __m256bh to a __m256i as MSVC does\n+  // not allow reinterpret_cast, static_cast, or a C-style cast to be used to\n+  // bit cast from one AVX vector type to a different AVX vector type\n+  return BitCastScalar<__m256i>(v);\n+#endif  // HWY_COMPILER_GCC || HWY_COMPILER_CLANG\n+}\n+#endif  // HWY_AVX3_HAVE_F32_TO_BF16C\n+\n template <typename T>\n HWY_INLINE Vec256<uint8_t> BitCastToByte(Vec256<T> v) {\n   return Vec256<uint8_t>{BitCastToInteger(v.raw)};\n@@ -6300,24 +6319,22 @@ HWY_DIAGNOSTICS(pop)\n \n #endif  // HWY_DISABLE_F16C\n \n+#if HWY_AVX3_HAVE_F32_TO_BF16C\n template <class D, HWY_IF_V_SIZE_D(D, 16), HWY_IF_BF16_D(D)>\n-HWY_API VFromD<D> DemoteTo(D dbf16, Vec256<float> v) {\n-  // TODO(janwas): _mm256_cvtneps_pbh once we have avx512bf16.\n-  const Rebind<int32_t, decltype(dbf16)> di32;\n-  const Rebind<uint32_t, decltype(dbf16)> du32;  // for logical shift right\n-  const Rebind<uint16_t, decltype(dbf16)> du16;\n-  const auto bits_in_32 = BitCast(di32, ShiftRight<16>(BitCast(du32, v)));\n-  return BitCast(dbf16, DemoteTo(du16, bits_in_32));\n+HWY_API VFromD<D> DemoteTo(D /*dbf16*/, Vec256<float> v) {\n+  // The _mm256_cvtneps_pbh intrinsic returns a __m128bh vector that needs to be\n+  // bit casted to a __m128i vector\n+  return VFromD<D>{detail::BitCastToInteger(_mm256_cvtneps_pbh(v.raw))};\n }\n \n template <class D, HWY_IF_V_SIZE_D(D, 32), HWY_IF_BF16_D(D)>\n-HWY_API VFromD<D> ReorderDemote2To(D dbf16, Vec256<float> a, Vec256<float> b) {\n-  // TODO(janwas): _mm256_cvtne2ps_pbh once we have avx512bf16.\n-  const RebindToUnsigned<decltype(dbf16)> du16;\n-  const Repartition<uint32_t, decltype(dbf16)> du32;\n-  const Vec256<uint32_t> b_in_even = ShiftRight<16>(BitCast(du32, b));\n-  return BitCast(dbf16, OddEven(BitCast(du16, a), BitCast(du16, b_in_even)));\n+HWY_API VFromD<D> ReorderDemote2To(D /*dbf16*/, Vec256<float> a,\n+                                   Vec256<float> b) {\n+  // The _mm256_cvtne2ps_pbh intrinsic returns a __m256bh vector that needs to\n+  // be bit casted to a __m256i vector\n+  return VFromD<D>{detail::BitCastToInteger(_mm256_cvtne2ps_pbh(b.raw, a.raw))};\n }\n+#endif  // HWY_AVX3_HAVE_F32_TO_BF16C\n \n template <class D, HWY_IF_V_SIZE_D(D, 32), HWY_IF_I16_D(D)>\n HWY_API VFromD<D> ReorderDemote2To(D /*d16*/, Vec256<int32_t> a,\n--- hwy/ops/x86_512-inl.h\n@@ -193,6 +193,25 @@ HWY_INLINE __m512i BitCastToInteger(__m512d v) {\n   return _mm512_castpd_si512(v);\n }\n \n+#if HWY_AVX3_HAVE_F32_TO_BF16C\n+HWY_INLINE __m512i BitCastToInteger(__m512bh v) {\n+  // Need to use reinterpret_cast on GCC/Clang or BitCastScalar on MSVC to\n+  // bit cast a __m512bh to a __m512i as there is currently no intrinsic\n+  // available (as of GCC 13 and Clang 17) that can bit cast a __m512bh vector\n+  // to a __m512i vector\n+\n+#if HWY_COMPILER_GCC || HWY_COMPILER_CLANG\n+  // On GCC or Clang, use reinterpret_cast to bit cast a __m512bh to a __m512i\n+  return reinterpret_cast<__m512i>(v);\n+#else\n+  // On MSVC, use BitCastScalar to bit cast a __m512bh to a __m512i as MSVC does\n+  // not allow reinterpret_cast, static_cast, or a C-style cast to be used to\n+  // bit cast from one AVX vector type to a different AVX vector type\n+  return BitCastScalar<__m512i>(v);\n+#endif  // HWY_COMPILER_GCC || HWY_COMPILER_CLANG\n+}\n+#endif  // HWY_AVX3_HAVE_F32_TO_BF16C\n+\n template <typename T>\n HWY_INLINE Vec512<uint8_t> BitCastToByte(Vec512<T> v) {\n   return Vec512<uint8_t>{BitCastToInteger(v.raw)};\n@@ -5513,24 +5532,22 @@ HWY_API VFromD<D> DemoteTo(D df16, Vec512<float> v) {\n   HWY_DIAGNOSTICS(pop)\n }\n \n+#if HWY_AVX3_HAVE_F32_TO_BF16C\n template <class D, HWY_IF_V_SIZE_D(D, 32), HWY_IF_BF16_D(D)>\n-HWY_API VFromD<D> DemoteTo(D dbf16, Vec512<float> v) {\n-  // TODO(janwas): _mm512_cvtneps_pbh once we have avx512bf16.\n-  const Rebind<int32_t, decltype(dbf16)> di32;\n-  const Rebind<uint32_t, decltype(dbf16)> du32;  // for logical shift right\n-  const Rebind<uint16_t, decltype(dbf16)> du16;\n-  const auto bits_in_32 = BitCast(di32, ShiftRight<16>(BitCast(du32, v)));\n-  return BitCast(dbf16, DemoteTo(du16, bits_in_32));\n+HWY_API VFromD<D> DemoteTo(D /*dbf16*/, Vec512<float> v) {\n+  // The _mm512_cvtneps_pbh intrinsic returns a __m256bh vector that needs to be\n+  // bit casted to a __m256i vector\n+  return VFromD<D>{detail::BitCastToInteger(_mm512_cvtneps_pbh(v.raw))};\n }\n \n template <class D, HWY_IF_V_SIZE_D(D, 64), HWY_IF_BF16_D(D)>\n-HWY_API VFromD<D> ReorderDemote2To(D dbf16, Vec512<float> a, Vec512<float> b) {\n-  // TODO(janwas): _mm512_cvtne2ps_pbh once we have avx512bf16.\n-  const RebindToUnsigned<decltype(dbf16)> du16;\n-  const Repartition<uint32_t, decltype(dbf16)> du32;\n-  const Vec512<uint32_t> b_in_even = ShiftRight<16>(BitCast(du32, b));\n-  return BitCast(dbf16, OddEven(BitCast(du16, a), BitCast(du16, b_in_even)));\n+HWY_API VFromD<D> ReorderDemote2To(D /*dbf16*/, Vec512<float> a,\n+                                   Vec512<float> b) {\n+  // The _mm512_cvtne2ps_pbh intrinsic returns a __m512bh vector that needs to\n+  // be bit casted to a __m512i vector\n+  return VFromD<D>{detail::BitCastToInteger(_mm512_cvtne2ps_pbh(b.raw, a.raw))};\n }\n+#endif  // HWY_AVX3_HAVE_F32_TO_BF16C\n \n template <class D, HWY_IF_V_SIZE_D(D, 64), HWY_IF_I16_D(D)>\n HWY_API VFromD<D> ReorderDemote2To(D /* tag */, Vec512<int32_t> a,\n--- hwy/targets.cc\n@@ -136,6 +136,7 @@ enum class FeatureIndex : uint32_t {\n   kAVX512DQ,\n   kAVX512BW,\n   kAVX512FP16,\n+  kAVX512BF16,\n \n   kVNNI,\n   kVPCLMULQDQ,\n@@ -203,6 +204,9 @@ uint64_t FlagsFromCPUID() {\n     flags |= IsBitSet(abcd[2], 14) ? Bit(FeatureIndex::kPOPCNTDQ) : 0;\n \n     flags |= IsBitSet(abcd[3], 23) ? Bit(FeatureIndex::kAVX512FP16) : 0;\n+\n+    Cpuid(7, 1, abcd);\n+    flags |= IsBitSet(abcd[0], 5) ? Bit(FeatureIndex::kAVX512BF16) : 0;\n   }\n \n   return flags;\n@@ -252,8 +256,11 @@ constexpr uint64_t kGroupAVX3_DL =\n     Bit(FeatureIndex::kVAES) | Bit(FeatureIndex::kPOPCNTDQ) |\n     Bit(FeatureIndex::kBITALG) | Bit(FeatureIndex::kGFNI) | kGroupAVX3;\n \n+constexpr uint64_t kGroupAVX3_ZEN4 =\n+    Bit(FeatureIndex::kAVX512BF16) | kGroupAVX3_DL;\n+\n constexpr uint64_t kGroupAVX3_SPR =\n-    Bit(FeatureIndex::kAVX512FP16) | kGroupAVX3_DL;\n+    Bit(FeatureIndex::kAVX512FP16) | kGroupAVX3_ZEN4;\n \n int64_t DetectTargets() {\n   int64_t bits = 0;  // return value of supported targets.\n@@ -322,7 +329,8 @@ int64_t DetectTargets() {\n \n   // This is mainly to work around the slow Zen4 CompressStore. It's unclear\n   // whether subsequent AMD models will be affected; assume yes.\n-  if ((bits & HWY_AVX3_DL) && IsAMD()) {\n+  if ((bits & HWY_AVX3_DL) && (flags & kGroupAVX3_ZEN4) == kGroupAVX3_ZEN4 &&\n+      IsAMD()) {\n     bits |= HWY_AVX3_ZEN4;\n   }\n "
    ],
    "files_changed": [
      {
        "filename": "hwy/base.h",
        "status": "modified",
        "additions": 31,
        "deletions": 1,
        "changes": 32,
        "patch": "@@ -1633,12 +1633,42 @@ HWY_API HWY_BF16_CONSTEXPR float F32FromBF16(bfloat16_t bf) {\n #endif\n }\n \n+namespace detail {\n+\n+// Returns the increment to add to the bits of a finite F32 value to round a\n+// finite F32 to the nearest BF16 value\n+static HWY_INLINE HWY_MAYBE_UNUSED constexpr uint32_t F32BitsToBF16RoundIncr(\n+    const uint32_t f32_bits) {\n+  return static_cast<uint32_t>(((f32_bits & 0x7FFFFFFFu) < 0x7F800000u)\n+                                   ? (0x7FFFu + ((f32_bits >> 16) & 1u))\n+                                   : 0u);\n+}\n+\n+// Converts f32_bits (which is the bits of a F32 value) to BF16 bits,\n+// rounded to the nearest F16 value\n+static HWY_INLINE HWY_MAYBE_UNUSED constexpr uint16_t F32BitsToBF16Bits(\n+    const uint32_t f32_bits) {\n+  // Round f32_bits to the nearest BF16 by first adding\n+  // F32BitsToBF16RoundIncr(f32_bits) to f32_bits and then right shifting\n+  // f32_bits + F32BitsToBF16RoundIncr(f32_bits) by 16\n+\n+  // If f32_bits is the bit representation of a NaN F32 value, make sure that\n+  // bit 6 of the BF16 result is set to convert SNaN F32 values to QNaN BF16\n+  // values and to prevent NaN F32 values from being converted to an infinite\n+  // BF16 value\n+  return static_cast<uint16_t>(\n+      ((f32_bits + F32BitsToBF16RoundIncr(f32_bits)) >> 16) |\n+      (static_cast<uint32_t>((f32_bits & 0x7FFFFFFFu) > 0x7F800000u) << 6));\n+}\n+\n+}  // namespace detail\n+\n HWY_API HWY_BITCASTSCALAR_CONSTEXPR bfloat16_t BF16FromF32(float f) {\n #if HWY_HAVE_SCALAR_BF16_OPERATORS\n   return static_cast<bfloat16_t>(f);\n #else\n   return bfloat16_t::FromBits(\n-      static_cast<uint16_t>(BitCastScalar<uint32_t>(f) >> 16));\n+      detail::F32BitsToBF16Bits(BitCastScalar<uint32_t>(f)));\n #endif\n }\n "
      },
      {
        "filename": "hwy/detect_targets.h",
        "status": "modified",
        "additions": 4,
        "deletions": 2,
        "changes": 6,
        "patch": "@@ -62,7 +62,8 @@\n // Bits 0..3 reserved (4 targets)\n #define HWY_AVX3_SPR (1LL << 4)\n // Bit 5 reserved (likely AVX10.2 with 256-bit vectors)\n-// Currently HWY_AVX3_DL plus a special case for CompressStore (10x as fast).\n+// Currently HWY_AVX3_DL plus AVX512BF16 and a special case for CompressStore\n+// (10x as fast).\n // We may later also use VPCONFLICT.\n #define HWY_AVX3_ZEN4 (1LL << 6)  // see HWY_WANT_AVX3_ZEN4 below\n \n@@ -496,7 +497,8 @@\n #define HWY_BASELINE_AVX3_ZEN4 0\n #endif\n \n-#if HWY_BASELINE_AVX3_DL != 0 && defined(__AVX512FP16__)\n+#if HWY_BASELINE_AVX3_DL != 0 && defined(__AVX512BF16__) && \\\n+    defined(__AVX512FP16__)\n #define HWY_BASELINE_AVX3_SPR HWY_AVX3_SPR\n #else\n #define HWY_BASELINE_AVX3_SPR 0"
      },
      {
        "filename": "hwy/ops/arm_neon-inl.h",
        "status": "modified",
        "additions": 0,
        "deletions": 21,
        "changes": 21,
        "patch": "@@ -4650,15 +4650,6 @@ HWY_API VFromD<D> DemoteTo(D /* tag */, VFromD<Rebind<float, D>> v) {\n \n #endif  // HWY_NEON_HAVE_F16C\n \n-template <class D, HWY_IF_BF16_D(D)>\n-HWY_API VFromD<D> DemoteTo(D dbf16, VFromD<Rebind<float, D>> v) {\n-  const Rebind<int32_t, decltype(dbf16)> di32;\n-  const Rebind<uint32_t, decltype(dbf16)> du32;  // for logical shift right\n-  const Rebind<uint16_t, decltype(dbf16)> du16;\n-  const auto bits_in_32 = BitCast(di32, ShiftRight<16>(BitCast(du32, v)));\n-  return BitCast(dbf16, DemoteTo(du16, bits_in_32));\n-}\n-\n #if HWY_HAVE_FLOAT64\n \n template <class D, HWY_IF_F32_D(D)>\n@@ -6862,13 +6853,6 @@ HWY_API VFromD<D> ReverseBlocks(D /* tag */, VFromD<D> v) {\n \n // ------------------------------ ReorderDemote2To (OddEven)\n \n-template <class D, HWY_IF_V_SIZE_LE_D(D, 16), HWY_IF_BF16_D(D),\n-          class V32 = VFromD<Repartition<float, D>>>\n-HWY_API VFromD<D> ReorderDemote2To(D dbf16, V32 a, V32 b) {\n-  const RebindToUnsigned<decltype(dbf16)> du16;\n-  return BitCast(dbf16, ConcatOdd(du16, BitCast(du16, b), BitCast(du16, a)));\n-}\n-\n template <class D, HWY_IF_I32_D(D)>\n HWY_API Vec128<int32_t> ReorderDemote2To(D d32, Vec128<int64_t> a,\n                                          Vec128<int64_t> b) {\n@@ -7083,11 +7067,6 @@ HWY_API VFromD<D> OrderedDemote2To(D d, V a, V b) {\n   return ReorderDemote2To(d, a, b);\n }\n \n-template <class D, HWY_IF_BF16_D(D), class V32 = VFromD<Repartition<float, D>>>\n-HWY_API VFromD<D> OrderedDemote2To(D dbf16, V32 a, V32 b) {\n-  return ReorderDemote2To(dbf16, a, b);\n-}\n-\n // ================================================== CRYPTO\n \n // (aarch64 or Arm7) and (__ARM_FEATURE_AES or HWY_HAVE_RUNTIME_DISPATCH)."
      },
      {
        "filename": "hwy/ops/arm_sve-inl.h",
        "status": "modified",
        "additions": 89,
        "deletions": 24,
        "changes": 113,
        "patch": "@@ -99,7 +99,13 @@ namespace detail {  // for code folding\n #define HWY_SVE_FOREACH_BF16(X_MACRO, NAME, OP) \\\n   HWY_SVE_FOREACH_BF16_UNCONDITIONAL(X_MACRO, NAME, OP)\n // We have both f16 and bf16, so nothing is emulated.\n-#define HWY_SVE_IF_EMULATED_D(D) hwy::EnableIf<false>* = nullptr\n+\n+// NOTE: hwy::EnableIf<!hwy::IsSame<D, D>()>* = nullptr is used instead of\n+// hwy::EnableIf<false>* = nullptr to avoid compiler errors since\n+// !hwy::IsSame<D, D>() is always false and as !hwy::IsSame<D, D>() will cause\n+// SFINAE to occur instead of a hard error due to a dependency on the D template\n+// argument\n+#define HWY_SVE_IF_EMULATED_D(D) hwy::EnableIf<!hwy::IsSame<D, D>()>* = nullptr\n #define HWY_SVE_IF_NOT_EMULATED_D(D) hwy::EnableIf<true>* = nullptr\n #else\n #define HWY_SVE_FOREACH_BF16(X_MACRO, NAME, OP)\n@@ -422,29 +428,24 @@ HWY_SVE_FOREACH_UI32(HWY_SVE_CAST, _, reinterpret)\n HWY_SVE_FOREACH_UI64(HWY_SVE_CAST, _, reinterpret)\n HWY_SVE_FOREACH_F(HWY_SVE_CAST, _, reinterpret)\n \n-#undef HWY_SVE_CAST_NOP\n-#undef HWY_SVE_CAST\n-\n+#if HWY_SVE_HAVE_BF16_FEATURE || HWY_SVE_HAVE_BF16_VEC\n+HWY_SVE_FOREACH_BF16_UNCONDITIONAL(HWY_SVE_CAST, _, reinterpret)\n+#else   // !(HWY_SVE_HAVE_BF16_FEATURE || HWY_SVE_HAVE_BF16_VEC)\n template <class V, HWY_SVE_IF_EMULATED_D(DFromV<V>)>\n HWY_INLINE svuint8_t BitCastToByte(V v) {\n-#if HWY_SVE_HAVE_BF16_VEC\n-  return svreinterpret_u8_bf16(v);\n-#else\n   const RebindToUnsigned<DFromV<V>> du;\n   return BitCastToByte(BitCast(du, v));\n-#endif\n }\n \n template <class D, HWY_SVE_IF_EMULATED_D(D)>\n HWY_INLINE VFromD<D> BitCastFromByte(D d, svuint8_t v) {\n-#if HWY_SVE_HAVE_BF16_VEC\n-  (void)d;\n-  return svreinterpret_bf16_u8(v);\n-#else\n   const RebindToUnsigned<decltype(d)> du;\n   return BitCastFromByte(du, v);\n-#endif\n }\n+#endif  // HWY_SVE_HAVE_BF16_FEATURE || HWY_SVE_HAVE_BF16_VEC\n+\n+#undef HWY_SVE_CAST_NOP\n+#undef HWY_SVE_CAST\n \n }  // namespace detail\n \n@@ -463,6 +464,7 @@ HWY_API VFromD<D> BitCast(D d, FromV v) {\n   }\n \n HWY_SVE_FOREACH(HWY_SVE_UNDEFINED, Undefined, undef)\n+HWY_SVE_FOREACH_BF16(HWY_SVE_UNDEFINED, Undefined, undef)\n \n template <class D, HWY_SVE_IF_EMULATED_D(D)>\n VFromD<D> Undefined(D d) {\n@@ -602,17 +604,22 @@ HWY_API svfloat16_t Dup128VecFromValues(D /*d*/, TFromD<D> t0, TFromD<D> t1,\n   return svdupq_n_f16(t0, t1, t2, t3, t4, t5, t6, t7);\n }\n \n-template <class D, HWY_SVE_IF_EMULATED_D(D)>\n+template <class D, HWY_IF_BF16_D(D)>\n HWY_API VBF16 Dup128VecFromValues(D d, TFromD<D> t0, TFromD<D> t1, TFromD<D> t2,\n                                   TFromD<D> t3, TFromD<D> t4, TFromD<D> t5,\n                                   TFromD<D> t6, TFromD<D> t7) {\n+#if HWY_SVE_HAVE_BF16_FEATURE\n+  (void)d;\n+  return svdupq_n_bf16(t0, t1, t2, t3, t4, t5, t6, t7);\n+#else\n   const RebindToUnsigned<decltype(d)> du;\n   return BitCast(\n       d, Dup128VecFromValues(\n              du, BitCastScalar<uint16_t>(t0), BitCastScalar<uint16_t>(t1),\n              BitCastScalar<uint16_t>(t2), BitCastScalar<uint16_t>(t3),\n              BitCastScalar<uint16_t>(t4), BitCastScalar<uint16_t>(t5),\n              BitCastScalar<uint16_t>(t6), BitCastScalar<uint16_t>(t7)));\n+#endif\n }\n \n template <class D, HWY_IF_I32_D(D)>\n@@ -672,6 +679,10 @@ HWY_API V And(const V a, const V b) {\n \n // ------------------------------ Or\n \n+namespace detail {\n+HWY_SVE_FOREACH_UI(HWY_SVE_RETV_ARGPVN, OrN, orr_n)\n+}  // namespace detail\n+\n HWY_SVE_FOREACH_UI(HWY_SVE_RETV_ARGPVV, Or, orr)\n \n template <class V, HWY_IF_FLOAT_V(V)>\n@@ -1264,6 +1275,7 @@ HWY_API size_t FindKnownFirstTrue(D d, svbool_t m) {\n   }\n \n HWY_SVE_FOREACH(HWY_SVE_IF_THEN_ELSE, IfThenElse, sel)\n+HWY_SVE_FOREACH_BF16(HWY_SVE_IF_THEN_ELSE, IfThenElse, sel)\n #undef HWY_SVE_IF_THEN_ELSE\n \n template <class V, class D = DFromV<V>, HWY_SVE_IF_EMULATED_D(D)>\n@@ -2535,10 +2547,46 @@ HWY_API svfloat16_t DemoteTo(Simd<float16_t, N, kPow2> d, const svfloat32_t v) {\n                                 in_even);  // lower half\n }\n \n+#ifdef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#undef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#else\n+#define HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#endif\n+\n+#if !HWY_SVE_HAVE_BF16_FEATURE\n+namespace detail {\n+\n+// Round a F32 value to the nearest BF16 value, with the result returned as the\n+// rounded F32 value bitcasted to an U32\n+\n+// RoundF32ForDemoteToBF16 also converts NaN values to QNaN values to prevent\n+// NaN F32 values from being converted to an infinity\n+HWY_INLINE svuint32_t RoundF32ForDemoteToBF16(svfloat32_t v) {\n+  const DFromV<decltype(v)> df32;\n+  const RebindToUnsigned<decltype(df32)> du32;\n+\n+  const auto is_non_nan = Eq(v, v);\n+  const auto bits32 = BitCast(du32, v);\n+\n+  const auto round_incr =\n+      detail::AddN(detail::AndN(ShiftRight<16>(bits32), 1u), 0x7FFFu);\n+  return MaskedAddOr(detail::OrN(bits32, 0x00400000u), is_non_nan, bits32,\n+                     round_incr);\n+}\n+\n+}  // namespace detail\n+#endif  // !HWY_SVE_HAVE_BF16_FEATURE\n+\n template <size_t N, int kPow2>\n HWY_API VBF16 DemoteTo(Simd<bfloat16_t, N, kPow2> dbf16, svfloat32_t v) {\n-  const svuint16_t in_even = BitCast(ScalableTag<uint16_t>(), v);\n-  return BitCast(dbf16, detail::ConcatOddFull(in_even, in_even));  // lower half\n+#if HWY_SVE_HAVE_BF16_FEATURE\n+  const VBF16 in_even = svcvt_bf16_f32_x(detail::PTrue(dbf16), v);\n+  return detail::ConcatEvenFull(in_even, in_even);\n+#else\n+  const svuint16_t in_odd =\n+      BitCast(ScalableTag<uint16_t>(), detail::RoundF32ForDemoteToBF16(v));\n+  return BitCast(dbf16, detail::ConcatOddFull(in_odd, in_odd));  // lower half\n+#endif\n }\n \n template <size_t N, int kPow2>\n@@ -4168,10 +4216,17 @@ HWY_INLINE VFromD<D> PromoteOddTo(ToTypeTag to_type_tag,\n template <size_t N, int kPow2>\n HWY_API VBF16 ReorderDemote2To(Simd<bfloat16_t, N, kPow2> dbf16, svfloat32_t a,\n                                svfloat32_t b) {\n-  const RebindToUnsigned<decltype(dbf16)> du16;\n-  const Repartition<uint32_t, decltype(dbf16)> du32;\n-  const svuint32_t b_in_even = ShiftRight<16>(BitCast(du32, b));\n-  return BitCast(dbf16, OddEven(BitCast(du16, a), BitCast(du16, b_in_even)));\n+#if HWY_SVE_HAVE_BF16_FEATURE\n+  const VBF16 b_in_even = svcvt_bf16_f32_x(detail::PTrue(dbf16), b);\n+  return svcvtnt_bf16_f32_x(b_in_even, detail::PTrue(dbf16), a);\n+#else\n+  (void)dbf16;\n+  const auto a_in_odd =\n+      BitCast(ScalableTag<uint16_t>(), detail::RoundF32ForDemoteToBF16(a));\n+  const auto b_in_odd =\n+      BitCast(ScalableTag<uint16_t>(), detail::RoundF32ForDemoteToBF16(b));\n+  return BitCast(dbf16, detail::InterleaveOdd(b_in_odd, a_in_odd));\n+#endif\n }\n \n template <size_t N, int kPow2>\n@@ -4319,10 +4374,20 @@ HWY_API VFromD<D> OrderedDemote2To(D dn, V a, V b) {\n   return Combine(dn, demoted_b, demoted_a);\n }\n \n-template <class D, HWY_IF_SPECIAL_FLOAT_D(D)>\n-HWY_API VFromD<D> OrderedDemote2To(D dn, svfloat32_t a, svfloat32_t b) {\n-  const Half<decltype(dn)> dnh;\n-  return Combine(dn, DemoteTo(dnh, b), DemoteTo(dnh, a));\n+template <size_t N, int kPow2>\n+HWY_API VBF16 OrderedDemote2To(Simd<bfloat16_t, N, kPow2> dbf16, svfloat32_t a,\n+                               svfloat32_t b) {\n+#if HWY_SVE_HAVE_BF16_FEATURE\n+  (void)dbf16;\n+  const VBF16 a_in_even = svcvt_bf16_f32_x(detail::PTrue(dbf16), a);\n+  const VBF16 b_in_even = svcvt_bf16_f32_x(detail::PTrue(dbf16), b);\n+  return ConcatEven(dbf16, b_in_even, a_in_even);\n+#else\n+  const RebindToUnsigned<decltype(dbf16)> du16;\n+  const svuint16_t a_in_odd = BitCast(du16, detail::RoundF32ForDemoteToBF16(a));\n+  const svuint16_t b_in_odd = BitCast(du16, detail::RoundF32ForDemoteToBF16(b));\n+  return BitCast(dbf16, ConcatOdd(du16, b_in_odd, a_in_odd));  // lower half\n+#endif\n }\n \n // ------------------------------ I8/U8/I16/U16 Div"
      },
      {
        "filename": "hwy/ops/emu128-inl.h",
        "status": "modified",
        "additions": 6,
        "deletions": 0,
        "changes": 6,
        "patch": "@@ -1806,6 +1806,12 @@ HWY_API VFromD<D> PromoteTo(D /* tag */, Vec128<bfloat16_t, N> v) {\n   return ret;\n }\n \n+#ifdef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#undef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#else\n+#define HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#endif\n+\n template <class D, HWY_IF_BF16_D(D), size_t N>\n HWY_API VFromD<D> DemoteTo(D /* tag */, Vec128<float, N> v) {\n   VFromD<D> ret;"
      },
      {
        "filename": "hwy/ops/generic_ops-inl.h",
        "status": "modified",
        "additions": 84,
        "deletions": 0,
        "changes": 84,
        "patch": "@@ -2999,6 +2999,90 @@ HWY_API VFromD<D> DemoteTo(D df16, VFromD<Rebind<float, D>> v) {\n \n #endif  // HWY_NATIVE_F16C\n \n+// ------------------------------ F32 to BF16 DemoteTo\n+#if (defined(HWY_NATIVE_DEMOTE_F32_TO_BF16) == defined(HWY_TARGET_TOGGLE))\n+#ifdef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#undef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#else\n+#define HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#endif\n+\n+namespace detail {\n+\n+// Round a F32 value to the nearest BF16 value, with the result returned as the\n+// rounded F32 value bitcasted to an U32\n+\n+// RoundF32ForDemoteToBF16 also converts NaN values to QNaN values to prevent\n+// NaN F32 values from being converted to an infinity\n+template <class V, HWY_IF_F32(TFromV<V>)>\n+HWY_INLINE VFromD<RebindToUnsigned<DFromV<V>>> RoundF32ForDemoteToBF16(V v) {\n+  const DFromV<decltype(v)> d;\n+  const RebindToUnsigned<decltype(d)> du32;\n+\n+  const auto is_non_nan = Not(IsNaN(v));\n+  const auto bits32 = BitCast(du32, v);\n+\n+  const auto round_incr =\n+      Add(And(ShiftRight<16>(bits32), Set(du32, uint32_t{1})),\n+          Set(du32, uint32_t{0x7FFFu}));\n+  return MaskedAddOr(Or(bits32, Set(du32, uint32_t{0x00400000u})),\n+                     RebindMask(du32, is_non_nan), bits32, round_incr);\n+}\n+\n+}  // namespace detail\n+\n+template <class D, HWY_IF_BF16_D(D)>\n+HWY_API VFromD<D> DemoteTo(D dbf16, VFromD<Rebind<float, D>> v) {\n+  const RebindToUnsigned<decltype(dbf16)> du16;\n+  const Twice<decltype(du16)> dt_u16;\n+\n+  const auto rounded_bits = BitCast(dt_u16, detail::RoundF32ForDemoteToBF16(v));\n+#if HWY_IS_LITTLE_ENDIAN\n+  return BitCast(\n+      dbf16, LowerHalf(du16, ConcatOdd(dt_u16, rounded_bits, rounded_bits)));\n+#else\n+  return BitCast(\n+      dbf16, LowerHalf(du16, ConcatEven(dt_u16, rounded_bits, rounded_bits)));\n+#endif\n+}\n+\n+template <class D, HWY_IF_BF16_D(D)>\n+HWY_API VFromD<D> OrderedDemote2To(D dbf16, VFromD<Repartition<float, D>> a,\n+                                   VFromD<Repartition<float, D>> b) {\n+  const RebindToUnsigned<decltype(dbf16)> du16;\n+\n+  const auto rounded_a_bits32 =\n+      BitCast(du16, detail::RoundF32ForDemoteToBF16(a));\n+  const auto rounded_b_bits32 =\n+      BitCast(du16, detail::RoundF32ForDemoteToBF16(b));\n+#if HWY_IS_LITTLE_ENDIAN\n+  return BitCast(dbf16, ConcatOdd(du16, BitCast(du16, rounded_b_bits32),\n+                                  BitCast(du16, rounded_a_bits32)));\n+#else\n+  return BitCast(dbf16, ConcatEven(du16, BitCast(du16, rounded_b_bits32),\n+                                   BitCast(du16, rounded_a_bits32)));\n+#endif\n+}\n+\n+template <class D, HWY_IF_BF16_D(D)>\n+HWY_API VFromD<D> ReorderDemote2To(D dbf16, VFromD<Repartition<float, D>> a,\n+                                   VFromD<Repartition<float, D>> b) {\n+  const RebindToUnsigned<decltype(dbf16)> du16;\n+\n+#if HWY_IS_LITTLE_ENDIAN\n+  const auto a_in_odd = detail::RoundF32ForDemoteToBF16(a);\n+  const auto b_in_even = ShiftRight<16>(detail::RoundF32ForDemoteToBF16(b));\n+#else\n+  const auto a_in_odd = ShiftRight<16>(detail::RoundF32ForDemoteToBF16(a));\n+  const auto b_in_even = detail::RoundF32ForDemoteToBF16(b);\n+#endif\n+\n+  return BitCast(dbf16,\n+                 OddEven(BitCast(du16, a_in_odd), BitCast(du16, b_in_even)));\n+}\n+\n+#endif  // HWY_NATIVE_DEMOTE_F32_TO_BF16\n+\n // ------------------------------ SumsOf2\n \n #if HWY_TARGET != HWY_SCALAR"
      },
      {
        "filename": "hwy/ops/ppc_vsx-inl.h",
        "status": "modified",
        "additions": 50,
        "deletions": 26,
        "changes": 76,
        "patch": "@@ -3903,29 +3903,43 @@ HWY_API VFromD<D> DemoteTo(D df16, VFromD<Rebind<float, D>> v) {\n \n #endif  // HWY_PPC_HAVE_9\n \n-template <class D, HWY_IF_V_SIZE_LE_D(D, 8), HWY_IF_BF16_D(D)>\n-HWY_API VFromD<D> DemoteTo(D dbf16, VFromD<Rebind<float, D>> v) {\n-  const Rebind<uint32_t, decltype(dbf16)> du32;  // for logical shift right\n-  const Rebind<uint16_t, decltype(dbf16)> du16;\n-  const auto bits_in_32 = ShiftRight<16>(BitCast(du32, v));\n-  return BitCast(dbf16, TruncateTo(du16, bits_in_32));\n-}\n+#if HWY_PPC_HAVE_10 && HWY_HAS_BUILTIN(__builtin_vsx_xvcvspbf16)\n \n-template <class D, HWY_IF_BF16_D(D), class V32 = VFromD<Repartition<float, D>>>\n-HWY_API VFromD<D> ReorderDemote2To(D dbf16, V32 a, V32 b) {\n-  const RebindToUnsigned<decltype(dbf16)> du16;\n-  const Repartition<uint32_t, decltype(dbf16)> du32;\n-#if HWY_IS_LITTLE_ENDIAN\n-  const auto a_in_odd = a;\n-  const auto b_in_even = ShiftRight<16>(BitCast(du32, b));\n+#ifdef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#undef HWY_NATIVE_DEMOTE_F32_TO_BF16\n #else\n-  const auto a_in_odd = ShiftRight<16>(BitCast(du32, a));\n-  const auto b_in_even = b;\n+#define HWY_NATIVE_DEMOTE_F32_TO_BF16\n #endif\n-  return BitCast(dbf16,\n-                 OddEven(BitCast(du16, a_in_odd), BitCast(du16, b_in_even)));\n+\n+namespace detail {\n+\n+// VsxXvcvspbf16 converts a F32 vector to a BF16 vector, bitcasted to an U32\n+// vector with the resulting BF16 bits in the lower 16 bits of each U32 lane\n+template <class D, HWY_IF_BF16_D(D)>\n+static HWY_INLINE VFromD<Rebind<uint32_t, D>> VsxXvcvspbf16(\n+    D dbf16, VFromD<Rebind<float, D>> v) {\n+  const Rebind<uint32_t, decltype(dbf16)> du32;\n+  const Repartition<uint8_t, decltype(du32)> du32_as_du8;\n+\n+  using VU32 = __vector unsigned int;\n+\n+  // Even though the __builtin_vsx_xvcvspbf16 builtin performs a F32 to BF16\n+  // conversion, the __builtin_vsx_xvcvspbf16 intrinsic expects a\n+  // __vector unsigned char argument (at least as of GCC 13 and Clang 17)\n+  return VFromD<Rebind<uint32_t, D>>{reinterpret_cast<VU32>(\n+      __builtin_vsx_xvcvspbf16(BitCast(du32_as_du8, v).raw))};\n+}\n+\n+}  // namespace detail\n+\n+template <class D, HWY_IF_BF16_D(D)>\n+HWY_API VFromD<D> DemoteTo(D dbf16, VFromD<Rebind<float, D>> v) {\n+  const RebindToUnsigned<decltype(dbf16)> du16;\n+  return BitCast(dbf16, TruncateTo(du16, detail::VsxXvcvspbf16(dbf16, v)));\n }\n \n+#endif  // HWY_PPC_HAVE_10 && HWY_HAS_BUILTIN(__builtin_vsx_xvcvspbf16)\n+\n // Specializations for partial vectors because vec_packs sets lanes above 2*N.\n template <class DN, typename V, HWY_IF_V_SIZE_LE_D(DN, 4), HWY_IF_SIGNED_D(DN),\n           HWY_IF_SIGNED_V(V),\n@@ -4017,6 +4031,18 @@ HWY_API VFromD<DN> ReorderDemote2To(DN /*dn*/, V a, V b) {\n   return VFromD<DN>{vec_packs(a.raw, b.raw)};\n }\n \n+#if HWY_PPC_HAVE_10 && HWY_HAS_BUILTIN(__builtin_vsx_xvcvspbf16)\n+template <class D, class V, HWY_IF_BF16_D(D), HWY_IF_F32(TFromV<V>),\n+          HWY_IF_LANES_D(D, HWY_MAX_LANES_V(V) * 2)>\n+HWY_API VFromD<D> ReorderDemote2To(D dbf16, V a, V b) {\n+  const RebindToUnsigned<decltype(dbf16)> du16;\n+  const Half<decltype(dbf16)> dh_bf16;\n+  return BitCast(dbf16,\n+                 OrderedTruncate2To(du16, detail::VsxXvcvspbf16(dh_bf16, a),\n+                                    detail::VsxXvcvspbf16(dh_bf16, b)));\n+}\n+#endif\n+\n template <class D, HWY_IF_NOT_FLOAT_NOR_SPECIAL(TFromD<D>), class V,\n           HWY_IF_NOT_FLOAT_NOR_SPECIAL_V(V),\n           HWY_IF_T_SIZE_V(V, sizeof(TFromD<D>) * 2),\n@@ -4025,15 +4051,13 @@ HWY_API VFromD<D> OrderedDemote2To(D d, V a, V b) {\n   return ReorderDemote2To(d, a, b);\n }\n \n-template <class D, HWY_IF_BF16_D(D), class V32 = VFromD<Repartition<float, D>>>\n-HWY_API VFromD<D> OrderedDemote2To(D dbf16, V32 a, V32 b) {\n-  const RebindToUnsigned<decltype(dbf16)> du16;\n-#if HWY_IS_LITTLE_ENDIAN\n-  return BitCast(dbf16, ConcatOdd(du16, BitCast(du16, b), BitCast(du16, a)));\n-#else\n-  return BitCast(dbf16, ConcatEven(du16, BitCast(du16, b), BitCast(du16, a)));\n-#endif\n+#if HWY_PPC_HAVE_10 && HWY_HAS_BUILTIN(__builtin_vsx_xvcvspbf16)\n+template <class D, HWY_IF_BF16_D(D), class V, HWY_IF_F32(TFromV<V>),\n+          HWY_IF_LANES_D(D, HWY_MAX_LANES_D(DFromV<V>) * 2)>\n+HWY_API VFromD<D> OrderedDemote2To(D d, V a, V b) {\n+  return ReorderDemote2To(d, a, b);\n }\n+#endif\n \n template <class D, HWY_IF_V_SIZE_D(D, 4), HWY_IF_F32_D(D)>\n HWY_API Vec32<float> DemoteTo(D /* tag */, Vec64<double> v) {"
      },
      {
        "filename": "hwy/ops/rvv-inl.h",
        "status": "modified",
        "additions": 39,
        "deletions": 4,
        "changes": 43,
        "patch": "@@ -845,6 +845,11 @@ HWY_API V And(const V a, const V b) {\n \n // ------------------------------ Or\n \n+// Non-vector version (ideally immediate) for use with RoundF32ForDemoteToBF16\n+namespace detail {\n+HWY_RVV_FOREACH_UI(HWY_RVV_RETV_ARGVS, OrS, or_vx, _ALL)\n+}  // namespace detail\n+\n HWY_RVV_FOREACH_UI(HWY_RVV_RETV_ARGVV, Or, or, _ALL)\n \n template <class V, HWY_IF_FLOAT_V(V)>\n@@ -2735,12 +2740,39 @@ HWY_RVV_FOREACH_U32(HWY_RVV_DEMOTE_TO_SHR_16, DemoteToShr16, nclipu_wx_,\n }\n #undef HWY_RVV_DEMOTE_TO_SHR_16\n \n+namespace detail {\n+\n+// Round a F32 value to the nearest BF16 value, with the result returned as the\n+// rounded F32 value bitcasted to an U32\n+\n+// RoundF32ForDemoteToBF16 also converts NaN values to QNaN values to prevent\n+// NaN F32 values from being converted to an infinity\n+template <class V, HWY_IF_F32(TFromV<V>)>\n+HWY_INLINE VFromD<RebindToUnsigned<DFromV<V>>> RoundF32ForDemoteToBF16(V v) {\n+  const RebindToUnsigned<DFromV<V>> du32;\n+  const auto is_non_nan = Eq(v, v);\n+  const auto bits32 = BitCast(du32, v);\n+\n+  const auto round_incr =\n+      detail::AddS(detail::AndS(ShiftRight<16>(bits32), 1u), 0x7FFFu);\n+  return MaskedAddOr(detail::OrS(bits32, 0x00400000u), is_non_nan, bits32,\n+                     round_incr);\n+}\n+\n+}  // namespace detail\n+\n+#ifdef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#undef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#else\n+#define HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#endif\n+\n template <size_t N, int kPow2>\n HWY_API VFromD<Simd<bfloat16_t, N, kPow2>> DemoteTo(\n     Simd<bfloat16_t, N, kPow2> d, VFromD<Simd<float, N, kPow2 + 1>> v) {\n   const RebindToUnsigned<decltype(d)> du16;\n-  const Rebind<uint32_t, decltype(d)> du32;\n-  return BitCast(d, detail::DemoteToShr16(du16, BitCast(du32, v)));\n+  return BitCast(\n+      d, detail::DemoteToShr16(du16, detail::RoundF32ForDemoteToBF16(v)));\n }\n \n // ------------------------------ ConvertTo F\n@@ -5165,8 +5197,11 @@ HWY_API VFromD<Simd<bfloat16_t, N, kPow2>> ReorderDemote2To(\n     VFromD<RepartitionToWide<decltype(dbf16)>> b) {\n   const RebindToUnsigned<decltype(dbf16)> du16;\n   const RebindToUnsigned<DFromV<decltype(a)>> du32;\n-  const VFromD<decltype(du32)> b_in_even = ShiftRight<16>(BitCast(du32, b));\n-  return BitCast(dbf16, OddEven(BitCast(du16, a), BitCast(du16, b_in_even)));\n+  const VFromD<decltype(du32)> b_in_even =\n+      ShiftRight<16>(detail::RoundF32ForDemoteToBF16(b));\n+  return BitCast(dbf16,\n+                 OddEven(BitCast(du16, detail::RoundF32ForDemoteToBF16(a)),\n+                         BitCast(du16, b_in_even)));\n }\n \n // If LMUL is not the max, Combine first to avoid another DemoteTo."
      },
      {
        "filename": "hwy/ops/scalar-inl.h",
        "status": "modified",
        "additions": 6,
        "deletions": 0,
        "changes": 6,
        "patch": "@@ -1442,6 +1442,12 @@ HWY_API Vec1<float16_t> DemoteTo(D /* tag */, const Vec1<float> v) {\n   return Vec1<float16_t>(F16FromF32(v.raw));\n }\n \n+#ifdef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#undef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#else\n+#define HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#endif\n+\n template <class D, HWY_IF_BF16_D(D)>\n HWY_API Vec1<bfloat16_t> DemoteTo(D d, const Vec1<float> v) {\n   return Set(d, BF16FromF32(v.raw));"
      },
      {
        "filename": "hwy/ops/set_macros-inl.h",
        "status": "modified",
        "additions": 10,
        "deletions": 3,
        "changes": 13,
        "patch": "@@ -116,7 +116,15 @@\n   \",vpclmulqdq,avx512vbmi,avx512vbmi2,vaes,avx512vnni,avx512bitalg,\" \\\n   \"avx512vpopcntdq,gfni\"\n \n-#define HWY_TARGET_STR_AVX3_SPR HWY_TARGET_STR_AVX3_DL \",avx512fp16\"\n+#if !HWY_COMPILER_CLANGCL &&                                          \\\n+    (HWY_COMPILER_GCC_ACTUAL >= 1000 || HWY_COMPILER_CLANG >= 900) && \\\n+    !defined(HWY_AVX3_DISABLE_AVX512BF16)\n+#define HWY_TARGET_STR_AVX3_ZEN4 HWY_TARGET_STR_AVX3_DL \",avx512bf16\"\n+#else\n+#define HWY_TARGET_STR_AVX3_ZEN4 HWY_TARGET_STR_AVX3_DL\n+#endif\n+\n+#define HWY_TARGET_STR_AVX3_SPR HWY_TARGET_STR_AVX3_ZEN4 \",avx512fp16\"\n \n #if defined(HWY_DISABLE_PPC8_CRYPTO)\n #define HWY_TARGET_STR_PPC8_CRYPTO \"\"\n@@ -271,8 +279,7 @@\n #elif HWY_TARGET == HWY_AVX3_ZEN4\n \n #define HWY_NAMESPACE N_AVX3_ZEN4\n-// Currently the same as HWY_AVX3_DL: both support Icelake.\n-#define HWY_TARGET_STR HWY_TARGET_STR_AVX3_DL\n+#define HWY_TARGET_STR HWY_TARGET_STR_AVX3_ZEN4\n \n #elif HWY_TARGET == HWY_AVX3_SPR\n "
      },
      {
        "filename": "hwy/ops/wasm_128-inl.h",
        "status": "modified",
        "additions": 0,
        "deletions": 24,
        "changes": 24,
        "patch": "@@ -4131,15 +4131,6 @@ HWY_API VFromD<D> DemoteTo(D du8, VFromD<Rebind<uint16_t, D>> v) {\n   return DemoteTo(du8, BitCast(di16, Min(v, Set(du16, 0x7FFF))));\n }\n \n-template <class D, HWY_IF_V_SIZE_LE_D(D, 8), HWY_IF_BF16_D(D)>\n-HWY_API VFromD<D> DemoteTo(D dbf16, VFromD<Rebind<float, D>> v) {\n-  const Rebind<int32_t, decltype(dbf16)> di32;\n-  const Rebind<uint32_t, decltype(dbf16)> du32;  // for logical shift right\n-  const Rebind<uint16_t, decltype(dbf16)> du16;\n-  const auto bits_in_32 = BitCast(di32, ShiftRight<16>(BitCast(du32, v)));\n-  return BitCast(dbf16, DemoteTo(du16, bits_in_32));\n-}\n-\n template <class D, HWY_IF_V_SIZE_LE_D(D, 8), HWY_IF_I32_D(D)>\n HWY_API VFromD<D> DemoteTo(D /* tag */, VFromD<Rebind<double, D>> v) {\n   return VFromD<D>{wasm_i32x4_trunc_sat_f64x2_zero(v.raw)};\n@@ -4210,15 +4201,6 @@ HWY_API VFromD<D> DemoteTo(D df32, VFromD<Rebind<uint64_t, D>> v) {\n   return DemoteTo(df32, adj_f64_val);\n }\n \n-template <class D, HWY_IF_V_SIZE_LE_D(D, 16), HWY_IF_BF16_D(D),\n-          class V32 = VFromD<Repartition<float, D>>>\n-HWY_API VFromD<D> ReorderDemote2To(D dbf16, V32 a, V32 b) {\n-  const RebindToUnsigned<decltype(dbf16)> du16;\n-  const Repartition<uint32_t, decltype(dbf16)> du32;\n-  const VFromD<decltype(du32)> b_in_even = ShiftRight<16>(BitCast(du32, b));\n-  return BitCast(dbf16, OddEven(BitCast(du16, a), BitCast(du16, b_in_even)));\n-}\n-\n // Specializations for partial vectors because i16x8_narrow_i32x4 sets lanes\n // above 2*N.\n template <class D, HWY_IF_I16_D(D)>\n@@ -4565,12 +4547,6 @@ HWY_API VFromD<D> OrderedDemote2To(D d, V a, V b) {\n   return ReorderDemote2To(d, a, b);\n }\n \n-template <class D, HWY_IF_BF16_D(D), class V32 = VFromD<Repartition<float, D>>>\n-HWY_API VFromD<D> OrderedDemote2To(D dbf16, V32 a, V32 b) {\n-  const RebindToUnsigned<decltype(dbf16)> du16;\n-  return BitCast(dbf16, ConcatOdd(du16, BitCast(du16, b), BitCast(du16, a)));\n-}\n-\n // ------------------------------ ConvertTo\n \n template <class D, HWY_IF_V_SIZE_LE_D(D, 16), HWY_IF_F32_D(D)>"
      },
      {
        "filename": "hwy/ops/wasm_256-inl.h",
        "status": "modified",
        "additions": 0,
        "deletions": 15,
        "changes": 15,
        "patch": "@@ -1863,14 +1863,6 @@ HWY_API Vec128<float16_t> DemoteTo(D d16, Vec256<float> v) {\n   return Combine(d16, hi, lo);\n }\n \n-template <class D, HWY_IF_BF16_D(D)>\n-HWY_API Vec128<bfloat16_t> DemoteTo(D dbf16, Vec256<float> v) {\n-  const Half<decltype(dbf16)> dbf16h;\n-  const Vec64<bfloat16_t> lo = DemoteTo(dbf16h, v.v0);\n-  const Vec64<bfloat16_t> hi = DemoteTo(dbf16h, v.v1);\n-  return Combine(dbf16, hi, lo);\n-}\n-\n // For already range-limited input [0, 255].\n HWY_API Vec64<uint8_t> U8FromU32(Vec256<uint32_t> v) {\n   const Full64<uint8_t> du8;\n@@ -1923,13 +1915,6 @@ HWY_API Vec128<uint8_t> TruncateTo(D /* tag */, Vec256<uint16_t> v) {\n }\n \n // ------------------------------ ReorderDemote2To\n-template <class DBF16, HWY_IF_BF16_D(DBF16)>\n-HWY_API Vec256<bfloat16_t> ReorderDemote2To(DBF16 dbf16, Vec256<float> a,\n-                                            Vec256<float> b) {\n-  const RebindToUnsigned<decltype(dbf16)> du16;\n-  return BitCast(dbf16, ConcatOdd(du16, BitCast(du16, b), BitCast(du16, a)));\n-}\n-\n template <class DN, typename V, HWY_IF_V_SIZE_D(DN, 32),\n           HWY_IF_NOT_FLOAT_NOR_SPECIAL(TFromD<DN>), HWY_IF_SIGNED_V(V),\n           HWY_IF_T_SIZE_ONE_OF_D(DN, (1 << 1) | (1 << 2) | (1 << 4)),"
      },
      {
        "filename": "hwy/ops/x86_128-inl.h",
        "status": "modified",
        "additions": 78,
        "deletions": 19,
        "changes": 97,
        "patch": "@@ -54,6 +54,15 @@ namespace detail {\n #define HWY_X86_IF_EMULATED_D(D) HWY_IF_BF16_D(D)\n #endif\n \n+#undef HWY_AVX3_HAVE_F32_TO_BF16C\n+#if HWY_TARGET <= HWY_AVX3_ZEN4 && !HWY_COMPILER_CLANGCL &&           \\\n+    (HWY_COMPILER_GCC_ACTUAL >= 1000 || HWY_COMPILER_CLANG >= 900) && \\\n+    !defined(HWY_AVX3_DISABLE_AVX512BF16)\n+#define HWY_AVX3_HAVE_F32_TO_BF16C 1\n+#else\n+#define HWY_AVX3_HAVE_F32_TO_BF16C 0\n+#endif\n+\n template <typename T>\n struct Raw128 {\n   using type = __m128i;\n@@ -242,6 +251,25 @@ HWY_INLINE __m128i BitCastToInteger(__m128h v) { return _mm_castph_si128(v); }\n HWY_INLINE __m128i BitCastToInteger(__m128 v) { return _mm_castps_si128(v); }\n HWY_INLINE __m128i BitCastToInteger(__m128d v) { return _mm_castpd_si128(v); }\n \n+#if HWY_AVX3_HAVE_F32_TO_BF16C\n+HWY_INLINE __m128i BitCastToInteger(__m128bh v) {\n+  // Need to use reinterpret_cast on GCC/Clang or BitCastScalar on MSVC to\n+  // bit cast a __m128bh to a __m128i as there is currently no intrinsic\n+  // available (as of GCC 13 and Clang 17) that can bit cast a __m128bh vector\n+  // to a __m128i vector\n+\n+#if HWY_COMPILER_GCC || HWY_COMPILER_CLANG\n+  // On GCC or Clang, use reinterpret_cast to bit cast a __m128bh to a __m128i\n+  return reinterpret_cast<__m128i>(v);\n+#else\n+  // On MSVC, use BitCastScalar to bit cast a __m128bh to a __m128i as MSVC does\n+  // not allow reinterpret_cast, static_cast, or a C-style cast to be used to\n+  // bit cast from one SSE/AVX vector type to a different SSE/AVX vector type\n+  return BitCastScalar<__m128i>(v);\n+#endif  // HWY_COMPILER_GCC || HWY_COMPILER_CLANG\n+}\n+#endif  // HWY_AVX3_HAVE_F32_TO_BF16C\n+\n template <typename T, size_t N>\n HWY_INLINE Vec128<uint8_t, N * sizeof(T)> BitCastToByte(Vec128<T, N> v) {\n   return Vec128<uint8_t, N * sizeof(T)>{BitCastToInteger(v.raw)};\n@@ -9250,26 +9278,53 @@ HWY_DIAGNOSTICS(pop)\n \n #endif  // F16C\n \n+// The _mm*_cvtneps_pbh and _mm*_cvtne2ps_pbh intrinsics require GCC 9 or later\n+// or Clang 10 or later\n+\n+// Also need GCC or Clang to bit cast the __m128bh, __m256bh, or __m512bh vector\n+// returned by the _mm*_cvtneps_pbh and _mm*_cvtne2ps_pbh intrinsics to a\n+// __m128i, __m256i, or __m512i as there are currently no intrinsics available\n+// (as of GCC 13 and Clang 17) to bit cast a __m128bh, __m256bh, or __m512bh\n+// vector to a __m128i, __m256i, or __m512i vector\n+\n+#if HWY_AVX3_HAVE_F32_TO_BF16C\n+#ifdef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#undef HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#else\n+#define HWY_NATIVE_DEMOTE_F32_TO_BF16\n+#endif\n+\n template <class D, HWY_IF_V_SIZE_LE_D(D, 8), HWY_IF_BF16_D(D)>\n-HWY_API VFromD<D> DemoteTo(D dbf16, VFromD<Rebind<float, D>> v) {\n-  // TODO(janwas): _mm_cvtneps_pbh once we have avx512bf16.\n-  const Rebind<int32_t, decltype(dbf16)> di32;\n-  const Rebind<uint32_t, decltype(dbf16)> du32;  // for logical shift right\n-  const Rebind<uint16_t, decltype(dbf16)> du16;\n-  const auto bits_in_32 = BitCast(di32, ShiftRight<16>(BitCast(du32, v)));\n-  return BitCast(dbf16, DemoteTo(du16, bits_in_32));\n+HWY_API VFromD<D> DemoteTo(D /*dbf16*/, VFromD<Rebind<float, D>> v) {\n+  // The _mm_cvtneps_pbh intrinsic returns a __m128bh vector that needs to be\n+  // bit casted to a __m128i vector\n+  return VFromD<D>{detail::BitCastToInteger(_mm_cvtneps_pbh(v.raw))};\n }\n \n-template <class D, HWY_IF_V_SIZE_LE_D(D, 16), HWY_IF_BF16_D(D),\n-          class V32 = VFromD<Repartition<float, D>>>\n-HWY_API VFromD<D> ReorderDemote2To(D dbf16, V32 a, V32 b) {\n-  // TODO(janwas): _mm_cvtne2ps_pbh once we have avx512bf16.\n-  const RebindToUnsigned<decltype(dbf16)> du16;\n-  const Repartition<uint32_t, decltype(dbf16)> du32;\n-  const VFromD<decltype(du32)> b_in_even = ShiftRight<16>(BitCast(du32, b));\n-  return BitCast(dbf16, OddEven(BitCast(du16, a), BitCast(du16, b_in_even)));\n+template <class D, HWY_IF_V_SIZE_D(D, 16), HWY_IF_BF16_D(D)>\n+HWY_API VFromD<D> ReorderDemote2To(D /*dbf16*/, Vec128<float> a,\n+                                   Vec128<float> b) {\n+  // The _mm_cvtne2ps_pbh intrinsic returns a __m128bh vector that needs to be\n+  // bit casted to a __m128i vector\n+  return VFromD<D>{detail::BitCastToInteger(_mm_cvtne2ps_pbh(b.raw, a.raw))};\n }\n \n+template <class D, HWY_IF_V_SIZE_D(D, 8), HWY_IF_BF16_D(D)>\n+HWY_API VFromD<D> ReorderDemote2To(D /* tag */, Vec64<float> a,\n+                                   Vec64<float> b) {\n+  return VFromD<D>{_mm_shuffle_epi32(\n+      detail::BitCastToInteger(_mm_cvtne2ps_pbh(b.raw, a.raw)),\n+      _MM_SHUFFLE(2, 0, 2, 0))};\n+}\n+\n+template <class D, HWY_IF_V_SIZE_D(D, 4), HWY_IF_BF16_D(D)>\n+HWY_API VFromD<D> ReorderDemote2To(D dbf16, Vec32<float> a, Vec32<float> b) {\n+  const DFromV<decltype(a)> d;\n+  const Twice<decltype(d)> dt;\n+  return DemoteTo(dbf16, Combine(dt, b, a));\n+}\n+#endif  // HWY_AVX3_HAVE_F32_TO_BF16C\n+\n // Specializations for partial vectors because packs_epi32 sets lanes above 2*N.\n template <class D, HWY_IF_V_SIZE_D(D, 4), HWY_IF_I16_D(D)>\n HWY_API VFromD<D> ReorderDemote2To(D dn, Vec32<int32_t> a, Vec32<int32_t> b) {\n@@ -9427,11 +9482,15 @@ HWY_API VFromD<D> OrderedDemote2To(D d, V a, V b) {\n   return ReorderDemote2To(d, a, b);\n }\n \n-template <class D, HWY_IF_BF16_D(D), class V32 = VFromD<Repartition<float, D>>>\n-HWY_API VFromD<D> OrderedDemote2To(D dbf16, V32 a, V32 b) {\n-  const RebindToUnsigned<decltype(dbf16)> du16;\n-  return BitCast(dbf16, ConcatOdd(du16, BitCast(du16, b), BitCast(du16, a)));\n+#if HWY_AVX3_HAVE_F32_TO_BF16C\n+// F32 to BF16 OrderedDemote2To is generic for all vector lengths on targets\n+// that support AVX512BF16\n+template <class D, HWY_IF_BF16_D(D)>\n+HWY_API VFromD<D> OrderedDemote2To(D dbf16, VFromD<Repartition<float, D>> a,\n+                                   VFromD<Repartition<float, D>> b) {\n+  return ReorderDemote2To(dbf16, a, b);\n }\n+#endif  // HWY_AVX3_HAVE_F32_TO_BF16C\n \n template <class D, HWY_IF_V_SIZE_LE_D(D, 8), HWY_IF_F32_D(D)>\n HWY_API VFromD<D> DemoteTo(D /* tag */, VFromD<Rebind<double, D>> v) {"
      },
      {
        "filename": "hwy/ops/x86_256-inl.h",
        "status": "modified",
        "additions": 30,
        "deletions": 13,
        "changes": 43,
        "patch": "@@ -194,6 +194,25 @@ HWY_INLINE __m256i BitCastToInteger(__m256d v) {\n   return _mm256_castpd_si256(v);\n }\n \n+#if HWY_AVX3_HAVE_F32_TO_BF16C\n+HWY_INLINE __m256i BitCastToInteger(__m256bh v) {\n+  // Need to use reinterpret_cast on GCC/Clang or BitCastScalar on MSVC to\n+  // bit cast a __m256bh to a __m256i as there is currently no intrinsic\n+  // available (as of GCC 13 and Clang 17) that can bit cast a __m256bh vector\n+  // to a __m256i vector\n+\n+#if HWY_COMPILER_GCC || HWY_COMPILER_CLANG\n+  // On GCC or Clang, use reinterpret_cast to bit cast a __m256bh to a __m256i\n+  return reinterpret_cast<__m256i>(v);\n+#else\n+  // On MSVC, use BitCastScalar to bit cast a __m256bh to a __m256i as MSVC does\n+  // not allow reinterpret_cast, static_cast, or a C-style cast to be used to\n+  // bit cast from one AVX vector type to a different AVX vector type\n+  return BitCastScalar<__m256i>(v);\n+#endif  // HWY_COMPILER_GCC || HWY_COMPILER_CLANG\n+}\n+#endif  // HWY_AVX3_HAVE_F32_TO_BF16C\n+\n template <typename T>\n HWY_INLINE Vec256<uint8_t> BitCastToByte(Vec256<T> v) {\n   return Vec256<uint8_t>{BitCastToInteger(v.raw)};\n@@ -6300,24 +6319,22 @@ HWY_DIAGNOSTICS(pop)\n \n #endif  // HWY_DISABLE_F16C\n \n+#if HWY_AVX3_HAVE_F32_TO_BF16C\n template <class D, HWY_IF_V_SIZE_D(D, 16), HWY_IF_BF16_D(D)>\n-HWY_API VFromD<D> DemoteTo(D dbf16, Vec256<float> v) {\n-  // TODO(janwas): _mm256_cvtneps_pbh once we have avx512bf16.\n-  const Rebind<int32_t, decltype(dbf16)> di32;\n-  const Rebind<uint32_t, decltype(dbf16)> du32;  // for logical shift right\n-  const Rebind<uint16_t, decltype(dbf16)> du16;\n-  const auto bits_in_32 = BitCast(di32, ShiftRight<16>(BitCast(du32, v)));\n-  return BitCast(dbf16, DemoteTo(du16, bits_in_32));\n+HWY_API VFromD<D> DemoteTo(D /*dbf16*/, Vec256<float> v) {\n+  // The _mm256_cvtneps_pbh intrinsic returns a __m128bh vector that needs to be\n+  // bit casted to a __m128i vector\n+  return VFromD<D>{detail::BitCastToInteger(_mm256_cvtneps_pbh(v.raw))};\n }\n \n template <class D, HWY_IF_V_SIZE_D(D, 32), HWY_IF_BF16_D(D)>\n-HWY_API VFromD<D> ReorderDemote2To(D dbf16, Vec256<float> a, Vec256<float> b) {\n-  // TODO(janwas): _mm256_cvtne2ps_pbh once we have avx512bf16.\n-  const RebindToUnsigned<decltype(dbf16)> du16;\n-  const Repartition<uint32_t, decltype(dbf16)> du32;\n-  const Vec256<uint32_t> b_in_even = ShiftRight<16>(BitCast(du32, b));\n-  return BitCast(dbf16, OddEven(BitCast(du16, a), BitCast(du16, b_in_even)));\n+HWY_API VFromD<D> ReorderDemote2To(D /*dbf16*/, Vec256<float> a,\n+                                   Vec256<float> b) {\n+  // The _mm256_cvtne2ps_pbh intrinsic returns a __m256bh vector that needs to\n+  // be bit casted to a __m256i vector\n+  return VFromD<D>{detail::BitCastToInteger(_mm256_cvtne2ps_pbh(b.raw, a.raw))};\n }\n+#endif  // HWY_AVX3_HAVE_F32_TO_BF16C\n \n template <class D, HWY_IF_V_SIZE_D(D, 32), HWY_IF_I16_D(D)>\n HWY_API VFromD<D> ReorderDemote2To(D /*d16*/, Vec256<int32_t> a,"
      },
      {
        "filename": "hwy/ops/x86_512-inl.h",
        "status": "modified",
        "additions": 30,
        "deletions": 13,
        "changes": 43,
        "patch": "@@ -193,6 +193,25 @@ HWY_INLINE __m512i BitCastToInteger(__m512d v) {\n   return _mm512_castpd_si512(v);\n }\n \n+#if HWY_AVX3_HAVE_F32_TO_BF16C\n+HWY_INLINE __m512i BitCastToInteger(__m512bh v) {\n+  // Need to use reinterpret_cast on GCC/Clang or BitCastScalar on MSVC to\n+  // bit cast a __m512bh to a __m512i as there is currently no intrinsic\n+  // available (as of GCC 13 and Clang 17) that can bit cast a __m512bh vector\n+  // to a __m512i vector\n+\n+#if HWY_COMPILER_GCC || HWY_COMPILER_CLANG\n+  // On GCC or Clang, use reinterpret_cast to bit cast a __m512bh to a __m512i\n+  return reinterpret_cast<__m512i>(v);\n+#else\n+  // On MSVC, use BitCastScalar to bit cast a __m512bh to a __m512i as MSVC does\n+  // not allow reinterpret_cast, static_cast, or a C-style cast to be used to\n+  // bit cast from one AVX vector type to a different AVX vector type\n+  return BitCastScalar<__m512i>(v);\n+#endif  // HWY_COMPILER_GCC || HWY_COMPILER_CLANG\n+}\n+#endif  // HWY_AVX3_HAVE_F32_TO_BF16C\n+\n template <typename T>\n HWY_INLINE Vec512<uint8_t> BitCastToByte(Vec512<T> v) {\n   return Vec512<uint8_t>{BitCastToInteger(v.raw)};\n@@ -5513,24 +5532,22 @@ HWY_API VFromD<D> DemoteTo(D df16, Vec512<float> v) {\n   HWY_DIAGNOSTICS(pop)\n }\n \n+#if HWY_AVX3_HAVE_F32_TO_BF16C\n template <class D, HWY_IF_V_SIZE_D(D, 32), HWY_IF_BF16_D(D)>\n-HWY_API VFromD<D> DemoteTo(D dbf16, Vec512<float> v) {\n-  // TODO(janwas): _mm512_cvtneps_pbh once we have avx512bf16.\n-  const Rebind<int32_t, decltype(dbf16)> di32;\n-  const Rebind<uint32_t, decltype(dbf16)> du32;  // for logical shift right\n-  const Rebind<uint16_t, decltype(dbf16)> du16;\n-  const auto bits_in_32 = BitCast(di32, ShiftRight<16>(BitCast(du32, v)));\n-  return BitCast(dbf16, DemoteTo(du16, bits_in_32));\n+HWY_API VFromD<D> DemoteTo(D /*dbf16*/, Vec512<float> v) {\n+  // The _mm512_cvtneps_pbh intrinsic returns a __m256bh vector that needs to be\n+  // bit casted to a __m256i vector\n+  return VFromD<D>{detail::BitCastToInteger(_mm512_cvtneps_pbh(v.raw))};\n }\n \n template <class D, HWY_IF_V_SIZE_D(D, 64), HWY_IF_BF16_D(D)>\n-HWY_API VFromD<D> ReorderDemote2To(D dbf16, Vec512<float> a, Vec512<float> b) {\n-  // TODO(janwas): _mm512_cvtne2ps_pbh once we have avx512bf16.\n-  const RebindToUnsigned<decltype(dbf16)> du16;\n-  const Repartition<uint32_t, decltype(dbf16)> du32;\n-  const Vec512<uint32_t> b_in_even = ShiftRight<16>(BitCast(du32, b));\n-  return BitCast(dbf16, OddEven(BitCast(du16, a), BitCast(du16, b_in_even)));\n+HWY_API VFromD<D> ReorderDemote2To(D /*dbf16*/, Vec512<float> a,\n+                                   Vec512<float> b) {\n+  // The _mm512_cvtne2ps_pbh intrinsic returns a __m512bh vector that needs to\n+  // be bit casted to a __m512i vector\n+  return VFromD<D>{detail::BitCastToInteger(_mm512_cvtne2ps_pbh(b.raw, a.raw))};\n }\n+#endif  // HWY_AVX3_HAVE_F32_TO_BF16C\n \n template <class D, HWY_IF_V_SIZE_D(D, 64), HWY_IF_I16_D(D)>\n HWY_API VFromD<D> ReorderDemote2To(D /* tag */, Vec512<int32_t> a,"
      },
      {
        "filename": "hwy/targets.cc",
        "status": "modified",
        "additions": 10,
        "deletions": 2,
        "changes": 12,
        "patch": "@@ -136,6 +136,7 @@ enum class FeatureIndex : uint32_t {\n   kAVX512DQ,\n   kAVX512BW,\n   kAVX512FP16,\n+  kAVX512BF16,\n \n   kVNNI,\n   kVPCLMULQDQ,\n@@ -203,6 +204,9 @@ uint64_t FlagsFromCPUID() {\n     flags |= IsBitSet(abcd[2], 14) ? Bit(FeatureIndex::kPOPCNTDQ) : 0;\n \n     flags |= IsBitSet(abcd[3], 23) ? Bit(FeatureIndex::kAVX512FP16) : 0;\n+\n+    Cpuid(7, 1, abcd);\n+    flags |= IsBitSet(abcd[0], 5) ? Bit(FeatureIndex::kAVX512BF16) : 0;\n   }\n \n   return flags;\n@@ -252,8 +256,11 @@ constexpr uint64_t kGroupAVX3_DL =\n     Bit(FeatureIndex::kVAES) | Bit(FeatureIndex::kPOPCNTDQ) |\n     Bit(FeatureIndex::kBITALG) | Bit(FeatureIndex::kGFNI) | kGroupAVX3;\n \n+constexpr uint64_t kGroupAVX3_ZEN4 =\n+    Bit(FeatureIndex::kAVX512BF16) | kGroupAVX3_DL;\n+\n constexpr uint64_t kGroupAVX3_SPR =\n-    Bit(FeatureIndex::kAVX512FP16) | kGroupAVX3_DL;\n+    Bit(FeatureIndex::kAVX512FP16) | kGroupAVX3_ZEN4;\n \n int64_t DetectTargets() {\n   int64_t bits = 0;  // return value of supported targets.\n@@ -322,7 +329,8 @@ int64_t DetectTargets() {\n \n   // This is mainly to work around the slow Zen4 CompressStore. It's unclear\n   // whether subsequent AMD models will be affected; assume yes.\n-  if ((bits & HWY_AVX3_DL) && IsAMD()) {\n+  if ((bits & HWY_AVX3_DL) && (flags & kGroupAVX3_ZEN4) == kGroupAVX3_ZEN4 &&\n+      IsAMD()) {\n     bits |= HWY_AVX3_ZEN4;\n   }\n "
      }
    ],
    "lines_added": 467,
    "lines_removed": 167
  },
  "issues": [],
  "pull_requests": [],
  "build_info": {
    "old_build_script": "#!/bin/bash\n#!/bin/bash\ncmake -S /test_workspace/workspace/old -B /test_workspace/workspace/old/build -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=ON -DBUILD_TESTING=ON -DHWY_ENABLE_TESTS=ON",
    "new_build_script": "#!/bin/bash\n#!/bin/bash\ncmake -S /test_workspace/workspace/new -B /test_workspace/workspace/new/build -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=ON -DBUILD_TESTING=ON -DHWY_ENABLE_TESTS=ON",
    "old_test_script": "#!/bin/bash\ncmake --build /test_workspace/workspace/old/build -- -j 1",
    "new_test_script": "#!/bin/bash\ncmake --build /test_workspace/workspace/new/build -- -j 1",
    "build_system": "cmake"
  },
  "performance_analysis": {
    "is_significant": false,
    "p_value": 0.9589172724370648,
    "is_pair_significant": false,
    "pair_p_value": 0.9999998859165735,
    "is_binom_significant": false,
    "binom_p_value": 1.0,
    "is_wilcoxon_significant": false,
    "wilcoxon_p_value": 1.0,
    "is_mannwhitney_significant": false,
    "mannwhitney_p_value": 0.8222637637028447,
    "relative_improvement": -0.017829486244684417,
    "absolute_improvement_ms": -1116.6666666666813,
    "old_mean_ms": 62630.33333333333,
    "new_mean_ms": 63747.00000000001,
    "old_std_ms": 9095.533001133726,
    "new_std_ms": 9912.125333181055,
    "effect_size_cohens_d": -0.11738822046131354,
    "old_ci95_ms": [
      59234.00549362417,
      66026.66117304246
    ],
    "new_ci95_ms": [
      60045.75157227478,
      67448.24842772524
    ],
    "old_ci99_ms": [
      58053.05262667613,
      67207.61403999051
    ],
    "new_ci99_ms": [
      58758.77335689043,
      68735.22664310958
    ],
    "new_times_s": [
      52.42,
      52.44,
      52.8,
      52.45,
      52.83,
      82.95,
      83.85,
      81.47,
      82.17,
      82.29,
      63.34,
      64.31,
      64.43,
      65.06,
      65.33,
      63.91,
      63.78,
      65.03,
      65.86,
      67.33,
      63.07,
      62.01,
      61.08,
      60.62,
      61.6,
      60.13,
      62.94,
      52.16,
      52.17,
      52.94,
      52.06
    ],
    "old_times_s": [
      51.06,
      52.3,
      51.68,
      51.96,
      51.55,
      81.82,
      81.31,
      81.04,
      81.95,
      63.57,
      64.2,
      63.73,
      64.44,
      64.8,
      63.88,
      63.46,
      62.75,
      63.39,
      67.06,
      66.79,
      62.74,
      60.81,
      60.52,
      62.51,
      61.29,
      60.32,
      60.11,
      51.78,
      52.6,
      52.0,
      52.55
    ]
  },
  "tests": {
    "total_tests": 5,
    "significant_improvements": 0,
    "significant_improvements_tests": [],
    "significant_regressions": 0,
    "significant_regressions_tests": [],
    "significant_pair_improvements": 0,
    "significant_pair_improvements_tests": [],
    "significant_pair_regressions": 0,
    "significant_pair_regressions_tests": [],
    "significant_binom_improvements": 0,
    "significant_binom_improvements_tests": [],
    "significant_binom_regressions": 0,
    "significant_binom_regressions_tests": [],
    "significant_wilcoxon_improvements": 0,
    "significant_wilcoxon_improvements_tests": [],
    "significant_wilcoxon_regressions": 0,
    "significant_wilcoxon_regressions_tests": [],
    "significant_mannwhitney_improvements": 1,
    "significant_mannwhitney_improvements_tests": [
      "NanobenchmarkTest.RunAll"
    ],
    "significant_mannwhitney_regressions": 0,
    "significant_mannwhitney_regressions_tests": [],
    "tests": [
      {
        "test_name": "NanobenchmarkTest.RunAll",
        "is_significant": false,
        "p_value": 0.2305787409408271,
        "is_pair_significant": false,
        "pair_p_value": 0.15853165237675634,
        "is_binom_significant": false,
        "binom_p_value": 0.355535551905632,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.21489623100415728,
        "is_mannwhitney_significant": true,
        "mannwhitney_p_value": 0.03191456761582982,
        "relative_improvement": 0.0769230769230768,
        "absolute_improvement_ms": 34.13793103448276,
        "old_mean_ms": 443.7931034482758,
        "new_mean_ms": 409.6551724137931,
        "old_std_ms": 58.51823849410714,
        "new_std_ms": 66.51974779936135,
        "effect_size_cohens_d": 0.5449263478444396,
        "old_ci95_ms": [
          421.5339559663272,
          466.05225093022443
        ],
        "new_ci95_ms": [
          384.35241356746997,
          434.9579312601162
        ],
        "old_ci99_ms": [
          413.76593488766764,
          473.820272008884
        ],
        "new_ci99_ms": [
          375.52222974188214,
          443.78811508570396
        ],
        "new_times": [
          0.46,
          0.32,
          0.33,
          0.38,
          0.3,
          0.34,
          0.4,
          0.37,
          0.33,
          0.35,
          0.41,
          0.38,
          0.3,
          0.4,
          0.35,
          0.48,
          0.47,
          0.41,
          0.42,
          0.4,
          0.49,
          0.53,
          0.42,
          0.5,
          0.44,
          0.48,
          0.48,
          0.52,
          0.42
        ],
        "old_times": [
          0.36,
          0.4,
          0.44,
          0.41,
          0.48,
          0.41,
          0.36,
          0.39,
          0.34,
          0.4,
          0.41,
          0.35,
          0.42,
          0.39,
          0.53,
          0.46,
          0.49,
          0.47,
          0.51,
          0.45,
          0.43,
          0.53,
          0.47,
          0.48,
          0.46,
          0.5,
          0.52,
          0.56,
          0.45
        ]
      },
      {
        "test_name": "ThreadPoolTest.TestDivisor",
        "is_significant": false,
        "p_value": 1.0,
        "is_pair_significant": false,
        "pair_p_value": 1.0,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999999638108507,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 1.0,
        "relative_improvement": 0.0,
        "absolute_improvement_ms": 0.0,
        "old_mean_ms": 10.000000000000002,
        "new_mean_ms": 10.000000000000002,
        "old_std_ms": 1.7654289301252243e-15,
        "new_std_ms": 1.7654289301252243e-15,
        "effect_size_cohens_d": 0.0,
        "old_ci95_ms": [
          10.000000000000002,
          10.000000000000002
        ],
        "new_ci95_ms": [
          10.000000000000002,
          10.000000000000002
        ],
        "old_ci99_ms": [
          10.0,
          10.000000000000004
        ],
        "new_ci99_ms": [
          10.0,
          10.000000000000004
        ],
        "new_times": [
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01
        ],
        "old_times": [
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01
        ]
      },
      {
        "test_name": "ThreadPoolTest.TestPool",
        "is_significant": false,
        "p_value": 0.9288675430172125,
        "is_pair_significant": false,
        "pair_p_value": 0.9995671861085691,
        "is_binom_significant": false,
        "binom_p_value": 0.995934970676899,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9989710844628298,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.5464330627366072,
        "relative_improvement": -0.05528366866050385,
        "absolute_improvement_ms": -105.17241379310337,
        "old_mean_ms": 1902.4137931034484,
        "new_mean_ms": 2007.5862068965519,
        "old_std_ms": 409.36933352600687,
        "new_std_ms": 609.3301660278498,
        "effect_size_cohens_d": -0.20261717018929934,
        "old_ci95_ms": [
          1746.6980264632748,
          2058.129559743622
        ],
        "new_ci95_ms": [
          1775.8094073918985,
          2239.3630064012054
        ],
        "old_ci99_ms": [
          1692.3561717933492,
          2112.471414413548
        ],
        "new_ci99_ms": [
          1694.9236921794677,
          2320.248721613636
        ],
        "new_times": [
          1.54,
          1.3,
          1.44,
          3.28,
          3.5,
          3.14,
          3.3,
          2.68,
          2.04,
          1.98,
          1.81,
          2.03,
          2.04,
          1.96,
          1.77,
          2.15,
          2.3,
          2.07,
          1.86,
          1.49,
          1.93,
          1.71,
          1.74,
          1.67,
          1.55,
          1.53,
          1.53,
          1.52,
          1.36
        ],
        "old_times": [
          1.34,
          1.23,
          1.58,
          2.78,
          2.71,
          2.71,
          2.74,
          1.97,
          2.17,
          2.08,
          1.94,
          2.03,
          1.97,
          1.81,
          1.82,
          1.99,
          1.97,
          1.73,
          1.84,
          1.69,
          1.59,
          2.08,
          1.85,
          1.83,
          1.62,
          1.41,
          1.6,
          1.52,
          1.57
        ]
      },
      {
        "test_name": "ThreadPoolTest.TestSmallAssignments",
        "is_significant": false,
        "p_value": 0.6782203633411505,
        "is_pair_significant": false,
        "pair_p_value": 0.843190058660725,
        "is_binom_significant": false,
        "binom_p_value": 0.9319770261645317,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9450589779944493,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.3069575176338514,
        "relative_improvement": 0.019354838709677438,
        "absolute_improvement_ms": 2.0689655172413666,
        "old_mean_ms": 106.89655172413792,
        "new_mean_ms": 104.82758620689656,
        "old_std_ms": 27.65907862785512,
        "new_std_ms": 27.33661720831765,
        "effect_size_cohens_d": 0.07523970455575686,
        "old_ci95_ms": [
          96.37560088495229,
          117.41750256332355
        ],
        "new_ci95_ms": [
          94.42929313184452,
          115.2258792819486
        ],
        "old_ci99_ms": [
          92.70398821638034,
          121.08911523189552
        ],
        "new_ci99_ms": [
          90.80048570089558,
          118.85468671289753
        ],
        "new_times": [
          0.08,
          0.08,
          0.08,
          0.17,
          0.13,
          0.16,
          0.19,
          0.11,
          0.1,
          0.11,
          0.11,
          0.12,
          0.11,
          0.09,
          0.1,
          0.1,
          0.1,
          0.1,
          0.09,
          0.1,
          0.09,
          0.08,
          0.1,
          0.1,
          0.11,
          0.08,
          0.09,
          0.08,
          0.08
        ],
        "old_times": [
          0.08,
          0.08,
          0.09,
          0.19,
          0.15,
          0.15,
          0.14,
          0.11,
          0.1,
          0.12,
          0.12,
          0.11,
          0.11,
          0.12,
          0.1,
          0.11,
          0.13,
          0.13,
          0.08,
          0.07,
          0.09,
          0.1,
          0.09,
          0.11,
          0.11,
          0.07,
          0.08,
          0.08,
          0.08
        ]
      },
      {
        "test_name": "ThreadPoolTest.TestCounter",
        "is_significant": false,
        "p_value": 0.8959927621248986,
        "is_pair_significant": false,
        "pair_p_value": 0.9307136525982643,
        "is_binom_significant": false,
        "binom_p_value": 0.9319770261645317,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.8679946960075686,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.6625004764262268,
        "relative_improvement": -0.08904109589041104,
        "absolute_improvement_ms": -4.482758620689649,
        "old_mean_ms": 50.344827586206904,
        "new_mean_ms": 54.827586206896555,
        "old_std_ms": 17.004780550667352,
        "new_std_ms": 24.730069847855326,
        "effect_size_cohens_d": -0.21123257285287492,
        "old_ci95_ms": [
          43.876554994344914,
          56.81310017806889
        ],
        "new_ci95_ms": [
          45.42077072256279,
          64.2344016912303
        ],
        "old_ci99_ms": [
          41.61925031199591,
          59.070404860417895
        ],
        "new_ci99_ms": [
          42.137970200906494,
          67.51720221288662
        ],
        "new_times": [
          0.04,
          0.03,
          0.03,
          0.07,
          0.13,
          0.06,
          0.06,
          0.08,
          0.05,
          0.05,
          0.04,
          0.06,
          0.07,
          0.04,
          0.04,
          0.06,
          0.12,
          0.05,
          0.07,
          0.06,
          0.07,
          0.04,
          0.04,
          0.04,
          0.07,
          0.03,
          0.03,
          0.03,
          0.03
        ],
        "old_times": [
          0.04,
          0.03,
          0.05,
          0.1,
          0.08,
          0.08,
          0.06,
          0.05,
          0.06,
          0.07,
          0.05,
          0.04,
          0.04,
          0.05,
          0.07,
          0.05,
          0.04,
          0.05,
          0.05,
          0.04,
          0.04,
          0.05,
          0.05,
          0.06,
          0.04,
          0.03,
          0.03,
          0.03,
          0.03
        ]
      }
    ]
  },
  "logs": {
    "full_log_path": "/logs/full.log",
    "config_log_path": "/logs/config.log",
    "build_log_path": "/logs/build.log",
    "test_log_path": "/logs/test.log",
    "build_success": true,
    "test_success": true
  },
  "raw_timing_data": {
    "warmup_runs": 1,
    "measurement_runs": 30,
    "min_exec_time_improvement": 0.05,
    "min_p_value": 0.05
  }
}