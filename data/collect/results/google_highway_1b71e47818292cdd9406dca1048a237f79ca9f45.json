{
  "metadata": {
    "collection_date": "2026-01-11T17:51:14.668297",
    "repository": "https://github.com/google/highway",
    "repository_name": "google/highway"
  },
  "commit_info": {
    "old_sha": "01361d52cd637a3f3c1394c5090798e186900271",
    "new_sha": "1b71e47818292cdd9406dca1048a237f79ca9f45",
    "commit_message": [
      "replace x86 LoadDup128 usages with Dup128VecFromValues. Fixes #1870, thanks @ag01\n\nPiperOrigin-RevId: 590608628"
    ],
    "commit_date": "2023-12-13T16:34:43+00:00",
    "patch": [
      "--- hwy/ops/generic_ops-inl.h\n@@ -867,40 +867,41 @@ HWY_API void LoadInterleaved3(D d, const TFromD<D>* HWY_RESTRICT unaligned,\n                               VFromD<D>& v0, VFromD<D>& v1, VFromD<D>& v2) {\n   const RebindToUnsigned<decltype(d)> du;\n   using V = VFromD<D>;\n+  using VU = VFromD<decltype(du)>;\n   // Compact notation so these fit on one line: 12 := v1[2].\n   V A;  // 05 24 14 04 23 13 03 22 12 02 21 11 01 20 10 00\n   V B;  // 1a 0a 29 19 09 28 18 08 27 17 07 26 16 06 25 15\n   V C;  // 2f 1f 0f 2e 1e 0e 2d 1d 0d 2c 1c 0c 2b 1b 0b 2a\n   detail::LoadTransposedBlocks3(d, unaligned, A, B, C);\n   // Compress all lanes belonging to v0 into consecutive lanes.\n   constexpr uint8_t Z = 0x80;\n-  alignas(16) static constexpr uint8_t kIdx_v0A[16] = {\n-      0, 3, 6, 9, 12, 15, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v0B[16] = {\n-      Z, Z, Z, Z, Z, Z, 2, 5, 8, 11, 14, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v0C[16] = {\n-      Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, 1, 4, 7, 10, 13};\n-  alignas(16) static constexpr uint8_t kIdx_v1A[16] = {\n-      1, 4, 7, 10, 13, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v1B[16] = {\n-      Z, Z, Z, Z, Z, 0, 3, 6, 9, 12, 15, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v1C[16] = {\n-      Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, 2, 5, 8, 11, 14};\n-  alignas(16) static constexpr uint8_t kIdx_v2A[16] = {\n-      2, 5, 8, 11, 14, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v2B[16] = {\n-      Z, Z, Z, Z, Z, 1, 4, 7, 10, 13, Z, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v2C[16] = {\n-      Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, 0, 3, 6, 9, 12, 15};\n-  const V v0L = BitCast(d, TableLookupBytesOr0(A, LoadDup128(du, kIdx_v0A)));\n-  const V v0M = BitCast(d, TableLookupBytesOr0(B, LoadDup128(du, kIdx_v0B)));\n-  const V v0U = BitCast(d, TableLookupBytesOr0(C, LoadDup128(du, kIdx_v0C)));\n-  const V v1L = BitCast(d, TableLookupBytesOr0(A, LoadDup128(du, kIdx_v1A)));\n-  const V v1M = BitCast(d, TableLookupBytesOr0(B, LoadDup128(du, kIdx_v1B)));\n-  const V v1U = BitCast(d, TableLookupBytesOr0(C, LoadDup128(du, kIdx_v1C)));\n-  const V v2L = BitCast(d, TableLookupBytesOr0(A, LoadDup128(du, kIdx_v2A)));\n-  const V v2M = BitCast(d, TableLookupBytesOr0(B, LoadDup128(du, kIdx_v2B)));\n-  const V v2U = BitCast(d, TableLookupBytesOr0(C, LoadDup128(du, kIdx_v2C)));\n+  const VU idx_v0A =\n+      Dup128VecFromValues(du, 0, 3, 6, 9, 12, 15, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z);\n+  const VU idx_v0B =\n+      Dup128VecFromValues(du, Z, Z, Z, Z, Z, Z, 2, 5, 8, 11, 14, Z, Z, Z, Z, Z);\n+  const VU idx_v0C =\n+      Dup128VecFromValues(du, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, 1, 4, 7, 10, 13);\n+  const VU idx_v1A =\n+      Dup128VecFromValues(du, 1, 4, 7, 10, 13, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z);\n+  const VU idx_v1B =\n+      Dup128VecFromValues(du, Z, Z, Z, Z, Z, 0, 3, 6, 9, 12, 15, Z, Z, Z, Z, Z);\n+  const VU idx_v1C =\n+      Dup128VecFromValues(du, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, 2, 5, 8, 11, 14);\n+  const VU idx_v2A =\n+      Dup128VecFromValues(du, 2, 5, 8, 11, 14, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z);\n+  const VU idx_v2B =\n+      Dup128VecFromValues(du, Z, Z, Z, Z, Z, 1, 4, 7, 10, 13, Z, Z, Z, Z, Z, Z);\n+  const VU idx_v2C =\n+      Dup128VecFromValues(du, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, 0, 3, 6, 9, 12, 15);\n+  const V v0L = BitCast(d, TableLookupBytesOr0(A, idx_v0A));\n+  const V v0M = BitCast(d, TableLookupBytesOr0(B, idx_v0B));\n+  const V v0U = BitCast(d, TableLookupBytesOr0(C, idx_v0C));\n+  const V v1L = BitCast(d, TableLookupBytesOr0(A, idx_v1A));\n+  const V v1M = BitCast(d, TableLookupBytesOr0(B, idx_v1B));\n+  const V v1U = BitCast(d, TableLookupBytesOr0(C, idx_v1C));\n+  const V v2L = BitCast(d, TableLookupBytesOr0(A, idx_v2A));\n+  const V v2M = BitCast(d, TableLookupBytesOr0(B, idx_v2B));\n+  const V v2U = BitCast(d, TableLookupBytesOr0(C, idx_v2C));\n   v0 = Xor3(v0L, v0M, v0U);\n   v1 = Xor3(v1L, v1M, v1U);\n   v2 = Xor3(v2L, v2M, v2U);\n@@ -912,30 +913,40 @@ HWY_API void LoadInterleaved3(D d, const TFromD<D>* HWY_RESTRICT unaligned,\n                               VFromD<D>& v0, VFromD<D>& v1, VFromD<D>& v2) {\n   const RebindToUnsigned<decltype(d)> du;\n   using V = VFromD<D>;\n+  using VU = VFromD<decltype(du)>;\n   V A;  // v1[2] v0[2] v2[1] v1[1] v0[1] v2[0] v1[0] v0[0]\n   V B;  // v0[5] v2[4] v1[4] v0[4] v2[3] v1[3] v0[3] v2[2]\n   V C;  // v2[7] v1[7] v0[7] v2[6] v1[6] v0[6] v2[5] v1[5]\n   detail::LoadTransposedBlocks3(d, unaligned, A, B, C);\n   // Compress all lanes belonging to v0 into consecutive lanes.\n   constexpr uint8_t Z = 0x80;\n-  alignas(16) static constexpr uint8_t kIdx_v0A[16] = {0, 3, 6, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v0B[16] = {Z, Z, Z, 1, 4, 7, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v0C[16] = {Z, Z, Z, Z, Z, Z, 2, 5};\n-  alignas(16) static constexpr uint8_t kIdx_v1A[16] = {1, 4, 7, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v1B[16] = {Z, Z, Z, 2, 5, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v1C[16] = {Z, Z, Z, Z, Z, 0, 3, 6};\n-  alignas(16) static constexpr uint8_t kIdx_v2A[16] = {2, 5, Z, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v2B[16] = {Z, Z, 0, 3, 6, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v2C[16] = {Z, Z, Z, Z, Z, 1, 4, 7};\n-  const V v0L = BitCast(d, TableLookupBytesOr0(A, LoadDup128(du, kIdx_v0A)));\n-  const V v0M = BitCast(d, TableLookupBytesOr0(B, LoadDup128(du, kIdx_v0B)));\n-  const V v0U = BitCast(d, TableLookupBytesOr0(C, LoadDup128(du, kIdx_v0C)));\n-  const V v1L = BitCast(d, TableLookupBytesOr0(A, LoadDup128(du, kIdx_v1A)));\n-  const V v1M = BitCast(d, TableLookupBytesOr0(B, LoadDup128(du, kIdx_v1B)));\n-  const V v1U = BitCast(d, TableLookupBytesOr0(C, LoadDup128(du, kIdx_v1C)));\n-  const V v2L = BitCast(d, TableLookupBytesOr0(A, LoadDup128(du, kIdx_v2A)));\n-  const V v2M = BitCast(d, TableLookupBytesOr0(B, LoadDup128(du, kIdx_v2B)));\n-  const V v2U = BitCast(d, TableLookupBytesOr0(C, LoadDup128(du, kIdx_v2C)));\n+  const VU idx_v0A =\n+      Dup128VecFromValues(du, 0, 3, 6, Z, Z, Z, Z, Z, 0, 0, 0, 0, 0, 0, 0, 0);\n+  const VU idx_v0B =\n+      Dup128VecFromValues(du, Z, Z, Z, 1, 4, 7, Z, Z, 0, 0, 0, 0, 0, 0, 0, 0);\n+  const VU idx_v0C =\n+      Dup128VecFromValues(du, Z, Z, Z, Z, Z, Z, 2, 5, 0, 0, 0, 0, 0, 0, 0, 0);\n+  const VU idx_v1A =\n+      Dup128VecFromValues(du, 1, 4, 7, Z, Z, Z, Z, Z, 0, 0, 0, 0, 0, 0, 0, 0);\n+  const VU idx_v1B =\n+      Dup128VecFromValues(du, Z, Z, Z, 2, 5, Z, Z, Z, 0, 0, 0, 0, 0, 0, 0, 0);\n+  const VU idx_v1C =\n+      Dup128VecFromValues(du, Z, Z, Z, Z, Z, 0, 3, 6, 0, 0, 0, 0, 0, 0, 0, 0);\n+  const VU idx_v2A =\n+      Dup128VecFromValues(du, 2, 5, Z, Z, Z, Z, Z, Z, 0, 0, 0, 0, 0, 0, 0, 0);\n+  const VU idx_v2B =\n+      Dup128VecFromValues(du, Z, Z, 0, 3, 6, Z, Z, Z, 0, 0, 0, 0, 0, 0, 0, 0);\n+  const VU idx_v2C =\n+      Dup128VecFromValues(du, Z, Z, Z, Z, Z, 1, 4, 7, 0, 0, 0, 0, 0, 0, 0, 0);\n+  const V v0L = BitCast(d, TableLookupBytesOr0(A, idx_v0A));\n+  const V v0M = BitCast(d, TableLookupBytesOr0(B, idx_v0B));\n+  const V v0U = BitCast(d, TableLookupBytesOr0(C, idx_v0C));\n+  const V v1L = BitCast(d, TableLookupBytesOr0(A, idx_v1A));\n+  const V v1M = BitCast(d, TableLookupBytesOr0(B, idx_v1B));\n+  const V v1U = BitCast(d, TableLookupBytesOr0(C, idx_v1C));\n+  const V v2L = BitCast(d, TableLookupBytesOr0(A, idx_v2A));\n+  const V v2M = BitCast(d, TableLookupBytesOr0(B, idx_v2B));\n+  const V v2U = BitCast(d, TableLookupBytesOr0(C, idx_v2C));\n   v0 = Xor3(v0L, v0M, v0U);\n   v1 = Xor3(v1L, v1M, v1U);\n   v2 = Xor3(v2L, v2M, v2U);\n@@ -948,40 +959,41 @@ HWY_API void LoadInterleaved3(D d, const TFromD<D>* HWY_RESTRICT unaligned,\n   const RebindToUnsigned<decltype(d)> du;\n   const Repartition<uint8_t, decltype(du)> du8;\n   using V = VFromD<D>;\n+  using VU8 = VFromD<decltype(du8)>;\n   V A;  // v1[2] v0[2] v2[1] v1[1] v0[1] v2[0] v1[0] v0[0]\n   V B;  // v0[5] v2[4] v1[4] v0[4] v2[3] v1[3] v0[3] v2[2]\n   V C;  // v2[7] v1[7] v0[7] v2[6] v1[6] v0[6] v2[5] v1[5]\n   detail::LoadTransposedBlocks3(d, unaligned, A, B, C);\n   // Compress all lanes belonging to v0 into consecutive lanes. Same as above,\n   // but each element of the array contains a byte index for a byte of a lane.\n   constexpr uint8_t Z = 0x80;\n-  alignas(16) static constexpr uint8_t kIdx_v0A[16] = {\n-      0x00, 0x01, 0x06, 0x07, 0x0C, 0x0D, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v0B[16] = {\n-      Z, Z, Z, Z, Z, Z, 0x02, 0x03, 0x08, 0x09, 0x0E, 0x0F, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v0C[16] = {\n-      Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, 0x04, 0x05, 0x0A, 0x0B};\n-  alignas(16) static constexpr uint8_t kIdx_v1A[16] = {\n-      0x02, 0x03, 0x08, 0x09, 0x0E, 0x0F, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v1B[16] = {\n-      Z, Z, Z, Z, Z, Z, 0x04, 0x05, 0x0A, 0x0B, Z, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v1C[16] = {\n-      Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, 0x00, 0x01, 0x06, 0x07, 0x0C, 0x0D};\n-  alignas(16) static constexpr uint8_t kIdx_v2A[16] = {\n-      0x04, 0x05, 0x0A, 0x0B, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v2B[16] = {\n-      Z, Z, Z, Z, 0x00, 0x01, 0x06, 0x07, 0x0C, 0x0D, Z, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v2C[16] = {\n-      Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, 0x02, 0x03, 0x08, 0x09, 0x0E, 0x0F};\n-  const V v0L = TableLookupBytesOr0(A, BitCast(d, LoadDup128(du8, kIdx_v0A)));\n-  const V v0M = TableLookupBytesOr0(B, BitCast(d, LoadDup128(du8, kIdx_v0B)));\n-  const V v0U = TableLookupBytesOr0(C, BitCast(d, LoadDup128(du8, kIdx_v0C)));\n-  const V v1L = TableLookupBytesOr0(A, BitCast(d, LoadDup128(du8, kIdx_v1A)));\n-  const V v1M = TableLookupBytesOr0(B, BitCast(d, LoadDup128(du8, kIdx_v1B)));\n-  const V v1U = TableLookupBytesOr0(C, BitCast(d, LoadDup128(du8, kIdx_v1C)));\n-  const V v2L = TableLookupBytesOr0(A, BitCast(d, LoadDup128(du8, kIdx_v2A)));\n-  const V v2M = TableLookupBytesOr0(B, BitCast(d, LoadDup128(du8, kIdx_v2B)));\n-  const V v2U = TableLookupBytesOr0(C, BitCast(d, LoadDup128(du8, kIdx_v2C)));\n+  const VU8 idx_v0A = Dup128VecFromValues(du8, 0x00, 0x01, 0x06, 0x07, 0x0C,\n+                                          0x0D, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z);\n+  const VU8 idx_v0B = Dup128VecFromValues(du8, Z, Z, Z, Z, Z, Z, 0x02, 0x03,\n+                                          0x08, 0x09, 0x0E, 0x0F, Z, Z, Z, Z);\n+  const VU8 idx_v0C = Dup128VecFromValues(du8, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z,\n+                                          Z, 0x04, 0x05, 0x0A, 0x0B);\n+  const VU8 idx_v1A = Dup128VecFromValues(du8, 0x02, 0x03, 0x08, 0x09, 0x0E,\n+                                          0x0F, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z);\n+  const VU8 idx_v1B = Dup128VecFromValues(du8, Z, Z, Z, Z, Z, Z, 0x04, 0x05,\n+                                          0x0A, 0x0B, Z, Z, Z, Z, Z, Z);\n+  const VU8 idx_v1C = Dup128VecFromValues(du8, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z,\n+                                          0x00, 0x01, 0x06, 0x07, 0x0C, 0x0D);\n+  const VU8 idx_v2A = Dup128VecFromValues(du8, 0x04, 0x05, 0x0A, 0x0B, Z, Z, Z,\n+                                          Z, Z, Z, Z, Z, Z, Z, Z, Z);\n+  const VU8 idx_v2B = Dup128VecFromValues(du8, Z, Z, Z, Z, 0x00, 0x01, 0x06,\n+                                          0x07, 0x0C, 0x0D, Z, Z, Z, Z, Z, Z);\n+  const VU8 idx_v2C = Dup128VecFromValues(du8, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z,\n+                                          0x02, 0x03, 0x08, 0x09, 0x0E, 0x0F);\n+  const V v0L = TableLookupBytesOr0(A, BitCast(d, idx_v0A));\n+  const V v0M = TableLookupBytesOr0(B, BitCast(d, idx_v0B));\n+  const V v0U = TableLookupBytesOr0(C, BitCast(d, idx_v0C));\n+  const V v1L = TableLookupBytesOr0(A, BitCast(d, idx_v1A));\n+  const V v1M = TableLookupBytesOr0(B, BitCast(d, idx_v1B));\n+  const V v1U = TableLookupBytesOr0(C, BitCast(d, idx_v1C));\n+  const V v2L = TableLookupBytesOr0(A, BitCast(d, idx_v2A));\n+  const V v2M = TableLookupBytesOr0(B, BitCast(d, idx_v2B));\n+  const V v2U = TableLookupBytesOr0(C, BitCast(d, idx_v2C));\n   v0 = Xor3(v0L, v0M, v0U);\n   v1 = Xor3(v1L, v1M, v1U);\n   v2 = Xor3(v2L, v2M, v2U);\n@@ -1234,16 +1246,16 @@ HWY_API void StoreInterleaved3(VFromD<D> v0, VFromD<D> v1, VFromD<D> v2, D d,\n   // v0[5], v2[4],v1[4],v0[4] .. v2[0],v1[0],v0[0]. We're expanding v0 lanes\n   // to their place, with 0x80 so lanes to be filled from other vectors are 0\n   // to enable blending by ORing together.\n-  alignas(16) static constexpr uint8_t tbl_v0[16] = {\n-      0, 0x80, 0x80, 1, 0x80, 0x80, 2, 0x80, 0x80,  //\n-      3, 0x80, 0x80, 4, 0x80, 0x80, 5};\n-  alignas(16) static constexpr uint8_t tbl_v1[16] = {\n-      0x80, 0, 0x80, 0x80, 1, 0x80,  //\n-      0x80, 2, 0x80, 0x80, 3, 0x80, 0x80, 4, 0x80, 0x80};\n+  const VFromD<decltype(du)> shuf_A0 =\n+      Dup128VecFromValues(du, 0, 0x80, 0x80, 1, 0x80, 0x80, 2, 0x80, 0x80, 3,\n+                          0x80, 0x80, 4, 0x80, 0x80, 5);\n+  // Cannot reuse shuf_A0 because it contains 5.\n+  const VFromD<decltype(du)> shuf_A1 =\n+      Dup128VecFromValues(du, 0x80, 0, 0x80, 0x80, 1, 0x80, 0x80, 2, 0x80, 0x80,\n+                          3, 0x80, 0x80, 4, 0x80, 0x80);\n   // The interleaved vectors will be named A, B, C; temporaries with suffix\n   // 0..2 indicate which input vector's lanes they hold.\n-  const auto shuf_A0 = LoadDup128(du, tbl_v0);\n-  const auto shuf_A1 = LoadDup128(du, tbl_v1);  // cannot reuse shuf_A0 (has 5)\n+  // cannot reuse shuf_A0 (has 5)\n   const auto shuf_A2 = CombineShiftRightBytes<15>(du, shuf_A1, shuf_A1);\n   const auto A0 = TableLookupBytesOr0(v0, shuf_A0);  // 5..4..3..2..1..0\n   const auto A1 = TableLookupBytesOr0(v1, shuf_A1);  // ..4..3..2..1..0.\n@@ -1283,19 +1295,16 @@ HWY_API void StoreInterleaved3(VFromD<D> v0, VFromD<D> v1, VFromD<D> v2, D d,\n   // v1[2],v0[2], v2[1],v1[1],v0[1], v2[0],v1[0],v0[0]. 0x80 so lanes to be\n   // filled from other vectors are 0 for blending. Note that these are byte\n   // indices for 16-bit lanes.\n-  alignas(16) static constexpr uint8_t tbl_v1[16] = {\n-      0x80, 0x80, 0,    1,    0x80, 0x80, 0x80, 0x80,\n-      2,    3,    0x80, 0x80, 0x80, 0x80, 4,    5};\n-  alignas(16) static constexpr uint8_t tbl_v2[16] = {\n-      0x80, 0x80, 0x80, 0x80, 0,    1,    0x80, 0x80,\n-      0x80, 0x80, 2,    3,    0x80, 0x80, 0x80, 0x80};\n+  const VFromD<decltype(du8)> shuf_A1 =\n+      Dup128VecFromValues(du8, 0x80, 0x80, 0, 1, 0x80, 0x80, 0x80, 0x80, 2, 3,\n+                          0x80, 0x80, 0x80, 0x80, 4, 5);\n+  const VFromD<decltype(du8)> shuf_A2 =\n+      Dup128VecFromValues(du8, 0x80, 0x80, 0x80, 0x80, 0, 1, 0x80, 0x80, 0x80,\n+                          0x80, 2, 3, 0x80, 0x80, 0x80, 0x80);\n \n   // The interleaved vectors will be named A, B, C; temporaries with suffix\n   // 0..2 indicate which input vector's lanes they hold.\n-  const auto shuf_A1 = LoadDup128(du8, tbl_v1);  // 2..1..0.\n-                                                 // .2..1..0\n   const auto shuf_A0 = CombineShiftRightBytes<2>(du8, shuf_A1, shuf_A1);\n-  const auto shuf_A2 = LoadDup128(du8, tbl_v2);  // ..1..0..\n \n   const auto A0 = TableLookupBytesOr0(v0, shuf_A0);\n   const auto A1 = TableLookupBytesOr0(v1, shuf_A1);\n@@ -3250,30 +3259,29 @@ HWY_INLINE V SubBytesMulInverseAndAffineLookup(V state, V affine_tblL,\n \n   // Change polynomial basis to GF(2^4)\n   {\n-    alignas(16) static constexpr uint8_t basisL[16] = {\n-        0x00, 0x70, 0x2A, 0x5A, 0x98, 0xE8, 0xB2, 0xC2,\n-        0x08, 0x78, 0x22, 0x52, 0x90, 0xE0, 0xBA, 0xCA};\n-    alignas(16) static constexpr uint8_t basisU[16] = {\n-        0x00, 0x4D, 0x7C, 0x31, 0x7D, 0x30, 0x01, 0x4C,\n-        0x81, 0xCC, 0xFD, 0xB0, 0xFC, 0xB1, 0x80, 0xCD};\n+    const VFromD<decltype(du)> basisL =\n+        Dup128VecFromValues(du, 0x00, 0x70, 0x2A, 0x5A, 0x98, 0xE8, 0xB2, 0xC2,\n+                            0x08, 0x78, 0x22, 0x52, 0x90, 0xE0, 0xBA, 0xCA);\n+    const VFromD<decltype(du)> basisU =\n+        Dup128VecFromValues(du, 0x00, 0x4D, 0x7C, 0x31, 0x7D, 0x30, 0x01, 0x4C,\n+                            0x81, 0xCC, 0xFD, 0xB0, 0xFC, 0xB1, 0x80, 0xCD);\n     const auto sL = And(state, mask);\n     const auto sU = ShiftRight<4>(state);  // byte shift => upper bits are zero\n-    const auto gf4L = TableLookupBytes(LoadDup128(du, basisL), sL);\n-    const auto gf4U = TableLookupBytes(LoadDup128(du, basisU), sU);\n+    const auto gf4L = TableLookupBytes(basisL, sL);\n+    const auto gf4U = TableLookupBytes(basisU, sU);\n     state = Xor(gf4L, gf4U);\n   }\n \n   // Inversion in GF(2^4). Elements 0 represent \"infinity\" (division by 0) and\n   // cause TableLookupBytesOr0 to return 0.\n-  alignas(16) static constexpr uint8_t kZetaInv[16] = {\n-      0x80, 7, 11, 15, 6, 10, 4, 1, 9, 8, 5, 2, 12, 14, 13, 3};\n-  alignas(16) static constexpr uint8_t kInv[16] = {\n-      0x80, 1, 8, 13, 15, 6, 5, 14, 2, 12, 11, 10, 9, 3, 7, 4};\n-  const auto tbl = LoadDup128(du, kInv);\n+  const VFromD<decltype(du)> zetaInv = Dup128VecFromValues(\n+      du, 0x80, 7, 11, 15, 6, 10, 4, 1, 9, 8, 5, 2, 12, 14, 13, 3);\n+  const VFromD<decltype(du)> tbl = Dup128VecFromValues(\n+      du, 0x80, 1, 8, 13, 15, 6, 5, 14, 2, 12, 11, 10, 9, 3, 7, 4);\n   const auto sL = And(state, mask);      // L=low nibble, U=upper\n   const auto sU = ShiftRight<4>(state);  // byte shift => upper bits are zero\n   const auto sX = Xor(sU, sL);\n-  const auto invL = TableLookupBytes(LoadDup128(du, kZetaInv), sL);\n+  const auto invL = TableLookupBytes(zetaInv, sL);\n   const auto invU = TableLookupBytes(tbl, sU);\n   const auto invX = TableLookupBytes(tbl, sX);\n   const auto outL = Xor(sX, TableLookupBytesOr0(tbl, Xor(invL, invU)));\n@@ -3289,26 +3297,25 @@ HWY_INLINE V SubBytes(V state) {\n   const DFromV<V> du;\n   // Linear skew (cannot bake 0x63 bias into the table because out* indices\n   // may have the infinity flag set).\n-  alignas(16) static constexpr uint8_t kAffineL[16] = {\n-      0x00, 0xC7, 0xBD, 0x6F, 0x17, 0x6D, 0xD2, 0xD0,\n-      0x78, 0xA8, 0x02, 0xC5, 0x7A, 0xBF, 0xAA, 0x15};\n-  alignas(16) static constexpr uint8_t kAffineU[16] = {\n-      0x00, 0x6A, 0xBB, 0x5F, 0xA5, 0x74, 0xE4, 0xCF,\n-      0xFA, 0x35, 0x2B, 0x41, 0xD1, 0x90, 0x1E, 0x8E};\n-  return Xor(SubBytesMulInverseAndAffineLookup(state, LoadDup128(du, kAffineL),\n-                                               LoadDup128(du, kAffineU)),\n+  const VFromD<decltype(du)> affineL =\n+      Dup128VecFromValues(du, 0x00, 0xC7, 0xBD, 0x6F, 0x17, 0x6D, 0xD2, 0xD0,\n+                          0x78, 0xA8, 0x02, 0xC5, 0x7A, 0xBF, 0xAA, 0x15);\n+  const VFromD<decltype(du)> affineU =\n+      Dup128VecFromValues(du, 0x00, 0x6A, 0xBB, 0x5F, 0xA5, 0x74, 0xE4, 0xCF,\n+                          0xFA, 0x35, 0x2B, 0x41, 0xD1, 0x90, 0x1E, 0x8E);\n+  return Xor(SubBytesMulInverseAndAffineLookup(state, affineL, affineU),\n              Set(du, uint8_t{0x63}));\n }\n \n template <class V>  // u8\n HWY_INLINE V InvSubBytes(V state) {\n   const DFromV<V> du;\n-  alignas(16) static constexpr uint8_t kGF2P4InvToGF2P8InvL[16]{\n-      0x00, 0x40, 0xF9, 0x7E, 0x53, 0xEA, 0x87, 0x13,\n-      0x2D, 0x3E, 0x94, 0xD4, 0xB9, 0x6D, 0xAA, 0xC7};\n-  alignas(16) static constexpr uint8_t kGF2P4InvToGF2P8InvU[16]{\n-      0x00, 0x1D, 0x44, 0x93, 0x0F, 0x56, 0xD7, 0x12,\n-      0x9C, 0x8E, 0xC5, 0xD8, 0x59, 0x81, 0x4B, 0xCA};\n+  const VFromD<decltype(du)> gF2P4InvToGF2P8InvL =\n+      Dup128VecFromValues(du, 0x00, 0x40, 0xF9, 0x7E, 0x53, 0xEA, 0x87, 0x13,\n+                          0x2D, 0x3E, 0x94, 0xD4, 0xB9, 0x6D, 0xAA, 0xC7);\n+  const VFromD<decltype(du)> gF2P4InvToGF2P8InvU =\n+      Dup128VecFromValues(du, 0x00, 0x1D, 0x44, 0x93, 0x0F, 0x56, 0xD7, 0x12,\n+                          0x9C, 0x8E, 0xC5, 0xD8, 0x59, 0x81, 0x4B, 0xCA);\n \n   // Apply the inverse affine transformation\n   const auto b = Xor(Xor3(Or(ShiftLeft<1>(state), ShiftRight<7>(state)),\n@@ -3322,9 +3329,8 @@ HWY_INLINE V InvSubBytes(V state) {\n   // - Converting the GF(2^4) multiplicative inverse to the GF(2^8)\n   //   multiplicative inverse through table lookups using the\n   //   kGF2P4InvToGF2P8InvL and kGF2P4InvToGF2P8InvU tables\n-  return SubBytesMulInverseAndAffineLookup(\n-      b, LoadDup128(du, kGF2P4InvToGF2P8InvL),\n-      LoadDup128(du, kGF2P4InvToGF2P8InvU));\n+  return SubBytesMulInverseAndAffineLookup(b, gF2P4InvToGF2P8InvL,\n+                                           gF2P4InvToGF2P8InvU);\n }\n \n }  // namespace detail\n@@ -3346,24 +3352,18 @@ namespace detail {\n template <class V>  // u8\n HWY_INLINE V ShiftRows(const V state) {\n   const DFromV<V> du;\n-  alignas(16) static constexpr uint8_t kShiftRow[16] = {\n-      0,  5,  10, 15,  // transposed: state is column major\n-      4,  9,  14, 3,   //\n-      8,  13, 2,  7,   //\n-      12, 1,  6,  11};\n-  const auto shift_row = LoadDup128(du, kShiftRow);\n+  // transposed: state is column major\n+  const VFromD<decltype(du)> shift_row = Dup128VecFromValues(\n+      du, 0, 5, 10, 15, 4, 9, 14, 3, 8, 13, 2, 7, 12, 1, 6, 11);\n   return TableLookupBytes(state, shift_row);\n }\n \n template <class V>  // u8\n HWY_INLINE V InvShiftRows(const V state) {\n   const DFromV<V> du;\n-  alignas(16) static constexpr uint8_t kShiftRow[16] = {\n-      0,  13, 10, 7,   // transposed: state is column major\n-      4,  1,  14, 11,  //\n-      8,  5,  2,  15,  //\n-      12, 9,  6,  3};\n-  const auto shift_row = LoadDup128(du, kShiftRow);\n+  // transposed: state is column major\n+  const VFromD<decltype(du)> shift_row = Dup128VecFromValues(\n+      du, 0, 13, 10, 7, 4, 1, 14, 11, 8, 5, 2, 15, 12, 9, 6, 3);\n   return TableLookupBytes(state, shift_row);\n }\n \n@@ -3384,15 +3384,15 @@ HWY_INLINE V MixColumns(const V state) {\n   // 1 2 3 1  // d are on diagonal, no permutation needed.\n   // 1 1 2 3  // t1230 indicates column indices of threes for the 4 rows.\n   // 3 1 1 2  // We also need to compute s2301 and s3012 (=1230 o 2301).\n-  alignas(16) static constexpr uint8_t k2301[16] = {\n-      2, 3, 0, 1, 6, 7, 4, 5, 10, 11, 8, 9, 14, 15, 12, 13};\n-  alignas(16) static constexpr uint8_t k1230[16] = {\n-      1, 2, 3, 0, 5, 6, 7, 4, 9, 10, 11, 8, 13, 14, 15, 12};\n+  const VFromD<decltype(du)> v2301 = Dup128VecFromValues(\n+      du, 2, 3, 0, 1, 6, 7, 4, 5, 10, 11, 8, 9, 14, 15, 12, 13);\n+  const VFromD<decltype(du)> v1230 = Dup128VecFromValues(\n+      du, 1, 2, 3, 0, 5, 6, 7, 4, 9, 10, 11, 8, 13, 14, 15, 12);\n   const auto d = GF2P8Mod11BMulBy2(state);  // = state*2 in GF(2^8).\n-  const auto s2301 = TableLookupBytes(state, LoadDup128(du, k2301));\n+  const auto s2301 = TableLookupBytes(state, v2301);\n   const auto d_s2301 = Xor(d, s2301);\n   const auto t_s2301 = Xor(state, d_s2301);  // t(s*3) = XOR-sum {s, d(s*2)}\n-  const auto t1230_s3012 = TableLookupBytes(t_s2301, LoadDup128(du, k1230));\n+  const auto t1230_s3012 = TableLookupBytes(t_s2301, v1230);\n   return Xor(d_s2301, t1230_s3012);  // XOR-sum of 4 terms\n }\n \n@@ -3404,11 +3404,10 @@ HWY_INLINE V InvMixColumns(const V state) {\n   //  9 14 11 13\n   // 13  9 14 11\n   // 11 13  9 14\n-  alignas(16) static constexpr uint8_t k2301[16] = {\n-      2, 3, 0, 1, 6, 7, 4, 5, 10, 11, 8, 9, 14, 15, 12, 13};\n-  alignas(16) static constexpr uint8_t k1230[16] = {\n-      1, 2, 3, 0, 5, 6, 7, 4, 9, 10, 11, 8, 13, 14, 15, 12};\n-  const auto v1230 = LoadDup128(du, k1230);\n+  const VFromD<decltype(du)> v2301 = Dup128VecFromValues(\n+      du, 2, 3, 0, 1, 6, 7, 4, 5, 10, 11, 8, 9, 14, 15, 12, 13);\n+  const VFromD<decltype(du)> v1230 = Dup128VecFromValues(\n+      du, 1, 2, 3, 0, 5, 6, 7, 4, 9, 10, 11, 8, 13, 14, 15, 12);\n \n   const auto sx2 = GF2P8Mod11BMulBy2(state); /* = state*2 in GF(2^8) */\n   const auto sx4 = GF2P8Mod11BMulBy2(sx2);   /* = state*4 in GF(2^8) */\n@@ -3420,8 +3419,7 @@ HWY_INLINE V InvMixColumns(const V state) {\n \n   const auto sx13_0123_sx9_1230 = Xor(sx13, TableLookupBytes(sx9, v1230));\n   const auto sx14_0123_sx11_1230 = Xor(sx14, TableLookupBytes(sx11, v1230));\n-  const auto sx13_2301_sx9_3012 =\n-      TableLookupBytes(sx13_0123_sx9_1230, LoadDup128(du, k2301));\n+  const auto sx13_2301_sx9_3012 = TableLookupBytes(sx13_0123_sx9_1230, v2301);\n   return Xor(sx14_0123_sx11_1230, sx13_2301_sx9_3012);\n }\n \n@@ -3472,15 +3470,15 @@ HWY_API V AESLastRoundInv(V state, const V round_key) {\n \n template <uint8_t kRcon, class V, HWY_IF_U8_D(DFromV<V>)>\n HWY_API V AESKeyGenAssist(V v) {\n-  alignas(16) static constexpr uint8_t kRconXorMask[16] = {\n-      0, 0, 0, 0, kRcon, 0, 0, 0, 0, 0, 0, 0, kRcon, 0, 0, 0};\n-  alignas(16) static constexpr uint8_t kRotWordShuffle[16] = {\n-      4, 5, 6, 7, 5, 6, 7, 4, 12, 13, 14, 15, 13, 14, 15, 12};\n   const DFromV<decltype(v)> d;\n+  const V rconXorMask = Dup128VecFromValues(d, 0, 0, 0, 0, kRcon, 0, 0, 0, 0, 0,\n+                                            0, 0, kRcon, 0, 0, 0);\n+  const V rotWordShuffle = Dup128VecFromValues(d, 4, 5, 6, 7, 5, 6, 7, 4, 12,\n+                                               13, 14, 15, 13, 14, 15, 12);\n   const auto sub_word_result = detail::SubBytes(v);\n   const auto rot_word_result =\n-      TableLookupBytes(sub_word_result, LoadDup128(d, kRotWordShuffle));\n-  return Xor(rot_word_result, LoadDup128(d, kRconXorMask));\n+      TableLookupBytes(sub_word_result, rotWordShuffle);\n+  return Xor(rot_word_result, rconXorMask);\n }\n \n // Constant-time implementation inspired by\n@@ -3570,12 +3568,10 @@ template <class V, class D = DFromV<V>, HWY_IF_U8_D(D),\n           HWY_IF_V_SIZE_GT_D(D, 8), HWY_IF_POPCNT(D)>\n HWY_API V PopulationCount(V v) {\n   const D d;\n-  HWY_ALIGN constexpr uint8_t kLookup[16] = {\n-      0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4,\n-  };\n+  const V lookup =\n+      Dup128VecFromValues(d, 0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4);\n   const auto lo = And(v, Set(d, uint8_t{0xF}));\n   const auto hi = ShiftRight<4>(v);\n-  const auto lookup = LoadDup128(d, kLookup);\n   return Add(TableLookupBytes(lookup, hi), TableLookupBytes(lookup, lo));\n }\n \n@@ -4868,9 +4864,9 @@ HWY_API VFromD<D> Reverse2(D d, VFromD<D> v) {\n   const Repartition<uint16_t, decltype(d)> du16;\n   return BitCast(d, RotateRight<8>(BitCast(du16, v)));\n #else\n-  alignas(16) static constexpr TFromD<D> kShuffle[16] = {\n-      1, 0, 3, 2, 5, 4, 7, 6, 9, 8, 11, 10, 13, 12, 15, 14};\n-  return TableLookupBytes(v, LoadDup128(d, kShuffle));\n+  const VFromD<D> shuffle = Dup128VecFromValues(d, 1, 0, 3, 2, 5, 4, 7, 6, 9, 8,\n+                                                11, 10, 13, 12, 15, 14);\n+  return TableLookupBytes(v, shuffle);\n #endif\n }\n \n@@ -4880,10 +4876,10 @@ HWY_API VFromD<D> Reverse4(D d, VFromD<D> v) {\n   const Repartition<uint16_t, decltype(d)> du16;\n   return BitCast(d, Reverse2(du16, BitCast(du16, Reverse2(d, v))));\n #else\n-  alignas(16) static constexpr uint8_t kShuffle[16] = {\n-      3, 2, 1, 0, 7, 6, 5, 4, 11, 10, 9, 8, 15, 14, 13, 12};\n   const Repartition<uint8_t, decltype(d)> du8;\n-  return TableLookupBytes(v, BitCast(d, LoadDup128(du8, kShuffle)));\n+  const VFromD<decltype(du8)> shuffle = Dup128VecFromValues(\n+      du8, 3, 2, 1, 0, 7, 6, 5, 4, 11, 10, 9, 8, 15, 14, 13, 12);\n+  return TableLookupBytes(v, BitCast(d, shuffle));\n #endif\n }\n \n@@ -4893,10 +4889,10 @@ HWY_API VFromD<D> Reverse8(D d, VFromD<D> v) {\n   const Repartition<uint32_t, D> du32;\n   return BitCast(d, Reverse2(du32, BitCast(du32, Reverse4(d, v))));\n #else\n-  alignas(16) static constexpr uint8_t kShuffle[16] = {\n-      7, 6, 5, 4, 3, 2, 1, 0, 15, 14, 13, 12, 11, 10, 9, 8};\n   const Repartition<uint8_t, decltype(d)> du8;\n-  return TableLookupBytes(v, BitCast(d, LoadDup128(du8, kShuffle)));\n+  const VFromD<decltype(du8)> shuffle = Dup128VecFromValues(\n+      du8, 7, 6, 5, 4, 3, 2, 1, 0, 15, 14, 13, 12, 11, 10, 9, 8);\n+  return TableLookupBytes(v, BitCast(d, shuffle));\n #endif\n }\n \n@@ -5032,8 +5028,6 @@ HWY_INLINE Vec<D> Per4LaneBlkShufDupSet4xU32(D d, const uint32_t x3,\n                                              const uint32_t x2,\n                                              const uint32_t x1,\n                                              const uint32_t x0) {\n-  alignas(16) const uint32_t lanes[4] = {x0, x1, x2, x3};\n-\n #if HWY_TARGET == HWY_RVV\n   constexpr int kPow2 = d.Pow2();\n   constexpr int kLoadPow2 = HWY_MAX(kPow2, -1);\n@@ -5049,8 +5043,7 @@ HWY_INLINE Vec<D> Per4LaneBlkShufDupSet4xU32(D d, const uint32_t x3,\n       HWY_MAX(kMaxBytes / sizeof(uint32_t), kMinLanesToLoad);\n   const CappedTag<uint32_t, kNumToLoad> d_load;\n #endif\n-\n-  return ResizeBitCast(d, LoadDup128(d_load, lanes));\n+  return ResizeBitCast(d, Dup128VecFromValues(d_load, x0, x1, x2, x3));\n }\n \n }  // namespace detail\n@@ -5212,19 +5205,16 @@ HWY_INLINE VFromD<D> TblLookupPer4LaneBlkIdxInBlk(D d, const uint32_t idx3,\n   const uint16_t u16_idx1 = static_cast<uint16_t>(idx1);\n   const uint16_t u16_idx2 = static_cast<uint16_t>(idx2);\n   const uint16_t u16_idx3 = static_cast<uint16_t>(idx3);\n-  alignas(16)\n-      const uint16_t indices[8] = {u16_idx0, u16_idx1, u16_idx2, u16_idx3,\n-                                   u16_idx0, u16_idx1, u16_idx2, u16_idx3};\n-\n #if HWY_TARGET == HWY_NEON || HWY_TARGET == HWY_NEON_WITHOUT_AES\n   constexpr size_t kMinLanesToLoad = 4;\n #else\n   constexpr size_t kMinLanesToLoad = 8;\n #endif\n   constexpr size_t kNumToLoad = HWY_MAX(HWY_MAX_LANES_D(D), kMinLanesToLoad);\n   const CappedTag<uint16_t, kNumToLoad> d_load;\n-\n-  return ResizeBitCast(d, LoadDup128(d_load, indices));\n+  return ResizeBitCast(\n+      d, Dup128VecFromValues(d_load, u16_idx0, u16_idx1, u16_idx2, u16_idx3,\n+                             u16_idx0, u16_idx1, u16_idx2, u16_idx3));\n }\n \n template <class D, HWY_IF_T_SIZE_D(D, 4)>\n--- hwy/ops/x86_128-inl.h\n@@ -6481,9 +6481,9 @@ HWY_API VFromD<D> Reverse(D d, const VFromD<D> v) {\n   return BitCast(d, VU{_mm_shuffle_epi32(rev4.raw, _MM_SHUFFLE(1, 0, 3, 2))});\n #else\n   const RebindToSigned<decltype(d)> di;\n-  alignas(16) static constexpr int16_t kShuffle[8] = {\n-      0x0F0E, 0x0D0C, 0x0B0A, 0x0908, 0x0706, 0x0504, 0x0302, 0x0100};\n-  return BitCast(d, TableLookupBytes(v, LoadDup128(di, kShuffle)));\n+  const VFromD<decltype(di)> shuffle = Dup128VecFromValues(\n+      di, 0x0F0E, 0x0D0C, 0x0B0A, 0x0908, 0x0706, 0x0504, 0x0302, 0x0100);\n+  return BitCast(d, TableLookupBytes(v, shuffle));\n #endif\n }\n \n@@ -6532,9 +6532,9 @@ HWY_API VFromD<D> Reverse2(D d, VFromD<D> v) {\n   return BitCast(d, VU{shuf_result});\n #else\n   const RebindToSigned<decltype(d)> di;\n-  alignas(16) static constexpr int16_t kShuffle[8] = {\n-      0x0302, 0x0100, 0x0706, 0x0504, 0x0B0A, 0x0908, 0x0F0E, 0x0D0C};\n-  return BitCast(d, TableLookupBytes(v, LoadDup128(di, kShuffle)));\n+  const VFromD<decltype(di)> shuffle = Dup128VecFromValues(\n+      di, 0x0302, 0x0100, 0x0706, 0x0504, 0x0B0A, 0x0908, 0x0F0E, 0x0D0C);\n+  return BitCast(d, TableLookupBytes(v, shuffle));\n #endif\n }\n \n@@ -6569,9 +6569,9 @@ HWY_API VFromD<D> Reverse4(D d, VFromD<D> v) {\n                         _MM_SHUFFLE(0, 1, 2, 3))});\n #else\n   const RebindToSigned<decltype(d)> di;\n-  alignas(16) static constexpr int16_t kShuffle[8] = {\n-      0x0706, 0x0504, 0x0302, 0x0100, 0x0F0E, 0x0D0C, 0x0B0A, 0x0908};\n-  return BitCast(d, TableLookupBytes(v, LoadDup128(di, kShuffle)));\n+  const VFromD<decltype(di)> shuffle = Dup128VecFromValues(\n+      di, 0x0706, 0x0504, 0x0302, 0x0100, 0x0F0E, 0x0D0C, 0x0B0A, 0x0908);\n+  return BitCast(d, TableLookupBytes(v, shuffle));\n #endif\n }\n \n@@ -6595,9 +6595,9 @@ HWY_API VFromD<D> Reverse8(D d, const VFromD<D> v) {\n   return Reverse2(d, BitCast(d, Shuffle0123(BitCast(dw, v))));\n #else\n   const RebindToSigned<decltype(d)> di;\n-  alignas(16) static constexpr int16_t kShuffle[8] = {\n-      0x0F0E, 0x0D0C, 0x0B0A, 0x0908, 0x0706, 0x0504, 0x0302, 0x0100};\n-  return BitCast(d, TableLookupBytes(v, LoadDup128(di, kShuffle)));\n+  const VFromD<decltype(di)> shuffle = Dup128VecFromValues(\n+      di, 0x0F0E, 0x0D0C, 0x0B0A, 0x0908, 0x0706, 0x0504, 0x0302, 0x0100);\n+  return BitCast(d, TableLookupBytes(v, shuffle));\n #endif\n }\n \n@@ -7603,9 +7603,9 @@ HWY_API V DupEven(V v) {\n \n #if HWY_TARGET <= HWY_SSSE3\n   const RebindToUnsigned<decltype(d)> du;\n-  alignas(16) static constexpr uint8_t kShuffle[16] = {\n-      0, 0, 2, 2, 4, 4, 6, 6, 8, 8, 10, 10, 12, 12, 14, 14};\n-  return TableLookupBytes(v, BitCast(d, LoadDup128(du, kShuffle)));\n+  const VFromD<decltype(du)> shuffle = Dup128VecFromValues(\n+      du, 0, 0, 2, 2, 4, 4, 6, 6, 8, 8, 10, 10, 12, 12, 14, 14);\n+  return TableLookupBytes(v, BitCast(d, shuffle));\n #else\n   const Repartition<uint16_t, decltype(d)> du16;\n   return IfVecThenElse(BitCast(d, Set(du16, uint16_t{0xFF00})),\n@@ -7627,9 +7627,9 @@ HWY_API V DupEven(const V v) {\n   const DFromV<decltype(v)> d;\n   const RebindToUnsigned<decltype(d)> du;  // for float16_t\n #if HWY_TARGET <= HWY_SSSE3\n-  alignas(16) static constexpr uint16_t kShuffle[8] = {\n-      0x0100, 0x0100, 0x0504, 0x0504, 0x0908, 0x0908, 0x0d0c, 0x0d0c};\n-  return TableLookupBytes(v, BitCast(d, LoadDup128(du, kShuffle)));\n+  const VFromD<decltype(du)> shuffle = Dup128VecFromValues(\n+      du, 0x0100, 0x0100, 0x0504, 0x0504, 0x0908, 0x0908, 0x0d0c, 0x0d0c);\n+  return TableLookupBytes(v, BitCast(d, shuffle));\n #else\n   return BitCast(\n       d, VFromD<decltype(du)>{_mm_shufflehi_epi16(\n@@ -7660,9 +7660,9 @@ HWY_API V DupOdd(V v) {\n \n #if HWY_TARGET <= HWY_SSSE3\n   const RebindToUnsigned<decltype(d)> du;\n-  alignas(16) static constexpr uint8_t kShuffle[16] = {\n-      1, 1, 3, 3, 5, 5, 7, 7, 9, 9, 11, 11, 13, 13, 15, 15};\n-  return TableLookupBytes(v, BitCast(d, LoadDup128(du, kShuffle)));\n+  const VFromD<decltype(du)> shuffle = Dup128VecFromValues(\n+      du, 1, 1, 3, 3, 5, 5, 7, 7, 9, 9, 11, 11, 13, 13, 15, 15);\n+  return TableLookupBytes(v, BitCast(d, shuffle));\n #else\n   const Repartition<uint16_t, decltype(d)> du16;\n   return IfVecThenElse(BitCast(d, Set(du16, uint16_t{0x00FF})),\n@@ -7684,9 +7684,9 @@ HWY_API V DupOdd(V v) {\n   const DFromV<decltype(v)> d;\n   const RebindToUnsigned<decltype(d)> du;  // for float16_t\n #if HWY_TARGET <= HWY_SSSE3\n-  alignas(16) static constexpr uint16_t kShuffle[8] = {\n-      0x0302, 0x0302, 0x0706, 0x0706, 0x0b0a, 0x0b0a, 0x0f0e, 0x0f0e};\n-  return TableLookupBytes(v, BitCast(d, LoadDup128(du, kShuffle)));\n+  const VFromD<decltype(du)> shuffle = Dup128VecFromValues(\n+      du, 0x0302, 0x0302, 0x0706, 0x0706, 0x0b0a, 0x0b0a, 0x0f0e, 0x0f0e);\n+  return TableLookupBytes(v, BitCast(d, shuffle));\n #else\n   return BitCast(\n       d, VFromD<decltype(du)>{_mm_shufflehi_epi16(\n@@ -10546,10 +10546,9 @@ HWY_INLINE MFromD<D> LoadMaskBits128(D d, uint64_t mask_bits) {\n                                                     1, 1, 1, 1, 1, 1, 1, 1};\n   const auto rep8 = TableLookupBytes(vbits, Load(du, kRep8));\n #endif\n-\n-  alignas(16) static constexpr uint8_t kBit[16] = {1, 2, 4, 8, 16, 32, 64, 128,\n-                                                   1, 2, 4, 8, 16, 32, 64, 128};\n-  return RebindMask(d, TestBit(rep8, LoadDup128(du, kBit)));\n+  const VFromD<decltype(du)> bit = Dup128VecFromValues(\n+      du, 1, 2, 4, 8, 16, 32, 64, 128, 1, 2, 4, 8, 16, 32, 64, 128);\n+  return RebindMask(d, TestBit(rep8, bit));\n }\n \n template <class D, HWY_IF_T_SIZE_D(D, 2)>\n--- hwy/ops/x86_256-inl.h\n@@ -4524,9 +4524,9 @@ HWY_API VFromD<D> Reverse(D d, const VFromD<D> v) {\n                         _mm256_permutexvar_epi16(idx.raw, BitCast(di, v).raw)});\n #else\n   const RebindToSigned<decltype(d)> di;\n-  alignas(16) static constexpr int16_t kShuffle[8] = {\n-      0x0F0E, 0x0D0C, 0x0B0A, 0x0908, 0x0706, 0x0504, 0x0302, 0x0100};\n-  const auto rev128 = TableLookupBytes(v, LoadDup128(di, kShuffle));\n+  const VFromD<decltype(di)> shuffle = Dup128VecFromValues(\n+      di, 0x0F0E, 0x0D0C, 0x0B0A, 0x0908, 0x0706, 0x0504, 0x0302, 0x0100);\n+  const auto rev128 = TableLookupBytes(v, shuffle);\n   return VFromD<D>{\n       _mm256_permute4x64_epi64(rev128.raw, _MM_SHUFFLE(1, 0, 3, 2))};\n #endif\n@@ -4555,9 +4555,9 @@ HWY_API VFromD<D> Reverse(D d, const VFromD<D> v) {\n template <class D, HWY_IF_V_SIZE_D(D, 32), HWY_IF_T_SIZE_D(D, 2)>\n HWY_API VFromD<D> Reverse4(D d, const VFromD<D> v) {\n   const RebindToSigned<decltype(d)> di;\n-  alignas(16) static constexpr int16_t kShuffle[8] = {\n-      0x0706, 0x0504, 0x0302, 0x0100, 0x0F0E, 0x0D0C, 0x0B0A, 0x0908};\n-  return BitCast(d, TableLookupBytes(v, LoadDup128(di, kShuffle)));\n+  const VFromD<decltype(di)> shuffle = Dup128VecFromValues(\n+      di, 0x0706, 0x0504, 0x0302, 0x0100, 0x0F0E, 0x0D0C, 0x0B0A, 0x0908);\n+  return BitCast(d, TableLookupBytes(v, shuffle));\n }\n \n // 32 bit Reverse4 defined in x86_128.\n@@ -4573,9 +4573,9 @@ HWY_API VFromD<D> Reverse4(D /* tag */, const VFromD<D> v) {\n template <class D, HWY_IF_V_SIZE_D(D, 32), HWY_IF_T_SIZE_D(D, 2)>\n HWY_API VFromD<D> Reverse8(D d, const VFromD<D> v) {\n   const RebindToSigned<decltype(d)> di;\n-  alignas(16) static constexpr int16_t kShuffle[8] = {\n-      0x0F0E, 0x0D0C, 0x0B0A, 0x0908, 0x0706, 0x0504, 0x0302, 0x0100};\n-  return BitCast(d, TableLookupBytes(v, LoadDup128(di, kShuffle)));\n+  const VFromD<decltype(di)> shuffle = Dup128VecFromValues(\n+      di, 0x0F0E, 0x0D0C, 0x0B0A, 0x0908, 0x0706, 0x0504, 0x0302, 0x0100);\n+  return BitCast(d, TableLookupBytes(v, shuffle));\n }\n \n template <class D, HWY_IF_V_SIZE_D(D, 32), HWY_IF_T_SIZE_D(D, 4)>\n@@ -5112,9 +5112,10 @@ template <typename T, HWY_IF_T_SIZE(T, 1)>\n HWY_INLINE Vec256<T> OddEven(Vec256<T> a, Vec256<T> b) {\n   const DFromV<decltype(a)> d;\n   const Full256<uint8_t> d8;\n-  alignas(32) static constexpr uint8_t mask[16] = {\n-      0xFF, 0, 0xFF, 0, 0xFF, 0, 0xFF, 0, 0xFF, 0, 0xFF, 0, 0xFF, 0, 0xFF, 0};\n-  return IfThenElse(MaskFromVec(BitCast(d, LoadDup128(d8, mask))), b, a);\n+  const VFromD<decltype(d8)> mask =\n+      Dup128VecFromValues(d8, 0xFF, 0, 0xFF, 0, 0xFF, 0, 0xFF, 0, 0xFF, 0, 0xFF,\n+                          0, 0xFF, 0, 0xFF, 0);\n+  return IfThenElse(MaskFromVec(BitCast(d, mask)), b, a);\n }\n \n template <typename T, HWY_IF_UI16(T)>\n@@ -5736,14 +5737,15 @@ HWY_API Vec256<uint8_t> Shl(hwy::UnsignedTag tag, Vec256<uint8_t> v,\n   const DFromV<decltype(v)> d;\n #if HWY_TARGET <= HWY_AVX3_DL\n   (void)tag;\n-  // kMask[i] = 0xFF >> i\n-  alignas(16) static constexpr uint8_t kMasks[16] = {\n-      0xFF, 0x7F, 0x3F, 0x1F, 0x0F, 0x07, 0x03, 0x01, 0x00};\n+  // masks[i] = 0xFF >> i\n+  const VFromD<decltype(d)> masks =\n+      Dup128VecFromValues(d, 0xFF, 0x7F, 0x3F, 0x1F, 0x0F, 0x07, 0x03, 0x01, 0,\n+                          0, 0, 0, 0, 0, 0, 0);\n   // kShl[i] = 1 << i\n-  alignas(16) static constexpr uint8_t kShl[16] = {1,    2,    4,    8,   0x10,\n-                                                   0x20, 0x40, 0x80, 0x00};\n-  v = And(v, TableLookupBytes(LoadDup128(d, kMasks), bits));\n-  const VFromD<decltype(d)> mul = TableLookupBytes(LoadDup128(d, kShl), bits);\n+  const VFromD<decltype(d)> shl = Dup128VecFromValues(\n+      d, 1, 2, 4, 8, 0x10, 0x20, 0x40, 0x80, 0, 0, 0, 0, 0, 0, 0, 0);\n+  v = And(v, TableLookupBytes(masks, bits));\n+  const VFromD<decltype(d)> mul = TableLookupBytes(shl, bits);\n   return VFromD<decltype(d)>{_mm256_gf2p8mul_epi8(v.raw, mul.raw)};\n #else\n   const Repartition<uint16_t, decltype(d)> dw;\n@@ -6752,14 +6754,14 @@ template <uint8_t kRcon>\n HWY_API Vec256<uint8_t> AESKeyGenAssist(Vec256<uint8_t> v) {\n   const Full256<uint8_t> d;\n #if HWY_TARGET <= HWY_AVX3_DL\n-  alignas(16) static constexpr uint8_t kRconXorMask[16] = {\n-      0, kRcon, 0, 0, 0, 0, 0, 0, 0, kRcon, 0, 0, 0, 0, 0, 0};\n-  alignas(16) static constexpr uint8_t kRotWordShuffle[16] = {\n-      0, 13, 10, 7, 1, 14, 11, 4, 8, 5, 2, 15, 9, 6, 3, 12};\n+  const VFromD<decltype(d)> rconXorMask = Dup128VecFromValues(\n+      d, 0, kRcon, 0, 0, 0, 0, 0, 0, 0, kRcon, 0, 0, 0, 0, 0, 0);\n+  const VFromD<decltype(d)> rotWordShuffle = Dup128VecFromValues(\n+      d, 0, 13, 10, 7, 1, 14, 11, 4, 8, 5, 2, 15, 9, 6, 3, 12);\n   const Repartition<uint32_t, decltype(d)> du32;\n   const auto w13 = BitCast(d, DupOdd(BitCast(du32, v)));\n-  const auto sub_word_result = AESLastRound(w13, LoadDup128(d, kRconXorMask));\n-  return TableLookupBytes(sub_word_result, LoadDup128(d, kRotWordShuffle));\n+  const auto sub_word_result = AESLastRound(w13, rconXorMask);\n+  return TableLookupBytes(sub_word_result, rotWordShuffle);\n #else\n   const Half<decltype(d)> d2;\n   return Combine(d, AESKeyGenAssist<kRcon>(UpperHalf(d2, v)),\n@@ -7019,9 +7021,9 @@ HWY_INLINE Mask256<T> LoadMaskBits256(uint64_t mask_bits) {\n       0x0303030303030303ull};\n   const auto rep8 = TableLookupBytes(vbits, BitCast(du, Load(du64, kRep8)));\n \n-  alignas(32) static constexpr uint8_t kBit[16] = {1, 2, 4, 8, 16, 32, 64, 128,\n-                                                   1, 2, 4, 8, 16, 32, 64, 128};\n-  return RebindMask(d, TestBit(rep8, LoadDup128(du, kBit)));\n+  const VFromD<decltype(du)> bit = Dup128VecFromValues(\n+      du, 1, 2, 4, 8, 16, 32, 64, 128, 1, 2, 4, 8, 16, 32, 64, 128);\n+  return RebindMask(d, TestBit(rep8, bit));\n }\n \n template <typename T, HWY_IF_T_SIZE(T, 2)>\n--- hwy/ops/x86_512-inl.h\n@@ -5350,8 +5350,7 @@ HWY_API VFromD<D> DemoteTo(D /* tag */, Vec512<int32_t> v) {\n   const Vec512<int16_t> i16{_mm512_packs_epi32(v.raw, v.raw)};\n   const Vec512<uint8_t> u8{_mm512_packus_epi16(i16.raw, i16.raw)};\n \n-  alignas(16) static constexpr uint32_t kLanes[4] = {0, 4, 8, 12};\n-  const auto idx32 = LoadDup128(du32, kLanes);\n+  const VFromD<decltype(du32)> idx32 = Dup128VecFromValues(du32, 0, 4, 8, 12);\n   const Vec512<uint8_t> fixed{_mm512_permutexvar_epi32(idx32.raw, u8.raw)};\n   return LowerHalf(LowerHalf(fixed));\n }\n@@ -5386,9 +5385,7 @@ HWY_API VFromD<D> DemoteTo(D /* tag */, Vec512<int32_t> v) {\n   const Vec512<int16_t> i16{_mm512_packs_epi32(v.raw, v.raw)};\n   const Vec512<int8_t> i8{_mm512_packs_epi16(i16.raw, i16.raw)};\n \n-  alignas(16) static constexpr uint32_t kLanes[16] = {0, 4, 8, 12, 0, 4, 8, 12,\n-                                                      0, 4, 8, 12, 0, 4, 8, 12};\n-  const auto idx32 = LoadDup128(du32, kLanes);\n+  const VFromD<decltype(du32)> idx32 = Dup128VecFromValues(du32, 0, 4, 8, 12);\n   const Vec512<int8_t> fixed{_mm512_permutexvar_epi32(idx32.raw, i8.raw)};\n   return LowerHalf(LowerHalf(fixed));\n }\n@@ -5587,13 +5584,12 @@ HWY_API Vec128<uint8_t> U8FromU32(const Vec512<uint32_t> v) {\n   const DFromV<decltype(v)> d32;\n   // In each 128 bit block, gather the lower byte of 4 uint32_t lanes into the\n   // lowest 4 bytes.\n-  alignas(16) static constexpr uint32_t k8From32[4] = {0x0C080400u, ~0u, ~0u,\n-                                                       ~0u};\n-  const auto quads = TableLookupBytes(v, LoadDup128(d32, k8From32));\n+  const VFromD<decltype(d32)> v8From32 =\n+      Dup128VecFromValues(d32, 0x0C080400u, ~0u, ~0u, ~0u);\n+  const auto quads = TableLookupBytes(v, v8From32);\n   // Gather the lowest 4 bytes of 4 128-bit blocks.\n-  alignas(16) static constexpr uint32_t kIndex32[4] = {0, 4, 8, 12};\n-  const Vec512<uint8_t> bytes{\n-      _mm512_permutexvar_epi32(LoadDup128(d32, kIndex32).raw, quads.raw)};\n+  const VFromD<decltype(d32)> index32 = Dup128VecFromValues(d32, 0, 4, 8, 12);\n+  const Vec512<uint8_t> bytes{_mm512_permutexvar_epi32(index32.raw, quads.raw)};\n   return LowerHalf(LowerHalf(bytes));\n }\n \n@@ -5604,10 +5600,9 @@ HWY_API VFromD<D> TruncateTo(D d, const Vec512<uint64_t> v) {\n #if HWY_TARGET <= HWY_AVX3_DL\n   (void)d;\n   const Full512<uint8_t> d8;\n-  alignas(16) static constexpr uint8_t k8From64[16] = {\n-      0, 8, 16, 24, 32, 40, 48, 56, 0, 8, 16, 24, 32, 40, 48, 56};\n-  const Vec512<uint8_t> bytes{\n-      _mm512_permutexvar_epi8(LoadDup128(d8, k8From64).raw, v.raw)};\n+  const VFromD<decltype(d8)> v8From64 = Dup128VecFromValues(\n+      d8, 0, 8, 16, 24, 32, 40, 48, 56, 0, 8, 16, 24, 32, 40, 48, 56);\n+  const Vec512<uint8_t> bytes{_mm512_permutexvar_epi8(v8From64.raw, v.raw)};\n   return LowerHalf(LowerHalf(LowerHalf(bytes)));\n #else\n   const Full512<uint32_t> d32;\n@@ -5643,21 +5638,19 @@ template <class D, HWY_IF_V_SIZE_D(D, 16), HWY_IF_U8_D(D)>\n HWY_API VFromD<D> TruncateTo(D /* tag */, const Vec512<uint32_t> v) {\n #if HWY_TARGET <= HWY_AVX3_DL\n   const Full512<uint8_t> d8;\n-  alignas(16) static constexpr uint8_t k8From32[16] = {\n-      0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60};\n-  const Vec512<uint8_t> bytes{\n-      _mm512_permutexvar_epi8(LoadDup128(d8, k8From32).raw, v.raw)};\n+  const VFromD<decltype(d8)> v8From32 = Dup128VecFromValues(\n+      d8, 0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60);\n+  const Vec512<uint8_t> bytes{_mm512_permutexvar_epi8(v8From32.raw, v.raw)};\n #else\n   const Full512<uint32_t> d32;\n   // In each 128 bit block, gather the lower byte of 4 uint32_t lanes into the\n   // lowest 4 bytes.\n-  alignas(16) static constexpr uint32_t k8From32[4] = {0x0C080400u, ~0u, ~0u,\n-                                                       ~0u};\n-  const auto quads = TableLookupBytes(v, LoadDup128(d32, k8From32));\n+  const VFromD<decltype(d32)> v8From32 =\n+      Dup128VecFromValues(d32, 0x0C080400u, ~0u, ~0u, ~0u);\n+  const auto quads = TableLookupBytes(v, v8From32);\n   // Gather the lowest 4 bytes of 4 128-bit blocks.\n-  alignas(16) static constexpr uint32_t kIndex32[4] = {0, 4, 8, 12};\n-  const Vec512<uint8_t> bytes{\n-      _mm512_permutexvar_epi32(LoadDup128(d32, kIndex32).raw, quads.raw)};\n+  const VFromD<decltype(d32)> index32 = Dup128VecFromValues(d32, 0, 4, 8, 12);\n+  const Vec512<uint8_t> bytes{_mm512_permutexvar_epi32(index32.raw, quads.raw)};\n #endif\n   return LowerHalf(LowerHalf(bytes));\n }\n@@ -5686,9 +5679,9 @@ HWY_API VFromD<D> TruncateTo(D /* tag */, const Vec512<uint16_t> v) {\n       _mm512_permutexvar_epi8(Load(d8, k8From16).raw, v.raw)};\n #else\n   const Full512<uint32_t> d32;\n-  alignas(16) static constexpr uint32_t k16From32[4] = {\n-      0x06040200u, 0x0E0C0A08u, 0x06040200u, 0x0E0C0A08u};\n-  const auto quads = TableLookupBytes(v, LoadDup128(d32, k16From32));\n+  const VFromD<decltype(d32)> v16From32 = Dup128VecFromValues(\n+      d32, 0x06040200u, 0x0E0C0A08u, 0x06040200u, 0x0E0C0A08u);\n+  const auto quads = TableLookupBytes(v, v16From32);\n   alignas(64) static constexpr uint32_t kIndex32[16] = {\n       0, 1, 4, 5, 8, 9, 12, 13, 0, 1, 4, 5, 8, 9, 12, 13};\n   const Vec512<uint8_t> bytes{\n@@ -5821,14 +5814,14 @@ template <uint8_t kRcon>\n HWY_API Vec512<uint8_t> AESKeyGenAssist(Vec512<uint8_t> v) {\n   const Full512<uint8_t> d;\n #if HWY_TARGET <= HWY_AVX3_DL\n-  alignas(16) static constexpr uint8_t kRconXorMask[16] = {\n-      0, kRcon, 0, 0, 0, 0, 0, 0, 0, kRcon, 0, 0, 0, 0, 0, 0};\n-  alignas(16) static constexpr uint8_t kRotWordShuffle[16] = {\n-      0, 13, 10, 7, 1, 14, 11, 4, 8, 5, 2, 15, 9, 6, 3, 12};\n+  const VFromD<decltype(d)> rconXorMask = Dup128VecFromValues(\n+      d, 0, kRcon, 0, 0, 0, 0, 0, 0, 0, kRcon, 0, 0, 0, 0, 0, 0);\n+  const VFromD<decltype(d)> rotWordShuffle = Dup128VecFromValues(\n+      d, 0, 13, 10, 7, 1, 14, 11, 4, 8, 5, 2, 15, 9, 6, 3, 12);\n   const Repartition<uint32_t, decltype(d)> du32;\n   const auto w13 = BitCast(d, DupOdd(BitCast(du32, v)));\n-  const auto sub_word_result = AESLastRound(w13, LoadDup128(d, kRconXorMask));\n-  return TableLookupBytes(sub_word_result, LoadDup128(d, kRotWordShuffle));\n+  const auto sub_word_result = AESLastRound(w13, rconXorMask);\n+  return TableLookupBytes(sub_word_result, rotWordShuffle);\n #else\n   const Half<decltype(d)> d2;\n   return Combine(d, AESKeyGenAssist<kRcon>(UpperHalf(d2, v)),\n@@ -6990,7 +6983,7 @@ HWY_API Mask512<T> SetOnlyFirst(Mask512<T> mask) {\n       static_cast<typename Mask512<T>::Raw>(detail::AVX3Blsi(mask.raw))};\n }\n \n-// ------------------------------ Shl (LoadDup128)\n+// ------------------------------ Shl (Dup128VecFromValues)\n \n HWY_API Vec512<uint16_t> operator<<(Vec512<uint16_t> v, Vec512<uint16_t> bits) {\n   return Vec512<uint16_t>{_mm512_sllv_epi16(v.raw, bits.raw)};\n@@ -7001,13 +6994,15 @@ HWY_API Vec512<uint8_t> operator<<(Vec512<uint8_t> v, Vec512<uint8_t> bits) {\n   const DFromV<decltype(v)> d;\n #if HWY_TARGET <= HWY_AVX3_DL\n   // kMask[i] = 0xFF >> i\n-  alignas(16) static constexpr uint8_t kMasks[16] = {\n-      0xFF, 0x7F, 0x3F, 0x1F, 0x0F, 0x07, 0x03, 0x01, 0x00};\n+  const VFromD<decltype(d)> masks =\n+      Dup128VecFromValues(d, 0xFF, 0x7F, 0x3F, 0x1F, 0x0F, 0x07, 0x03, 0x01, 0,\n+                          0, 0, 0, 0, 0, 0, 0);\n   // kShl[i] = 1 << i\n-  alignas(16) static constexpr uint8_t kShl[16] = {0x01, 0x02, 0x04, 0x08,\n-                                                   0x10, 0x20, 0x40, 0x80};\n-  v = And(v, TableLookupBytes(LoadDup128(d, kMasks), bits));\n-  const VFromD<decltype(d)> mul = TableLookupBytes(LoadDup128(d, kShl), bits);\n+  const VFromD<decltype(d)> shl =\n+      Dup128VecFromValues(d, 0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 0x40, 0x80, 0,\n+                          0, 0, 0, 0, 0, 0, 0);\n+  v = And(v, TableLookupBytes(masks, bits));\n+  const VFromD<decltype(d)> mul = TableLookupBytes(shl, bits);\n   return VFromD<decltype(d)>{_mm512_gf2p8mul_epi8(v.raw, mul.raw)};\n #else\n   const Repartition<uint16_t, decltype(d)> dw;"
    ],
    "files_changed": [
      {
        "filename": "hwy/ops/generic_ops-inl.h",
        "status": "modified",
        "additions": 164,
        "deletions": 174,
        "changes": 338,
        "patch": "@@ -867,40 +867,41 @@ HWY_API void LoadInterleaved3(D d, const TFromD<D>* HWY_RESTRICT unaligned,\n                               VFromD<D>& v0, VFromD<D>& v1, VFromD<D>& v2) {\n   const RebindToUnsigned<decltype(d)> du;\n   using V = VFromD<D>;\n+  using VU = VFromD<decltype(du)>;\n   // Compact notation so these fit on one line: 12 := v1[2].\n   V A;  // 05 24 14 04 23 13 03 22 12 02 21 11 01 20 10 00\n   V B;  // 1a 0a 29 19 09 28 18 08 27 17 07 26 16 06 25 15\n   V C;  // 2f 1f 0f 2e 1e 0e 2d 1d 0d 2c 1c 0c 2b 1b 0b 2a\n   detail::LoadTransposedBlocks3(d, unaligned, A, B, C);\n   // Compress all lanes belonging to v0 into consecutive lanes.\n   constexpr uint8_t Z = 0x80;\n-  alignas(16) static constexpr uint8_t kIdx_v0A[16] = {\n-      0, 3, 6, 9, 12, 15, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v0B[16] = {\n-      Z, Z, Z, Z, Z, Z, 2, 5, 8, 11, 14, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v0C[16] = {\n-      Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, 1, 4, 7, 10, 13};\n-  alignas(16) static constexpr uint8_t kIdx_v1A[16] = {\n-      1, 4, 7, 10, 13, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v1B[16] = {\n-      Z, Z, Z, Z, Z, 0, 3, 6, 9, 12, 15, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v1C[16] = {\n-      Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, 2, 5, 8, 11, 14};\n-  alignas(16) static constexpr uint8_t kIdx_v2A[16] = {\n-      2, 5, 8, 11, 14, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v2B[16] = {\n-      Z, Z, Z, Z, Z, 1, 4, 7, 10, 13, Z, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v2C[16] = {\n-      Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, 0, 3, 6, 9, 12, 15};\n-  const V v0L = BitCast(d, TableLookupBytesOr0(A, LoadDup128(du, kIdx_v0A)));\n-  const V v0M = BitCast(d, TableLookupBytesOr0(B, LoadDup128(du, kIdx_v0B)));\n-  const V v0U = BitCast(d, TableLookupBytesOr0(C, LoadDup128(du, kIdx_v0C)));\n-  const V v1L = BitCast(d, TableLookupBytesOr0(A, LoadDup128(du, kIdx_v1A)));\n-  const V v1M = BitCast(d, TableLookupBytesOr0(B, LoadDup128(du, kIdx_v1B)));\n-  const V v1U = BitCast(d, TableLookupBytesOr0(C, LoadDup128(du, kIdx_v1C)));\n-  const V v2L = BitCast(d, TableLookupBytesOr0(A, LoadDup128(du, kIdx_v2A)));\n-  const V v2M = BitCast(d, TableLookupBytesOr0(B, LoadDup128(du, kIdx_v2B)));\n-  const V v2U = BitCast(d, TableLookupBytesOr0(C, LoadDup128(du, kIdx_v2C)));\n+  const VU idx_v0A =\n+      Dup128VecFromValues(du, 0, 3, 6, 9, 12, 15, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z);\n+  const VU idx_v0B =\n+      Dup128VecFromValues(du, Z, Z, Z, Z, Z, Z, 2, 5, 8, 11, 14, Z, Z, Z, Z, Z);\n+  const VU idx_v0C =\n+      Dup128VecFromValues(du, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, 1, 4, 7, 10, 13);\n+  const VU idx_v1A =\n+      Dup128VecFromValues(du, 1, 4, 7, 10, 13, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z);\n+  const VU idx_v1B =\n+      Dup128VecFromValues(du, Z, Z, Z, Z, Z, 0, 3, 6, 9, 12, 15, Z, Z, Z, Z, Z);\n+  const VU idx_v1C =\n+      Dup128VecFromValues(du, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, 2, 5, 8, 11, 14);\n+  const VU idx_v2A =\n+      Dup128VecFromValues(du, 2, 5, 8, 11, 14, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z);\n+  const VU idx_v2B =\n+      Dup128VecFromValues(du, Z, Z, Z, Z, Z, 1, 4, 7, 10, 13, Z, Z, Z, Z, Z, Z);\n+  const VU idx_v2C =\n+      Dup128VecFromValues(du, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, 0, 3, 6, 9, 12, 15);\n+  const V v0L = BitCast(d, TableLookupBytesOr0(A, idx_v0A));\n+  const V v0M = BitCast(d, TableLookupBytesOr0(B, idx_v0B));\n+  const V v0U = BitCast(d, TableLookupBytesOr0(C, idx_v0C));\n+  const V v1L = BitCast(d, TableLookupBytesOr0(A, idx_v1A));\n+  const V v1M = BitCast(d, TableLookupBytesOr0(B, idx_v1B));\n+  const V v1U = BitCast(d, TableLookupBytesOr0(C, idx_v1C));\n+  const V v2L = BitCast(d, TableLookupBytesOr0(A, idx_v2A));\n+  const V v2M = BitCast(d, TableLookupBytesOr0(B, idx_v2B));\n+  const V v2U = BitCast(d, TableLookupBytesOr0(C, idx_v2C));\n   v0 = Xor3(v0L, v0M, v0U);\n   v1 = Xor3(v1L, v1M, v1U);\n   v2 = Xor3(v2L, v2M, v2U);\n@@ -912,30 +913,40 @@ HWY_API void LoadInterleaved3(D d, const TFromD<D>* HWY_RESTRICT unaligned,\n                               VFromD<D>& v0, VFromD<D>& v1, VFromD<D>& v2) {\n   const RebindToUnsigned<decltype(d)> du;\n   using V = VFromD<D>;\n+  using VU = VFromD<decltype(du)>;\n   V A;  // v1[2] v0[2] v2[1] v1[1] v0[1] v2[0] v1[0] v0[0]\n   V B;  // v0[5] v2[4] v1[4] v0[4] v2[3] v1[3] v0[3] v2[2]\n   V C;  // v2[7] v1[7] v0[7] v2[6] v1[6] v0[6] v2[5] v1[5]\n   detail::LoadTransposedBlocks3(d, unaligned, A, B, C);\n   // Compress all lanes belonging to v0 into consecutive lanes.\n   constexpr uint8_t Z = 0x80;\n-  alignas(16) static constexpr uint8_t kIdx_v0A[16] = {0, 3, 6, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v0B[16] = {Z, Z, Z, 1, 4, 7, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v0C[16] = {Z, Z, Z, Z, Z, Z, 2, 5};\n-  alignas(16) static constexpr uint8_t kIdx_v1A[16] = {1, 4, 7, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v1B[16] = {Z, Z, Z, 2, 5, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v1C[16] = {Z, Z, Z, Z, Z, 0, 3, 6};\n-  alignas(16) static constexpr uint8_t kIdx_v2A[16] = {2, 5, Z, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v2B[16] = {Z, Z, 0, 3, 6, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v2C[16] = {Z, Z, Z, Z, Z, 1, 4, 7};\n-  const V v0L = BitCast(d, TableLookupBytesOr0(A, LoadDup128(du, kIdx_v0A)));\n-  const V v0M = BitCast(d, TableLookupBytesOr0(B, LoadDup128(du, kIdx_v0B)));\n-  const V v0U = BitCast(d, TableLookupBytesOr0(C, LoadDup128(du, kIdx_v0C)));\n-  const V v1L = BitCast(d, TableLookupBytesOr0(A, LoadDup128(du, kIdx_v1A)));\n-  const V v1M = BitCast(d, TableLookupBytesOr0(B, LoadDup128(du, kIdx_v1B)));\n-  const V v1U = BitCast(d, TableLookupBytesOr0(C, LoadDup128(du, kIdx_v1C)));\n-  const V v2L = BitCast(d, TableLookupBytesOr0(A, LoadDup128(du, kIdx_v2A)));\n-  const V v2M = BitCast(d, TableLookupBytesOr0(B, LoadDup128(du, kIdx_v2B)));\n-  const V v2U = BitCast(d, TableLookupBytesOr0(C, LoadDup128(du, kIdx_v2C)));\n+  const VU idx_v0A =\n+      Dup128VecFromValues(du, 0, 3, 6, Z, Z, Z, Z, Z, 0, 0, 0, 0, 0, 0, 0, 0);\n+  const VU idx_v0B =\n+      Dup128VecFromValues(du, Z, Z, Z, 1, 4, 7, Z, Z, 0, 0, 0, 0, 0, 0, 0, 0);\n+  const VU idx_v0C =\n+      Dup128VecFromValues(du, Z, Z, Z, Z, Z, Z, 2, 5, 0, 0, 0, 0, 0, 0, 0, 0);\n+  const VU idx_v1A =\n+      Dup128VecFromValues(du, 1, 4, 7, Z, Z, Z, Z, Z, 0, 0, 0, 0, 0, 0, 0, 0);\n+  const VU idx_v1B =\n+      Dup128VecFromValues(du, Z, Z, Z, 2, 5, Z, Z, Z, 0, 0, 0, 0, 0, 0, 0, 0);\n+  const VU idx_v1C =\n+      Dup128VecFromValues(du, Z, Z, Z, Z, Z, 0, 3, 6, 0, 0, 0, 0, 0, 0, 0, 0);\n+  const VU idx_v2A =\n+      Dup128VecFromValues(du, 2, 5, Z, Z, Z, Z, Z, Z, 0, 0, 0, 0, 0, 0, 0, 0);\n+  const VU idx_v2B =\n+      Dup128VecFromValues(du, Z, Z, 0, 3, 6, Z, Z, Z, 0, 0, 0, 0, 0, 0, 0, 0);\n+  const VU idx_v2C =\n+      Dup128VecFromValues(du, Z, Z, Z, Z, Z, 1, 4, 7, 0, 0, 0, 0, 0, 0, 0, 0);\n+  const V v0L = BitCast(d, TableLookupBytesOr0(A, idx_v0A));\n+  const V v0M = BitCast(d, TableLookupBytesOr0(B, idx_v0B));\n+  const V v0U = BitCast(d, TableLookupBytesOr0(C, idx_v0C));\n+  const V v1L = BitCast(d, TableLookupBytesOr0(A, idx_v1A));\n+  const V v1M = BitCast(d, TableLookupBytesOr0(B, idx_v1B));\n+  const V v1U = BitCast(d, TableLookupBytesOr0(C, idx_v1C));\n+  const V v2L = BitCast(d, TableLookupBytesOr0(A, idx_v2A));\n+  const V v2M = BitCast(d, TableLookupBytesOr0(B, idx_v2B));\n+  const V v2U = BitCast(d, TableLookupBytesOr0(C, idx_v2C));\n   v0 = Xor3(v0L, v0M, v0U);\n   v1 = Xor3(v1L, v1M, v1U);\n   v2 = Xor3(v2L, v2M, v2U);\n@@ -948,40 +959,41 @@ HWY_API void LoadInterleaved3(D d, const TFromD<D>* HWY_RESTRICT unaligned,\n   const RebindToUnsigned<decltype(d)> du;\n   const Repartition<uint8_t, decltype(du)> du8;\n   using V = VFromD<D>;\n+  using VU8 = VFromD<decltype(du8)>;\n   V A;  // v1[2] v0[2] v2[1] v1[1] v0[1] v2[0] v1[0] v0[0]\n   V B;  // v0[5] v2[4] v1[4] v0[4] v2[3] v1[3] v0[3] v2[2]\n   V C;  // v2[7] v1[7] v0[7] v2[6] v1[6] v0[6] v2[5] v1[5]\n   detail::LoadTransposedBlocks3(d, unaligned, A, B, C);\n   // Compress all lanes belonging to v0 into consecutive lanes. Same as above,\n   // but each element of the array contains a byte index for a byte of a lane.\n   constexpr uint8_t Z = 0x80;\n-  alignas(16) static constexpr uint8_t kIdx_v0A[16] = {\n-      0x00, 0x01, 0x06, 0x07, 0x0C, 0x0D, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v0B[16] = {\n-      Z, Z, Z, Z, Z, Z, 0x02, 0x03, 0x08, 0x09, 0x0E, 0x0F, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v0C[16] = {\n-      Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, 0x04, 0x05, 0x0A, 0x0B};\n-  alignas(16) static constexpr uint8_t kIdx_v1A[16] = {\n-      0x02, 0x03, 0x08, 0x09, 0x0E, 0x0F, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v1B[16] = {\n-      Z, Z, Z, Z, Z, Z, 0x04, 0x05, 0x0A, 0x0B, Z, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v1C[16] = {\n-      Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, 0x00, 0x01, 0x06, 0x07, 0x0C, 0x0D};\n-  alignas(16) static constexpr uint8_t kIdx_v2A[16] = {\n-      0x04, 0x05, 0x0A, 0x0B, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v2B[16] = {\n-      Z, Z, Z, Z, 0x00, 0x01, 0x06, 0x07, 0x0C, 0x0D, Z, Z, Z, Z, Z, Z};\n-  alignas(16) static constexpr uint8_t kIdx_v2C[16] = {\n-      Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, 0x02, 0x03, 0x08, 0x09, 0x0E, 0x0F};\n-  const V v0L = TableLookupBytesOr0(A, BitCast(d, LoadDup128(du8, kIdx_v0A)));\n-  const V v0M = TableLookupBytesOr0(B, BitCast(d, LoadDup128(du8, kIdx_v0B)));\n-  const V v0U = TableLookupBytesOr0(C, BitCast(d, LoadDup128(du8, kIdx_v0C)));\n-  const V v1L = TableLookupBytesOr0(A, BitCast(d, LoadDup128(du8, kIdx_v1A)));\n-  const V v1M = TableLookupBytesOr0(B, BitCast(d, LoadDup128(du8, kIdx_v1B)));\n-  const V v1U = TableLookupBytesOr0(C, BitCast(d, LoadDup128(du8, kIdx_v1C)));\n-  const V v2L = TableLookupBytesOr0(A, BitCast(d, LoadDup128(du8, kIdx_v2A)));\n-  const V v2M = TableLookupBytesOr0(B, BitCast(d, LoadDup128(du8, kIdx_v2B)));\n-  const V v2U = TableLookupBytesOr0(C, BitCast(d, LoadDup128(du8, kIdx_v2C)));\n+  const VU8 idx_v0A = Dup128VecFromValues(du8, 0x00, 0x01, 0x06, 0x07, 0x0C,\n+                                          0x0D, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z);\n+  const VU8 idx_v0B = Dup128VecFromValues(du8, Z, Z, Z, Z, Z, Z, 0x02, 0x03,\n+                                          0x08, 0x09, 0x0E, 0x0F, Z, Z, Z, Z);\n+  const VU8 idx_v0C = Dup128VecFromValues(du8, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z,\n+                                          Z, 0x04, 0x05, 0x0A, 0x0B);\n+  const VU8 idx_v1A = Dup128VecFromValues(du8, 0x02, 0x03, 0x08, 0x09, 0x0E,\n+                                          0x0F, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z);\n+  const VU8 idx_v1B = Dup128VecFromValues(du8, Z, Z, Z, Z, Z, Z, 0x04, 0x05,\n+                                          0x0A, 0x0B, Z, Z, Z, Z, Z, Z);\n+  const VU8 idx_v1C = Dup128VecFromValues(du8, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z,\n+                                          0x00, 0x01, 0x06, 0x07, 0x0C, 0x0D);\n+  const VU8 idx_v2A = Dup128VecFromValues(du8, 0x04, 0x05, 0x0A, 0x0B, Z, Z, Z,\n+                                          Z, Z, Z, Z, Z, Z, Z, Z, Z);\n+  const VU8 idx_v2B = Dup128VecFromValues(du8, Z, Z, Z, Z, 0x00, 0x01, 0x06,\n+                                          0x07, 0x0C, 0x0D, Z, Z, Z, Z, Z, Z);\n+  const VU8 idx_v2C = Dup128VecFromValues(du8, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z,\n+                                          0x02, 0x03, 0x08, 0x09, 0x0E, 0x0F);\n+  const V v0L = TableLookupBytesOr0(A, BitCast(d, idx_v0A));\n+  const V v0M = TableLookupBytesOr0(B, BitCast(d, idx_v0B));\n+  const V v0U = TableLookupBytesOr0(C, BitCast(d, idx_v0C));\n+  const V v1L = TableLookupBytesOr0(A, BitCast(d, idx_v1A));\n+  const V v1M = TableLookupBytesOr0(B, BitCast(d, idx_v1B));\n+  const V v1U = TableLookupBytesOr0(C, BitCast(d, idx_v1C));\n+  const V v2L = TableLookupBytesOr0(A, BitCast(d, idx_v2A));\n+  const V v2M = TableLookupBytesOr0(B, BitCast(d, idx_v2B));\n+  const V v2U = TableLookupBytesOr0(C, BitCast(d, idx_v2C));\n   v0 = Xor3(v0L, v0M, v0U);\n   v1 = Xor3(v1L, v1M, v1U);\n   v2 = Xor3(v2L, v2M, v2U);\n@@ -1234,16 +1246,16 @@ HWY_API void StoreInterleaved3(VFromD<D> v0, VFromD<D> v1, VFromD<D> v2, D d,\n   // v0[5], v2[4],v1[4],v0[4] .. v2[0],v1[0],v0[0]. We're expanding v0 lanes\n   // to their place, with 0x80 so lanes to be filled from other vectors are 0\n   // to enable blending by ORing together.\n-  alignas(16) static constexpr uint8_t tbl_v0[16] = {\n-      0, 0x80, 0x80, 1, 0x80, 0x80, 2, 0x80, 0x80,  //\n-      3, 0x80, 0x80, 4, 0x80, 0x80, 5};\n-  alignas(16) static constexpr uint8_t tbl_v1[16] = {\n-      0x80, 0, 0x80, 0x80, 1, 0x80,  //\n-      0x80, 2, 0x80, 0x80, 3, 0x80, 0x80, 4, 0x80, 0x80};\n+  const VFromD<decltype(du)> shuf_A0 =\n+      Dup128VecFromValues(du, 0, 0x80, 0x80, 1, 0x80, 0x80, 2, 0x80, 0x80, 3,\n+                          0x80, 0x80, 4, 0x80, 0x80, 5);\n+  // Cannot reuse shuf_A0 because it contains 5.\n+  const VFromD<decltype(du)> shuf_A1 =\n+      Dup128VecFromValues(du, 0x80, 0, 0x80, 0x80, 1, 0x80, 0x80, 2, 0x80, 0x80,\n+                          3, 0x80, 0x80, 4, 0x80, 0x80);\n   // The interleaved vectors will be named A, B, C; temporaries with suffix\n   // 0..2 indicate which input vector's lanes they hold.\n-  const auto shuf_A0 = LoadDup128(du, tbl_v0);\n-  const auto shuf_A1 = LoadDup128(du, tbl_v1);  // cannot reuse shuf_A0 (has 5)\n+  // cannot reuse shuf_A0 (has 5)\n   const auto shuf_A2 = CombineShiftRightBytes<15>(du, shuf_A1, shuf_A1);\n   const auto A0 = TableLookupBytesOr0(v0, shuf_A0);  // 5..4..3..2..1..0\n   const auto A1 = TableLookupBytesOr0(v1, shuf_A1);  // ..4..3..2..1..0.\n@@ -1283,19 +1295,16 @@ HWY_API void StoreInterleaved3(VFromD<D> v0, VFromD<D> v1, VFromD<D> v2, D d,\n   // v1[2],v0[2], v2[1],v1[1],v0[1], v2[0],v1[0],v0[0]. 0x80 so lanes to be\n   // filled from other vectors are 0 for blending. Note that these are byte\n   // indices for 16-bit lanes.\n-  alignas(16) static constexpr uint8_t tbl_v1[16] = {\n-      0x80, 0x80, 0,    1,    0x80, 0x80, 0x80, 0x80,\n-      2,    3,    0x80, 0x80, 0x80, 0x80, 4,    5};\n-  alignas(16) static constexpr uint8_t tbl_v2[16] = {\n-      0x80, 0x80, 0x80, 0x80, 0,    1,    0x80, 0x80,\n-      0x80, 0x80, 2,    3,    0x80, 0x80, 0x80, 0x80};\n+  const VFromD<decltype(du8)> shuf_A1 =\n+      Dup128VecFromValues(du8, 0x80, 0x80, 0, 1, 0x80, 0x80, 0x80, 0x80, 2, 3,\n+                          0x80, 0x80, 0x80, 0x80, 4, 5);\n+  const VFromD<decltype(du8)> shuf_A2 =\n+      Dup128VecFromValues(du8, 0x80, 0x80, 0x80, 0x80, 0, 1, 0x80, 0x80, 0x80,\n+                          0x80, 2, 3, 0x80, 0x80, 0x80, 0x80);\n \n   // The interleaved vectors will be named A, B, C; temporaries with suffix\n   // 0..2 indicate which input vector's lanes they hold.\n-  const auto shuf_A1 = LoadDup128(du8, tbl_v1);  // 2..1..0.\n-                                                 // .2..1..0\n   const auto shuf_A0 = CombineShiftRightBytes<2>(du8, shuf_A1, shuf_A1);\n-  const auto shuf_A2 = LoadDup128(du8, tbl_v2);  // ..1..0..\n \n   const auto A0 = TableLookupBytesOr0(v0, shuf_A0);\n   const auto A1 = TableLookupBytesOr0(v1, shuf_A1);\n@@ -3250,30 +3259,29 @@ HWY_INLINE V SubBytesMulInverseAndAffineLookup(V state, V affine_tblL,\n \n   // Change polynomial basis to GF(2^4)\n   {\n-    alignas(16) static constexpr uint8_t basisL[16] = {\n-        0x00, 0x70, 0x2A, 0x5A, 0x98, 0xE8, 0xB2, 0xC2,\n-        0x08, 0x78, 0x22, 0x52, 0x90, 0xE0, 0xBA, 0xCA};\n-    alignas(16) static constexpr uint8_t basisU[16] = {\n-        0x00, 0x4D, 0x7C, 0x31, 0x7D, 0x30, 0x01, 0x4C,\n-        0x81, 0xCC, 0xFD, 0xB0, 0xFC, 0xB1, 0x80, 0xCD};\n+    const VFromD<decltype(du)> basisL =\n+        Dup128VecFromValues(du, 0x00, 0x70, 0x2A, 0x5A, 0x98, 0xE8, 0xB2, 0xC2,\n+                            0x08, 0x78, 0x22, 0x52, 0x90, 0xE0, 0xBA, 0xCA);\n+    const VFromD<decltype(du)> basisU =\n+        Dup128VecFromValues(du, 0x00, 0x4D, 0x7C, 0x31, 0x7D, 0x30, 0x01, 0x4C,\n+                            0x81, 0xCC, 0xFD, 0xB0, 0xFC, 0xB1, 0x80, 0xCD);\n     const auto sL = And(state, mask);\n     const auto sU = ShiftRight<4>(state);  // byte shift => upper bits are zero\n-    const auto gf4L = TableLookupBytes(LoadDup128(du, basisL), sL);\n-    const auto gf4U = TableLookupBytes(LoadDup128(du, basisU), sU);\n+    const auto gf4L = TableLookupBytes(basisL, sL);\n+    const auto gf4U = TableLookupBytes(basisU, sU);\n     state = Xor(gf4L, gf4U);\n   }\n \n   // Inversion in GF(2^4). Elements 0 represent \"infinity\" (division by 0) and\n   // cause TableLookupBytesOr0 to return 0.\n-  alignas(16) static constexpr uint8_t kZetaInv[16] = {\n-      0x80, 7, 11, 15, 6, 10, 4, 1, 9, 8, 5, 2, 12, 14, 13, 3};\n-  alignas(16) static constexpr uint8_t kInv[16] = {\n-      0x80, 1, 8, 13, 15, 6, 5, 14, 2, 12, 11, 10, 9, 3, 7, 4};\n-  const auto tbl = LoadDup128(du, kInv);\n+  const VFromD<decltype(du)> zetaInv = Dup128VecFromValues(\n+      du, 0x80, 7, 11, 15, 6, 10, 4, 1, 9, 8, 5, 2, 12, 14, 13, 3);\n+  const VFromD<decltype(du)> tbl = Dup128VecFromValues(\n+      du, 0x80, 1, 8, 13, 15, 6, 5, 14, 2, 12, 11, 10, 9, 3, 7, 4);\n   const auto sL = And(state, mask);      // L=low nibble, U=upper\n   const auto sU = ShiftRight<4>(state);  // byte shift => upper bits are zero\n   const auto sX = Xor(sU, sL);\n-  const auto invL = TableLookupBytes(LoadDup128(du, kZetaInv), sL);\n+  const auto invL = TableLookupBytes(zetaInv, sL);\n   const auto invU = TableLookupBytes(tbl, sU);\n   const auto invX = TableLookupBytes(tbl, sX);\n   const auto outL = Xor(sX, TableLookupBytesOr0(tbl, Xor(invL, invU)));\n@@ -3289,26 +3297,25 @@ HWY_INLINE V SubBytes(V state) {\n   const DFromV<V> du;\n   // Linear skew (cannot bake 0x63 bias into the table because out* indices\n   // may have the infinity flag set).\n-  alignas(16) static constexpr uint8_t kAffineL[16] = {\n-      0x00, 0xC7, 0xBD, 0x6F, 0x17, 0x6D, 0xD2, 0xD0,\n-      0x78, 0xA8, 0x02, 0xC5, 0x7A, 0xBF, 0xAA, 0x15};\n-  alignas(16) static constexpr uint8_t kAffineU[16] = {\n-      0x00, 0x6A, 0xBB, 0x5F, 0xA5, 0x74, 0xE4, 0xCF,\n-      0xFA, 0x35, 0x2B, 0x41, 0xD1, 0x90, 0x1E, 0x8E};\n-  return Xor(SubBytesMulInverseAndAffineLookup(state, LoadDup128(du, kAffineL),\n-                                               LoadDup128(du, kAffineU)),\n+  const VFromD<decltype(du)> affineL =\n+      Dup128VecFromValues(du, 0x00, 0xC7, 0xBD, 0x6F, 0x17, 0x6D, 0xD2, 0xD0,\n+                          0x78, 0xA8, 0x02, 0xC5, 0x7A, 0xBF, 0xAA, 0x15);\n+  const VFromD<decltype(du)> affineU =\n+      Dup128VecFromValues(du, 0x00, 0x6A, 0xBB, 0x5F, 0xA5, 0x74, 0xE4, 0xCF,\n+                          0xFA, 0x35, 0x2B, 0x41, 0xD1, 0x90, 0x1E, 0x8E);\n+  return Xor(SubBytesMulInverseAndAffineLookup(state, affineL, affineU),\n              Set(du, uint8_t{0x63}));\n }\n \n template <class V>  // u8\n HWY_INLINE V InvSubBytes(V state) {\n   const DFromV<V> du;\n-  alignas(16) static constexpr uint8_t kGF2P4InvToGF2P8InvL[16]{\n-      0x00, 0x40, 0xF9, 0x7E, 0x53, 0xEA, 0x87, 0x13,\n-      0x2D, 0x3E, 0x94, 0xD4, 0xB9, 0x6D, 0xAA, 0xC7};\n-  alignas(16) static constexpr uint8_t kGF2P4InvToGF2P8InvU[16]{\n-      0x00, 0x1D, 0x44, 0x93, 0x0F, 0x56, 0xD7, 0x12,\n-      0x9C, 0x8E, 0xC5, 0xD8, 0x59, 0x81, 0x4B, 0xCA};\n+  const VFromD<decltype(du)> gF2P4InvToGF2P8InvL =\n+      Dup128VecFromValues(du, 0x00, 0x40, 0xF9, 0x7E, 0x53, 0xEA, 0x87, 0x13,\n+                          0x2D, 0x3E, 0x94, 0xD4, 0xB9, 0x6D, 0xAA, 0xC7);\n+  const VFromD<decltype(du)> gF2P4InvToGF2P8InvU =\n+      Dup128VecFromValues(du, 0x00, 0x1D, 0x44, 0x93, 0x0F, 0x56, 0xD7, 0x12,\n+                          0x9C, 0x8E, 0xC5, 0xD8, 0x59, 0x81, 0x4B, 0xCA);\n \n   // Apply the inverse affine transformation\n   const auto b = Xor(Xor3(Or(ShiftLeft<1>(state), ShiftRight<7>(state)),\n@@ -3322,9 +3329,8 @@ HWY_INLINE V InvSubBytes(V state) {\n   // - Converting the GF(2^4) multiplicative inverse to the GF(2^8)\n   //   multiplicative inverse through table lookups using the\n   //   kGF2P4InvToGF2P8InvL and kGF2P4InvToGF2P8InvU tables\n-  return SubBytesMulInverseAndAffineLookup(\n-      b, LoadDup128(du, kGF2P4InvToGF2P8InvL),\n-      LoadDup128(du, kGF2P4InvToGF2P8InvU));\n+  return SubBytesMulInverseAndAffineLookup(b, gF2P4InvToGF2P8InvL,\n+                                           gF2P4InvToGF2P8InvU);\n }\n \n }  // namespace detail\n@@ -3346,24 +3352,18 @@ namespace detail {\n template <class V>  // u8\n HWY_INLINE V ShiftRows(const V state) {\n   const DFromV<V> du;\n-  alignas(16) static constexpr uint8_t kShiftRow[16] = {\n-      0,  5,  10, 15,  // transposed: state is column major\n-      4,  9,  14, 3,   //\n-      8,  13, 2,  7,   //\n-      12, 1,  6,  11};\n-  const auto shift_row = LoadDup128(du, kShiftRow);\n+  // transposed: state is column major\n+  const VFromD<decltype(du)> shift_row = Dup128VecFromValues(\n+      du, 0, 5, 10, 15, 4, 9, 14, 3, 8, 13, 2, 7, 12, 1, 6, 11);\n   return TableLookupBytes(state, shift_row);\n }\n \n template <class V>  // u8\n HWY_INLINE V InvShiftRows(const V state) {\n   const DFromV<V> du;\n-  alignas(16) static constexpr uint8_t kShiftRow[16] = {\n-      0,  13, 10, 7,   // transposed: state is column major\n-      4,  1,  14, 11,  //\n-      8,  5,  2,  15,  //\n-      12, 9,  6,  3};\n-  const auto shift_row = LoadDup128(du, kShiftRow);\n+  // transposed: state is column major\n+  const VFromD<decltype(du)> shift_row = Dup128VecFromValues(\n+      du, 0, 13, 10, 7, 4, 1, 14, 11, 8, 5, 2, 15, 12, 9, 6, 3);\n   return TableLookupBytes(state, shift_row);\n }\n \n@@ -3384,15 +3384,15 @@ HWY_INLINE V MixColumns(const V state) {\n   // 1 2 3 1  // d are on diagonal, no permutation needed.\n   // 1 1 2 3  // t1230 indicates column indices of threes for the 4 rows.\n   // 3 1 1 2  // We also need to compute s2301 and s3012 (=1230 o 2301).\n-  alignas(16) static constexpr uint8_t k2301[16] = {\n-      2, 3, 0, 1, 6, 7, 4, 5, 10, 11, 8, 9, 14, 15, 12, 13};\n-  alignas(16) static constexpr uint8_t k1230[16] = {\n-      1, 2, 3, 0, 5, 6, 7, 4, 9, 10, 11, 8, 13, 14, 15, 12};\n+  const VFromD<decltype(du)> v2301 = Dup128VecFromValues(\n+      du, 2, 3, 0, 1, 6, 7, 4, 5, 10, 11, 8, 9, 14, 15, 12, 13);\n+  const VFromD<decltype(du)> v1230 = Dup128VecFromValues(\n+      du, 1, 2, 3, 0, 5, 6, 7, 4, 9, 10, 11, 8, 13, 14, 15, 12);\n   const auto d = GF2P8Mod11BMulBy2(state);  // = state*2 in GF(2^8).\n-  const auto s2301 = TableLookupBytes(state, LoadDup128(du, k2301));\n+  const auto s2301 = TableLookupBytes(state, v2301);\n   const auto d_s2301 = Xor(d, s2301);\n   const auto t_s2301 = Xor(state, d_s2301);  // t(s*3) = XOR-sum {s, d(s*2)}\n-  const auto t1230_s3012 = TableLookupBytes(t_s2301, LoadDup128(du, k1230));\n+  const auto t1230_s3012 = TableLookupBytes(t_s2301, v1230);\n   return Xor(d_s2301, t1230_s3012);  // XOR-sum of 4 terms\n }\n \n@@ -3404,11 +3404,10 @@ HWY_INLINE V InvMixColumns(const V state) {\n   //  9 14 11 13\n   // 13  9 14 11\n   // 11 13  9 14\n-  alignas(16) static constexpr uint8_t k2301[16] = {\n-      2, 3, 0, 1, 6, 7, 4, 5, 10, 11, 8, 9, 14, 15, 12, 13};\n-  alignas(16) static constexpr uint8_t k1230[16] = {\n-      1, 2, 3, 0, 5, 6, 7, 4, 9, 10, 11, 8, 13, 14, 15, 12};\n-  const auto v1230 = LoadDup128(du, k1230);\n+  const VFromD<decltype(du)> v2301 = Dup128VecFromValues(\n+      du, 2, 3, 0, 1, 6, 7, 4, 5, 10, 11, 8, 9, 14, 15, 12, 13);\n+  const VFromD<decltype(du)> v1230 = Dup128VecFromValues(\n+      du, 1, 2, 3, 0, 5, 6, 7, 4, 9, 10, 11, 8, 13, 14, 15, 12);\n \n   const auto sx2 = GF2P8Mod11BMulBy2(state); /* = state*2 in GF(2^8) */\n   const auto sx4 = GF2P8Mod11BMulBy2(sx2);   /* = state*4 in GF(2^8) */\n@@ -3420,8 +3419,7 @@ HWY_INLINE V InvMixColumns(const V state) {\n \n   const auto sx13_0123_sx9_1230 = Xor(sx13, TableLookupBytes(sx9, v1230));\n   const auto sx14_0123_sx11_1230 = Xor(sx14, TableLookupBytes(sx11, v1230));\n-  const auto sx13_2301_sx9_3012 =\n-      TableLookupBytes(sx13_0123_sx9_1230, LoadDup128(du, k2301));\n+  const auto sx13_2301_sx9_3012 = TableLookupBytes(sx13_0123_sx9_1230, v2301);\n   return Xor(sx14_0123_sx11_1230, sx13_2301_sx9_3012);\n }\n \n@@ -3472,15 +3470,15 @@ HWY_API V AESLastRoundInv(V state, const V round_key) {\n \n template <uint8_t kRcon, class V, HWY_IF_U8_D(DFromV<V>)>\n HWY_API V AESKeyGenAssist(V v) {\n-  alignas(16) static constexpr uint8_t kRconXorMask[16] = {\n-      0, 0, 0, 0, kRcon, 0, 0, 0, 0, 0, 0, 0, kRcon, 0, 0, 0};\n-  alignas(16) static constexpr uint8_t kRotWordShuffle[16] = {\n-      4, 5, 6, 7, 5, 6, 7, 4, 12, 13, 14, 15, 13, 14, 15, 12};\n   const DFromV<decltype(v)> d;\n+  const V rconXorMask = Dup128VecFromValues(d, 0, 0, 0, 0, kRcon, 0, 0, 0, 0, 0,\n+                                            0, 0, kRcon, 0, 0, 0);\n+  const V rotWordShuffle = Dup128VecFromValues(d, 4, 5, 6, 7, 5, 6, 7, 4, 12,\n+                                               13, 14, 15, 13, 14, 15, 12);\n   const auto sub_word_result = detail::SubBytes(v);\n   const auto rot_word_result =\n-      TableLookupBytes(sub_word_result, LoadDup128(d, kRotWordShuffle));\n-  return Xor(rot_word_result, LoadDup128(d, kRconXorMask));\n+      TableLookupBytes(sub_word_result, rotWordShuffle);\n+  return Xor(rot_word_result, rconXorMask);\n }\n \n // Constant-time implementation inspired by\n@@ -3570,12 +3568,10 @@ template <class V, class D = DFromV<V>, HWY_IF_U8_D(D),\n           HWY_IF_V_SIZE_GT_D(D, 8), HWY_IF_POPCNT(D)>\n HWY_API V PopulationCount(V v) {\n   const D d;\n-  HWY_ALIGN constexpr uint8_t kLookup[16] = {\n-      0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4,\n-  };\n+  const V lookup =\n+      Dup128VecFromValues(d, 0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4);\n   const auto lo = And(v, Set(d, uint8_t{0xF}));\n   const auto hi = ShiftRight<4>(v);\n-  const auto lookup = LoadDup128(d, kLookup);\n   return Add(TableLookupBytes(lookup, hi), TableLookupBytes(lookup, lo));\n }\n \n@@ -4868,9 +4864,9 @@ HWY_API VFromD<D> Reverse2(D d, VFromD<D> v) {\n   const Repartition<uint16_t, decltype(d)> du16;\n   return BitCast(d, RotateRight<8>(BitCast(du16, v)));\n #else\n-  alignas(16) static constexpr TFromD<D> kShuffle[16] = {\n-      1, 0, 3, 2, 5, 4, 7, 6, 9, 8, 11, 10, 13, 12, 15, 14};\n-  return TableLookupBytes(v, LoadDup128(d, kShuffle));\n+  const VFromD<D> shuffle = Dup128VecFromValues(d, 1, 0, 3, 2, 5, 4, 7, 6, 9, 8,\n+                                                11, 10, 13, 12, 15, 14);\n+  return TableLookupBytes(v, shuffle);\n #endif\n }\n \n@@ -4880,10 +4876,10 @@ HWY_API VFromD<D> Reverse4(D d, VFromD<D> v) {\n   const Repartition<uint16_t, decltype(d)> du16;\n   return BitCast(d, Reverse2(du16, BitCast(du16, Reverse2(d, v))));\n #else\n-  alignas(16) static constexpr uint8_t kShuffle[16] = {\n-      3, 2, 1, 0, 7, 6, 5, 4, 11, 10, 9, 8, 15, 14, 13, 12};\n   const Repartition<uint8_t, decltype(d)> du8;\n-  return TableLookupBytes(v, BitCast(d, LoadDup128(du8, kShuffle)));\n+  const VFromD<decltype(du8)> shuffle = Dup128VecFromValues(\n+      du8, 3, 2, 1, 0, 7, 6, 5, 4, 11, 10, 9, 8, 15, 14, 13, 12);\n+  return TableLookupBytes(v, BitCast(d, shuffle));\n #endif\n }\n \n@@ -4893,10 +4889,10 @@ HWY_API VFromD<D> Reverse8(D d, VFromD<D> v) {\n   const Repartition<uint32_t, D> du32;\n   return BitCast(d, Reverse2(du32, BitCast(du32, Reverse4(d, v))));\n #else\n-  alignas(16) static constexpr uint8_t kShuffle[16] = {\n-      7, 6, 5, 4, 3, 2, 1, 0, 15, 14, 13, 12, 11, 10, 9, 8};\n   const Repartition<uint8_t, decltype(d)> du8;\n-  return TableLookupBytes(v, BitCast(d, LoadDup128(du8, kShuffle)));\n+  const VFromD<decltype(du8)> shuffle = Dup128VecFromValues(\n+      du8, 7, 6, 5, 4, 3, 2, 1, 0, 15, 14, 13, 12, 11, 10, 9, 8);\n+  return TableLookupBytes(v, BitCast(d, shuffle));\n #endif\n }\n \n@@ -5032,8 +5028,6 @@ HWY_INLINE Vec<D> Per4LaneBlkShufDupSet4xU32(D d, const uint32_t x3,\n                                              const uint32_t x2,\n                                              const uint32_t x1,\n                                              const uint32_t x0) {\n-  alignas(16) const uint32_t lanes[4] = {x0, x1, x2, x3};\n-\n #if HWY_TARGET == HWY_RVV\n   constexpr int kPow2 = d.Pow2();\n   constexpr int kLoadPow2 = HWY_MAX(kPow2, -1);\n@@ -5049,8 +5043,7 @@ HWY_INLINE Vec<D> Per4LaneBlkShufDupSet4xU32(D d, const uint32_t x3,\n       HWY_MAX(kMaxBytes / sizeof(uint32_t), kMinLanesToLoad);\n   const CappedTag<uint32_t, kNumToLoad> d_load;\n #endif\n-\n-  return ResizeBitCast(d, LoadDup128(d_load, lanes));\n+  return ResizeBitCast(d, Dup128VecFromValues(d_load, x0, x1, x2, x3));\n }\n \n }  // namespace detail\n@@ -5212,19 +5205,16 @@ HWY_INLINE VFromD<D> TblLookupPer4LaneBlkIdxInBlk(D d, const uint32_t idx3,\n   const uint16_t u16_idx1 = static_cast<uint16_t>(idx1);\n   const uint16_t u16_idx2 = static_cast<uint16_t>(idx2);\n   const uint16_t u16_idx3 = static_cast<uint16_t>(idx3);\n-  alignas(16)\n-      const uint16_t indices[8] = {u16_idx0, u16_idx1, u16_idx2, u16_idx3,\n-                                   u16_idx0, u16_idx1, u16_idx2, u16_idx3};\n-\n #if HWY_TARGET == HWY_NEON || HWY_TARGET == HWY_NEON_WITHOUT_AES\n   constexpr size_t kMinLanesToLoad = 4;\n #else\n   constexpr size_t kMinLanesToLoad = 8;\n #endif\n   constexpr size_t kNumToLoad = HWY_MAX(HWY_MAX_LANES_D(D), kMinLanesToLoad);\n   const CappedTag<uint16_t, kNumToLoad> d_load;\n-\n-  return ResizeBitCast(d, LoadDup128(d_load, indices));\n+  return ResizeBitCast(\n+      d, Dup128VecFromValues(d_load, u16_idx0, u16_idx1, u16_idx2, u16_idx3,\n+                             u16_idx0, u16_idx1, u16_idx2, u16_idx3));\n }\n \n template <class D, HWY_IF_T_SIZE_D(D, 4)>"
      },
      {
        "filename": "hwy/ops/x86_128-inl.h",
        "status": "modified",
        "additions": 27,
        "deletions": 28,
        "changes": 55,
        "patch": "@@ -6481,9 +6481,9 @@ HWY_API VFromD<D> Reverse(D d, const VFromD<D> v) {\n   return BitCast(d, VU{_mm_shuffle_epi32(rev4.raw, _MM_SHUFFLE(1, 0, 3, 2))});\n #else\n   const RebindToSigned<decltype(d)> di;\n-  alignas(16) static constexpr int16_t kShuffle[8] = {\n-      0x0F0E, 0x0D0C, 0x0B0A, 0x0908, 0x0706, 0x0504, 0x0302, 0x0100};\n-  return BitCast(d, TableLookupBytes(v, LoadDup128(di, kShuffle)));\n+  const VFromD<decltype(di)> shuffle = Dup128VecFromValues(\n+      di, 0x0F0E, 0x0D0C, 0x0B0A, 0x0908, 0x0706, 0x0504, 0x0302, 0x0100);\n+  return BitCast(d, TableLookupBytes(v, shuffle));\n #endif\n }\n \n@@ -6532,9 +6532,9 @@ HWY_API VFromD<D> Reverse2(D d, VFromD<D> v) {\n   return BitCast(d, VU{shuf_result});\n #else\n   const RebindToSigned<decltype(d)> di;\n-  alignas(16) static constexpr int16_t kShuffle[8] = {\n-      0x0302, 0x0100, 0x0706, 0x0504, 0x0B0A, 0x0908, 0x0F0E, 0x0D0C};\n-  return BitCast(d, TableLookupBytes(v, LoadDup128(di, kShuffle)));\n+  const VFromD<decltype(di)> shuffle = Dup128VecFromValues(\n+      di, 0x0302, 0x0100, 0x0706, 0x0504, 0x0B0A, 0x0908, 0x0F0E, 0x0D0C);\n+  return BitCast(d, TableLookupBytes(v, shuffle));\n #endif\n }\n \n@@ -6569,9 +6569,9 @@ HWY_API VFromD<D> Reverse4(D d, VFromD<D> v) {\n                         _MM_SHUFFLE(0, 1, 2, 3))});\n #else\n   const RebindToSigned<decltype(d)> di;\n-  alignas(16) static constexpr int16_t kShuffle[8] = {\n-      0x0706, 0x0504, 0x0302, 0x0100, 0x0F0E, 0x0D0C, 0x0B0A, 0x0908};\n-  return BitCast(d, TableLookupBytes(v, LoadDup128(di, kShuffle)));\n+  const VFromD<decltype(di)> shuffle = Dup128VecFromValues(\n+      di, 0x0706, 0x0504, 0x0302, 0x0100, 0x0F0E, 0x0D0C, 0x0B0A, 0x0908);\n+  return BitCast(d, TableLookupBytes(v, shuffle));\n #endif\n }\n \n@@ -6595,9 +6595,9 @@ HWY_API VFromD<D> Reverse8(D d, const VFromD<D> v) {\n   return Reverse2(d, BitCast(d, Shuffle0123(BitCast(dw, v))));\n #else\n   const RebindToSigned<decltype(d)> di;\n-  alignas(16) static constexpr int16_t kShuffle[8] = {\n-      0x0F0E, 0x0D0C, 0x0B0A, 0x0908, 0x0706, 0x0504, 0x0302, 0x0100};\n-  return BitCast(d, TableLookupBytes(v, LoadDup128(di, kShuffle)));\n+  const VFromD<decltype(di)> shuffle = Dup128VecFromValues(\n+      di, 0x0F0E, 0x0D0C, 0x0B0A, 0x0908, 0x0706, 0x0504, 0x0302, 0x0100);\n+  return BitCast(d, TableLookupBytes(v, shuffle));\n #endif\n }\n \n@@ -7603,9 +7603,9 @@ HWY_API V DupEven(V v) {\n \n #if HWY_TARGET <= HWY_SSSE3\n   const RebindToUnsigned<decltype(d)> du;\n-  alignas(16) static constexpr uint8_t kShuffle[16] = {\n-      0, 0, 2, 2, 4, 4, 6, 6, 8, 8, 10, 10, 12, 12, 14, 14};\n-  return TableLookupBytes(v, BitCast(d, LoadDup128(du, kShuffle)));\n+  const VFromD<decltype(du)> shuffle = Dup128VecFromValues(\n+      du, 0, 0, 2, 2, 4, 4, 6, 6, 8, 8, 10, 10, 12, 12, 14, 14);\n+  return TableLookupBytes(v, BitCast(d, shuffle));\n #else\n   const Repartition<uint16_t, decltype(d)> du16;\n   return IfVecThenElse(BitCast(d, Set(du16, uint16_t{0xFF00})),\n@@ -7627,9 +7627,9 @@ HWY_API V DupEven(const V v) {\n   const DFromV<decltype(v)> d;\n   const RebindToUnsigned<decltype(d)> du;  // for float16_t\n #if HWY_TARGET <= HWY_SSSE3\n-  alignas(16) static constexpr uint16_t kShuffle[8] = {\n-      0x0100, 0x0100, 0x0504, 0x0504, 0x0908, 0x0908, 0x0d0c, 0x0d0c};\n-  return TableLookupBytes(v, BitCast(d, LoadDup128(du, kShuffle)));\n+  const VFromD<decltype(du)> shuffle = Dup128VecFromValues(\n+      du, 0x0100, 0x0100, 0x0504, 0x0504, 0x0908, 0x0908, 0x0d0c, 0x0d0c);\n+  return TableLookupBytes(v, BitCast(d, shuffle));\n #else\n   return BitCast(\n       d, VFromD<decltype(du)>{_mm_shufflehi_epi16(\n@@ -7660,9 +7660,9 @@ HWY_API V DupOdd(V v) {\n \n #if HWY_TARGET <= HWY_SSSE3\n   const RebindToUnsigned<decltype(d)> du;\n-  alignas(16) static constexpr uint8_t kShuffle[16] = {\n-      1, 1, 3, 3, 5, 5, 7, 7, 9, 9, 11, 11, 13, 13, 15, 15};\n-  return TableLookupBytes(v, BitCast(d, LoadDup128(du, kShuffle)));\n+  const VFromD<decltype(du)> shuffle = Dup128VecFromValues(\n+      du, 1, 1, 3, 3, 5, 5, 7, 7, 9, 9, 11, 11, 13, 13, 15, 15);\n+  return TableLookupBytes(v, BitCast(d, shuffle));\n #else\n   const Repartition<uint16_t, decltype(d)> du16;\n   return IfVecThenElse(BitCast(d, Set(du16, uint16_t{0x00FF})),\n@@ -7684,9 +7684,9 @@ HWY_API V DupOdd(V v) {\n   const DFromV<decltype(v)> d;\n   const RebindToUnsigned<decltype(d)> du;  // for float16_t\n #if HWY_TARGET <= HWY_SSSE3\n-  alignas(16) static constexpr uint16_t kShuffle[8] = {\n-      0x0302, 0x0302, 0x0706, 0x0706, 0x0b0a, 0x0b0a, 0x0f0e, 0x0f0e};\n-  return TableLookupBytes(v, BitCast(d, LoadDup128(du, kShuffle)));\n+  const VFromD<decltype(du)> shuffle = Dup128VecFromValues(\n+      du, 0x0302, 0x0302, 0x0706, 0x0706, 0x0b0a, 0x0b0a, 0x0f0e, 0x0f0e);\n+  return TableLookupBytes(v, BitCast(d, shuffle));\n #else\n   return BitCast(\n       d, VFromD<decltype(du)>{_mm_shufflehi_epi16(\n@@ -10546,10 +10546,9 @@ HWY_INLINE MFromD<D> LoadMaskBits128(D d, uint64_t mask_bits) {\n                                                     1, 1, 1, 1, 1, 1, 1, 1};\n   const auto rep8 = TableLookupBytes(vbits, Load(du, kRep8));\n #endif\n-\n-  alignas(16) static constexpr uint8_t kBit[16] = {1, 2, 4, 8, 16, 32, 64, 128,\n-                                                   1, 2, 4, 8, 16, 32, 64, 128};\n-  return RebindMask(d, TestBit(rep8, LoadDup128(du, kBit)));\n+  const VFromD<decltype(du)> bit = Dup128VecFromValues(\n+      du, 1, 2, 4, 8, 16, 32, 64, 128, 1, 2, 4, 8, 16, 32, 64, 128);\n+  return RebindMask(d, TestBit(rep8, bit));\n }\n \n template <class D, HWY_IF_T_SIZE_D(D, 2)>"
      },
      {
        "filename": "hwy/ops/x86_256-inl.h",
        "status": "modified",
        "additions": 30,
        "deletions": 28,
        "changes": 58,
        "patch": "@@ -4524,9 +4524,9 @@ HWY_API VFromD<D> Reverse(D d, const VFromD<D> v) {\n                         _mm256_permutexvar_epi16(idx.raw, BitCast(di, v).raw)});\n #else\n   const RebindToSigned<decltype(d)> di;\n-  alignas(16) static constexpr int16_t kShuffle[8] = {\n-      0x0F0E, 0x0D0C, 0x0B0A, 0x0908, 0x0706, 0x0504, 0x0302, 0x0100};\n-  const auto rev128 = TableLookupBytes(v, LoadDup128(di, kShuffle));\n+  const VFromD<decltype(di)> shuffle = Dup128VecFromValues(\n+      di, 0x0F0E, 0x0D0C, 0x0B0A, 0x0908, 0x0706, 0x0504, 0x0302, 0x0100);\n+  const auto rev128 = TableLookupBytes(v, shuffle);\n   return VFromD<D>{\n       _mm256_permute4x64_epi64(rev128.raw, _MM_SHUFFLE(1, 0, 3, 2))};\n #endif\n@@ -4555,9 +4555,9 @@ HWY_API VFromD<D> Reverse(D d, const VFromD<D> v) {\n template <class D, HWY_IF_V_SIZE_D(D, 32), HWY_IF_T_SIZE_D(D, 2)>\n HWY_API VFromD<D> Reverse4(D d, const VFromD<D> v) {\n   const RebindToSigned<decltype(d)> di;\n-  alignas(16) static constexpr int16_t kShuffle[8] = {\n-      0x0706, 0x0504, 0x0302, 0x0100, 0x0F0E, 0x0D0C, 0x0B0A, 0x0908};\n-  return BitCast(d, TableLookupBytes(v, LoadDup128(di, kShuffle)));\n+  const VFromD<decltype(di)> shuffle = Dup128VecFromValues(\n+      di, 0x0706, 0x0504, 0x0302, 0x0100, 0x0F0E, 0x0D0C, 0x0B0A, 0x0908);\n+  return BitCast(d, TableLookupBytes(v, shuffle));\n }\n \n // 32 bit Reverse4 defined in x86_128.\n@@ -4573,9 +4573,9 @@ HWY_API VFromD<D> Reverse4(D /* tag */, const VFromD<D> v) {\n template <class D, HWY_IF_V_SIZE_D(D, 32), HWY_IF_T_SIZE_D(D, 2)>\n HWY_API VFromD<D> Reverse8(D d, const VFromD<D> v) {\n   const RebindToSigned<decltype(d)> di;\n-  alignas(16) static constexpr int16_t kShuffle[8] = {\n-      0x0F0E, 0x0D0C, 0x0B0A, 0x0908, 0x0706, 0x0504, 0x0302, 0x0100};\n-  return BitCast(d, TableLookupBytes(v, LoadDup128(di, kShuffle)));\n+  const VFromD<decltype(di)> shuffle = Dup128VecFromValues(\n+      di, 0x0F0E, 0x0D0C, 0x0B0A, 0x0908, 0x0706, 0x0504, 0x0302, 0x0100);\n+  return BitCast(d, TableLookupBytes(v, shuffle));\n }\n \n template <class D, HWY_IF_V_SIZE_D(D, 32), HWY_IF_T_SIZE_D(D, 4)>\n@@ -5112,9 +5112,10 @@ template <typename T, HWY_IF_T_SIZE(T, 1)>\n HWY_INLINE Vec256<T> OddEven(Vec256<T> a, Vec256<T> b) {\n   const DFromV<decltype(a)> d;\n   const Full256<uint8_t> d8;\n-  alignas(32) static constexpr uint8_t mask[16] = {\n-      0xFF, 0, 0xFF, 0, 0xFF, 0, 0xFF, 0, 0xFF, 0, 0xFF, 0, 0xFF, 0, 0xFF, 0};\n-  return IfThenElse(MaskFromVec(BitCast(d, LoadDup128(d8, mask))), b, a);\n+  const VFromD<decltype(d8)> mask =\n+      Dup128VecFromValues(d8, 0xFF, 0, 0xFF, 0, 0xFF, 0, 0xFF, 0, 0xFF, 0, 0xFF,\n+                          0, 0xFF, 0, 0xFF, 0);\n+  return IfThenElse(MaskFromVec(BitCast(d, mask)), b, a);\n }\n \n template <typename T, HWY_IF_UI16(T)>\n@@ -5736,14 +5737,15 @@ HWY_API Vec256<uint8_t> Shl(hwy::UnsignedTag tag, Vec256<uint8_t> v,\n   const DFromV<decltype(v)> d;\n #if HWY_TARGET <= HWY_AVX3_DL\n   (void)tag;\n-  // kMask[i] = 0xFF >> i\n-  alignas(16) static constexpr uint8_t kMasks[16] = {\n-      0xFF, 0x7F, 0x3F, 0x1F, 0x0F, 0x07, 0x03, 0x01, 0x00};\n+  // masks[i] = 0xFF >> i\n+  const VFromD<decltype(d)> masks =\n+      Dup128VecFromValues(d, 0xFF, 0x7F, 0x3F, 0x1F, 0x0F, 0x07, 0x03, 0x01, 0,\n+                          0, 0, 0, 0, 0, 0, 0);\n   // kShl[i] = 1 << i\n-  alignas(16) static constexpr uint8_t kShl[16] = {1,    2,    4,    8,   0x10,\n-                                                   0x20, 0x40, 0x80, 0x00};\n-  v = And(v, TableLookupBytes(LoadDup128(d, kMasks), bits));\n-  const VFromD<decltype(d)> mul = TableLookupBytes(LoadDup128(d, kShl), bits);\n+  const VFromD<decltype(d)> shl = Dup128VecFromValues(\n+      d, 1, 2, 4, 8, 0x10, 0x20, 0x40, 0x80, 0, 0, 0, 0, 0, 0, 0, 0);\n+  v = And(v, TableLookupBytes(masks, bits));\n+  const VFromD<decltype(d)> mul = TableLookupBytes(shl, bits);\n   return VFromD<decltype(d)>{_mm256_gf2p8mul_epi8(v.raw, mul.raw)};\n #else\n   const Repartition<uint16_t, decltype(d)> dw;\n@@ -6752,14 +6754,14 @@ template <uint8_t kRcon>\n HWY_API Vec256<uint8_t> AESKeyGenAssist(Vec256<uint8_t> v) {\n   const Full256<uint8_t> d;\n #if HWY_TARGET <= HWY_AVX3_DL\n-  alignas(16) static constexpr uint8_t kRconXorMask[16] = {\n-      0, kRcon, 0, 0, 0, 0, 0, 0, 0, kRcon, 0, 0, 0, 0, 0, 0};\n-  alignas(16) static constexpr uint8_t kRotWordShuffle[16] = {\n-      0, 13, 10, 7, 1, 14, 11, 4, 8, 5, 2, 15, 9, 6, 3, 12};\n+  const VFromD<decltype(d)> rconXorMask = Dup128VecFromValues(\n+      d, 0, kRcon, 0, 0, 0, 0, 0, 0, 0, kRcon, 0, 0, 0, 0, 0, 0);\n+  const VFromD<decltype(d)> rotWordShuffle = Dup128VecFromValues(\n+      d, 0, 13, 10, 7, 1, 14, 11, 4, 8, 5, 2, 15, 9, 6, 3, 12);\n   const Repartition<uint32_t, decltype(d)> du32;\n   const auto w13 = BitCast(d, DupOdd(BitCast(du32, v)));\n-  const auto sub_word_result = AESLastRound(w13, LoadDup128(d, kRconXorMask));\n-  return TableLookupBytes(sub_word_result, LoadDup128(d, kRotWordShuffle));\n+  const auto sub_word_result = AESLastRound(w13, rconXorMask);\n+  return TableLookupBytes(sub_word_result, rotWordShuffle);\n #else\n   const Half<decltype(d)> d2;\n   return Combine(d, AESKeyGenAssist<kRcon>(UpperHalf(d2, v)),\n@@ -7019,9 +7021,9 @@ HWY_INLINE Mask256<T> LoadMaskBits256(uint64_t mask_bits) {\n       0x0303030303030303ull};\n   const auto rep8 = TableLookupBytes(vbits, BitCast(du, Load(du64, kRep8)));\n \n-  alignas(32) static constexpr uint8_t kBit[16] = {1, 2, 4, 8, 16, 32, 64, 128,\n-                                                   1, 2, 4, 8, 16, 32, 64, 128};\n-  return RebindMask(d, TestBit(rep8, LoadDup128(du, kBit)));\n+  const VFromD<decltype(du)> bit = Dup128VecFromValues(\n+      du, 1, 2, 4, 8, 16, 32, 64, 128, 1, 2, 4, 8, 16, 32, 64, 128);\n+  return RebindMask(d, TestBit(rep8, bit));\n }\n \n template <typename T, HWY_IF_T_SIZE(T, 2)>"
      },
      {
        "filename": "hwy/ops/x86_512-inl.h",
        "status": "modified",
        "additions": 36,
        "deletions": 41,
        "changes": 77,
        "patch": "@@ -5350,8 +5350,7 @@ HWY_API VFromD<D> DemoteTo(D /* tag */, Vec512<int32_t> v) {\n   const Vec512<int16_t> i16{_mm512_packs_epi32(v.raw, v.raw)};\n   const Vec512<uint8_t> u8{_mm512_packus_epi16(i16.raw, i16.raw)};\n \n-  alignas(16) static constexpr uint32_t kLanes[4] = {0, 4, 8, 12};\n-  const auto idx32 = LoadDup128(du32, kLanes);\n+  const VFromD<decltype(du32)> idx32 = Dup128VecFromValues(du32, 0, 4, 8, 12);\n   const Vec512<uint8_t> fixed{_mm512_permutexvar_epi32(idx32.raw, u8.raw)};\n   return LowerHalf(LowerHalf(fixed));\n }\n@@ -5386,9 +5385,7 @@ HWY_API VFromD<D> DemoteTo(D /* tag */, Vec512<int32_t> v) {\n   const Vec512<int16_t> i16{_mm512_packs_epi32(v.raw, v.raw)};\n   const Vec512<int8_t> i8{_mm512_packs_epi16(i16.raw, i16.raw)};\n \n-  alignas(16) static constexpr uint32_t kLanes[16] = {0, 4, 8, 12, 0, 4, 8, 12,\n-                                                      0, 4, 8, 12, 0, 4, 8, 12};\n-  const auto idx32 = LoadDup128(du32, kLanes);\n+  const VFromD<decltype(du32)> idx32 = Dup128VecFromValues(du32, 0, 4, 8, 12);\n   const Vec512<int8_t> fixed{_mm512_permutexvar_epi32(idx32.raw, i8.raw)};\n   return LowerHalf(LowerHalf(fixed));\n }\n@@ -5587,13 +5584,12 @@ HWY_API Vec128<uint8_t> U8FromU32(const Vec512<uint32_t> v) {\n   const DFromV<decltype(v)> d32;\n   // In each 128 bit block, gather the lower byte of 4 uint32_t lanes into the\n   // lowest 4 bytes.\n-  alignas(16) static constexpr uint32_t k8From32[4] = {0x0C080400u, ~0u, ~0u,\n-                                                       ~0u};\n-  const auto quads = TableLookupBytes(v, LoadDup128(d32, k8From32));\n+  const VFromD<decltype(d32)> v8From32 =\n+      Dup128VecFromValues(d32, 0x0C080400u, ~0u, ~0u, ~0u);\n+  const auto quads = TableLookupBytes(v, v8From32);\n   // Gather the lowest 4 bytes of 4 128-bit blocks.\n-  alignas(16) static constexpr uint32_t kIndex32[4] = {0, 4, 8, 12};\n-  const Vec512<uint8_t> bytes{\n-      _mm512_permutexvar_epi32(LoadDup128(d32, kIndex32).raw, quads.raw)};\n+  const VFromD<decltype(d32)> index32 = Dup128VecFromValues(d32, 0, 4, 8, 12);\n+  const Vec512<uint8_t> bytes{_mm512_permutexvar_epi32(index32.raw, quads.raw)};\n   return LowerHalf(LowerHalf(bytes));\n }\n \n@@ -5604,10 +5600,9 @@ HWY_API VFromD<D> TruncateTo(D d, const Vec512<uint64_t> v) {\n #if HWY_TARGET <= HWY_AVX3_DL\n   (void)d;\n   const Full512<uint8_t> d8;\n-  alignas(16) static constexpr uint8_t k8From64[16] = {\n-      0, 8, 16, 24, 32, 40, 48, 56, 0, 8, 16, 24, 32, 40, 48, 56};\n-  const Vec512<uint8_t> bytes{\n-      _mm512_permutexvar_epi8(LoadDup128(d8, k8From64).raw, v.raw)};\n+  const VFromD<decltype(d8)> v8From64 = Dup128VecFromValues(\n+      d8, 0, 8, 16, 24, 32, 40, 48, 56, 0, 8, 16, 24, 32, 40, 48, 56);\n+  const Vec512<uint8_t> bytes{_mm512_permutexvar_epi8(v8From64.raw, v.raw)};\n   return LowerHalf(LowerHalf(LowerHalf(bytes)));\n #else\n   const Full512<uint32_t> d32;\n@@ -5643,21 +5638,19 @@ template <class D, HWY_IF_V_SIZE_D(D, 16), HWY_IF_U8_D(D)>\n HWY_API VFromD<D> TruncateTo(D /* tag */, const Vec512<uint32_t> v) {\n #if HWY_TARGET <= HWY_AVX3_DL\n   const Full512<uint8_t> d8;\n-  alignas(16) static constexpr uint8_t k8From32[16] = {\n-      0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60};\n-  const Vec512<uint8_t> bytes{\n-      _mm512_permutexvar_epi8(LoadDup128(d8, k8From32).raw, v.raw)};\n+  const VFromD<decltype(d8)> v8From32 = Dup128VecFromValues(\n+      d8, 0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60);\n+  const Vec512<uint8_t> bytes{_mm512_permutexvar_epi8(v8From32.raw, v.raw)};\n #else\n   const Full512<uint32_t> d32;\n   // In each 128 bit block, gather the lower byte of 4 uint32_t lanes into the\n   // lowest 4 bytes.\n-  alignas(16) static constexpr uint32_t k8From32[4] = {0x0C080400u, ~0u, ~0u,\n-                                                       ~0u};\n-  const auto quads = TableLookupBytes(v, LoadDup128(d32, k8From32));\n+  const VFromD<decltype(d32)> v8From32 =\n+      Dup128VecFromValues(d32, 0x0C080400u, ~0u, ~0u, ~0u);\n+  const auto quads = TableLookupBytes(v, v8From32);\n   // Gather the lowest 4 bytes of 4 128-bit blocks.\n-  alignas(16) static constexpr uint32_t kIndex32[4] = {0, 4, 8, 12};\n-  const Vec512<uint8_t> bytes{\n-      _mm512_permutexvar_epi32(LoadDup128(d32, kIndex32).raw, quads.raw)};\n+  const VFromD<decltype(d32)> index32 = Dup128VecFromValues(d32, 0, 4, 8, 12);\n+  const Vec512<uint8_t> bytes{_mm512_permutexvar_epi32(index32.raw, quads.raw)};\n #endif\n   return LowerHalf(LowerHalf(bytes));\n }\n@@ -5686,9 +5679,9 @@ HWY_API VFromD<D> TruncateTo(D /* tag */, const Vec512<uint16_t> v) {\n       _mm512_permutexvar_epi8(Load(d8, k8From16).raw, v.raw)};\n #else\n   const Full512<uint32_t> d32;\n-  alignas(16) static constexpr uint32_t k16From32[4] = {\n-      0x06040200u, 0x0E0C0A08u, 0x06040200u, 0x0E0C0A08u};\n-  const auto quads = TableLookupBytes(v, LoadDup128(d32, k16From32));\n+  const VFromD<decltype(d32)> v16From32 = Dup128VecFromValues(\n+      d32, 0x06040200u, 0x0E0C0A08u, 0x06040200u, 0x0E0C0A08u);\n+  const auto quads = TableLookupBytes(v, v16From32);\n   alignas(64) static constexpr uint32_t kIndex32[16] = {\n       0, 1, 4, 5, 8, 9, 12, 13, 0, 1, 4, 5, 8, 9, 12, 13};\n   const Vec512<uint8_t> bytes{\n@@ -5821,14 +5814,14 @@ template <uint8_t kRcon>\n HWY_API Vec512<uint8_t> AESKeyGenAssist(Vec512<uint8_t> v) {\n   const Full512<uint8_t> d;\n #if HWY_TARGET <= HWY_AVX3_DL\n-  alignas(16) static constexpr uint8_t kRconXorMask[16] = {\n-      0, kRcon, 0, 0, 0, 0, 0, 0, 0, kRcon, 0, 0, 0, 0, 0, 0};\n-  alignas(16) static constexpr uint8_t kRotWordShuffle[16] = {\n-      0, 13, 10, 7, 1, 14, 11, 4, 8, 5, 2, 15, 9, 6, 3, 12};\n+  const VFromD<decltype(d)> rconXorMask = Dup128VecFromValues(\n+      d, 0, kRcon, 0, 0, 0, 0, 0, 0, 0, kRcon, 0, 0, 0, 0, 0, 0);\n+  const VFromD<decltype(d)> rotWordShuffle = Dup128VecFromValues(\n+      d, 0, 13, 10, 7, 1, 14, 11, 4, 8, 5, 2, 15, 9, 6, 3, 12);\n   const Repartition<uint32_t, decltype(d)> du32;\n   const auto w13 = BitCast(d, DupOdd(BitCast(du32, v)));\n-  const auto sub_word_result = AESLastRound(w13, LoadDup128(d, kRconXorMask));\n-  return TableLookupBytes(sub_word_result, LoadDup128(d, kRotWordShuffle));\n+  const auto sub_word_result = AESLastRound(w13, rconXorMask);\n+  return TableLookupBytes(sub_word_result, rotWordShuffle);\n #else\n   const Half<decltype(d)> d2;\n   return Combine(d, AESKeyGenAssist<kRcon>(UpperHalf(d2, v)),\n@@ -6990,7 +6983,7 @@ HWY_API Mask512<T> SetOnlyFirst(Mask512<T> mask) {\n       static_cast<typename Mask512<T>::Raw>(detail::AVX3Blsi(mask.raw))};\n }\n \n-// ------------------------------ Shl (LoadDup128)\n+// ------------------------------ Shl (Dup128VecFromValues)\n \n HWY_API Vec512<uint16_t> operator<<(Vec512<uint16_t> v, Vec512<uint16_t> bits) {\n   return Vec512<uint16_t>{_mm512_sllv_epi16(v.raw, bits.raw)};\n@@ -7001,13 +6994,15 @@ HWY_API Vec512<uint8_t> operator<<(Vec512<uint8_t> v, Vec512<uint8_t> bits) {\n   const DFromV<decltype(v)> d;\n #if HWY_TARGET <= HWY_AVX3_DL\n   // kMask[i] = 0xFF >> i\n-  alignas(16) static constexpr uint8_t kMasks[16] = {\n-      0xFF, 0x7F, 0x3F, 0x1F, 0x0F, 0x07, 0x03, 0x01, 0x00};\n+  const VFromD<decltype(d)> masks =\n+      Dup128VecFromValues(d, 0xFF, 0x7F, 0x3F, 0x1F, 0x0F, 0x07, 0x03, 0x01, 0,\n+                          0, 0, 0, 0, 0, 0, 0);\n   // kShl[i] = 1 << i\n-  alignas(16) static constexpr uint8_t kShl[16] = {0x01, 0x02, 0x04, 0x08,\n-                                                   0x10, 0x20, 0x40, 0x80};\n-  v = And(v, TableLookupBytes(LoadDup128(d, kMasks), bits));\n-  const VFromD<decltype(d)> mul = TableLookupBytes(LoadDup128(d, kShl), bits);\n+  const VFromD<decltype(d)> shl =\n+      Dup128VecFromValues(d, 0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 0x40, 0x80, 0,\n+                          0, 0, 0, 0, 0, 0, 0);\n+  v = And(v, TableLookupBytes(masks, bits));\n+  const VFromD<decltype(d)> mul = TableLookupBytes(shl, bits);\n   return VFromD<decltype(d)>{_mm512_gf2p8mul_epi8(v.raw, mul.raw)};\n #else\n   const Repartition<uint16_t, decltype(d)> dw;"
      }
    ],
    "lines_added": 257,
    "lines_removed": 271
  },
  "issues": [
    {
      "number": 1870,
      "url": "https://github.com/google/highway/issues/1870",
      "title": "Potential sub-optimal AVX512 codegen for DupEven/DupOdd for 16-bit integer types",
      "body": "Hi,\r\n\r\nJust to share what I think is some sub-optimal codegen for the AVX target that was spotted for the DupEven/DupOdd functions.\r\n\r\nI see vbroadcasti32x4 and vpshufb being generated, where this could really be implemented with a single vpshufb.\r\n\r\nSee https://godbolt.org/z/Teencnfhc\r\n\r\nI presume this is due to the use of LoadDup128 within the DupEven/DupOdd implementation instead of Dup128VecFromValues?\r\n\r\nRegards",
      "created_at": "2023-11-15T15:17:25+00:00"
    }
  ],
  "pull_requests": [],
  "build_info": {
    "old_build_script": "#!/bin/bash\n#!/bin/bash\ncmake --build /test_workspace/workspace/old/build -- -j 1",
    "new_build_script": "#!/bin/bash\n#!/bin/bash\ncmake --build /test_workspace/workspace/old/build -- -j 1",
    "old_test_script": "#!/bin/bash\ncmake -S /test_workspace/workspace/old -B /test_workspace/workspace/old/build -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=ON -DBUILD_TESTING=ON -DHWY_ENABLE_TESTS=ON",
    "new_test_script": "#!/bin/bash\ncmake -S /test_workspace/workspace/old -B /test_workspace/workspace/old/build -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=ON -DBUILD_TESTING=ON -DHWY_ENABLE_TESTS=ON",
    "build_system": "cmake"
  },
  "performance_analysis": {
    "is_significant": false,
    "p_value": 1.0,
    "is_pair_significant": false,
    "pair_p_value": 1.0,
    "is_binom_significant": false,
    "binom_p_value": 1.0,
    "is_wilcoxon_significant": false,
    "wilcoxon_p_value": 0.9999991377003091,
    "is_mannwhitney_significant": false,
    "mannwhitney_p_value": 0.5617191357464386,
    "relative_improvement": -0.0002805486284288497,
    "absolute_improvement_ms": -6.000000000000227,
    "old_mean_ms": 21386.666666666668,
    "new_mean_ms": 21392.666666666668,
    "old_std_ms": 192.82533338594894,
    "new_std_ms": 183.48979739246082,
    "effect_size_cohens_d": -0.031878359843012405,
    "old_ci95_ms": [
      21314.664503857926,
      21458.668829475406
    ],
    "new_ci95_ms": [
      21324.15045028782,
      21461.182883045512
    ],
    "old_ci99_ms": [
      21289.62829869502,
      21483.70503463831
    ],
    "new_ci99_ms": [
      21300.326359686496,
      21485.006973646836
    ],
    "new_times_s": [
      21.13,
      21.09,
      21.14,
      21.16,
      21.17,
      21.16,
      21.25,
      21.22,
      21.17,
      21.34,
      21.19,
      21.28,
      21.2,
      21.25,
      21.49,
      21.4,
      21.54,
      21.47,
      21.49,
      21.44,
      21.46,
      21.6,
      21.54,
      21.62,
      21.61,
      21.56,
      21.58,
      21.63,
      21.62,
      21.49,
      21.62
    ],
    "old_times_s": [
      20.98,
      20.99,
      21.03,
      21.14,
      21.27,
      21.21,
      21.31,
      21.33,
      21.25,
      21.3,
      21.31,
      21.37,
      21.31,
      21.25,
      21.33,
      21.43,
      21.48,
      21.43,
      21.4,
      21.3,
      21.25,
      21.44,
      21.42,
      21.61,
      21.51,
      21.52,
      21.52,
      21.85,
      21.67,
      21.65,
      21.72
    ]
  },
  "tests": {
    "total_tests": 1,
    "significant_improvements": 0,
    "significant_improvements_tests": [],
    "significant_regressions": 0,
    "significant_regressions_tests": [],
    "significant_pair_improvements": 0,
    "significant_pair_improvements_tests": [],
    "significant_pair_regressions": 0,
    "significant_pair_regressions_tests": [],
    "significant_binom_improvements": 0,
    "significant_binom_improvements_tests": [],
    "significant_binom_regressions": 0,
    "significant_binom_regressions_tests": [],
    "significant_wilcoxon_improvements": 0,
    "significant_wilcoxon_improvements_tests": [],
    "significant_wilcoxon_regressions": 0,
    "significant_wilcoxon_regressions_tests": [],
    "significant_mannwhitney_improvements": 0,
    "significant_mannwhitney_improvements_tests": [],
    "significant_mannwhitney_regressions": 0,
    "significant_mannwhitney_regressions_tests": [],
    "tests": [
      {
        "test_name": "NanobenchmarkTest.RunAll",
        "is_significant": false,
        "p_value": 0.8720425051530104,
        "is_pair_significant": false,
        "pair_p_value": 0.8612563307763603,
        "is_binom_significant": false,
        "binom_p_value": 0.9692858271300793,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9118065479443975,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.37452368866658303,
        "relative_improvement": 0.01734104046242776,
        "absolute_improvement_ms": 8.275862068965523,
        "old_mean_ms": 477.2413793103448,
        "new_mean_ms": 468.9655172413793,
        "old_std_ms": 60.17216678143156,
        "new_std_ms": 45.54000028124466,
        "effect_size_cohens_d": 0.1550948380242499,
        "old_ci95_ms": [
          454.35311115389356,
          500.1296474667961
        ],
        "new_ci95_ms": [
          451.64302755826475,
          486.28800692449386
        ],
        "old_ci99_ms": [
          446.3655388698466,
          508.117219750843
        ],
        "new_ci99_ms": [
          445.59780659450496,
          492.33322788825365
        ],
        "new_times": [
          0.47,
          0.44,
          0.44,
          0.4,
          0.51,
          0.46,
          0.48,
          0.47,
          0.4,
          0.5,
          0.46,
          0.47,
          0.53,
          0.44,
          0.53,
          0.48,
          0.47,
          0.45,
          0.5,
          0.54,
          0.53,
          0.53,
          0.5,
          0.46,
          0.48,
          0.45,
          0.46,
          0.34,
          0.41
        ],
        "old_times": [
          0.44,
          0.5,
          0.46,
          0.44,
          0.51,
          0.47,
          0.43,
          0.49,
          0.45,
          0.56,
          0.53,
          0.49,
          0.5,
          0.53,
          0.52,
          0.48,
          0.45,
          0.43,
          0.35,
          0.36,
          0.52,
          0.53,
          0.41,
          0.44,
          0.47,
          0.66,
          0.49,
          0.49,
          0.44
        ]
      }
    ]
  },
  "logs": {
    "full_log_path": "/logs/full.log",
    "config_log_path": "/logs/config.log",
    "build_log_path": "/logs/build.log",
    "test_log_path": "/logs/test.log",
    "build_success": true,
    "test_success": true
  },
  "raw_timing_data": {
    "warmup_runs": 1,
    "measurement_runs": 30,
    "min_exec_time_improvement": 0.05,
    "min_p_value": 0.05
  }
}