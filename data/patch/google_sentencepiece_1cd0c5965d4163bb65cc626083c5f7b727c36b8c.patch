diff --git a/src/unigram_model_trainer.cc b/src/unigram_model_trainer.cc
index 201ea5e..2a6fed3 100644
--- a/src/unigram_model_trainer.cc
+++ b/src/unigram_model_trainer.cc
@@ -434,20 +434,14 @@ TrainerModel::SentencePieces Trainer::PruneSentencePieces(
   // Second, segments all sentences to compute likelihood
   // with a unigram language model. inverted[i] stores
   // the set of sentence index where the sentencepieces[i] appears.
-  float vsum = 0.0;
   std::vector<float> freq(sentencepieces.size(), 0.0);
-  std::vector<std::vector<int>> inverted(sentencepieces.size());
   {
-    std::vector<float> vsums(trainer_spec_.num_threads(), 0.0);
     std::vector<std::vector<float>> freqs(trainer_spec_.num_threads());
-    std::vector<std::vector<std::vector<int>>> inverteds(
-        trainer_spec_.num_threads());
 
     auto pool = std::make_unique<ThreadPool>(trainer_spec_.num_threads());
     pool->StartWorkers();
     for (int n = 0; n < trainer_spec_.num_threads(); ++n) {
       freqs[n].resize(sentencepieces.size(), 0.0);
-      inverteds[n].resize(sentencepieces.size());
 
       pool->Schedule([&, n]() {
         Lattice lattice;
@@ -456,11 +450,9 @@ TrainerModel::SentencePieces Trainer::PruneSentencePieces(
           const auto &w = sentences_[i];
           lattice.SetSentence(w.first);
           model.PopulateNodes(&lattice);
-          vsums[n] += w.second;
           for (const auto *node : lattice.Viterbi().first) {
             if (node->id >= 0) {
               freqs[n][node->id] += w.second;
-              inverteds[n][node->id].push_back(i);
             }
           }
         }
@@ -469,11 +461,8 @@ TrainerModel::SentencePieces Trainer::PruneSentencePieces(
     pool.reset(nullptr);
 
     for (int n = 0; n < trainer_spec_.num_threads(); ++n) {
-      vsum += vsums[n];
       for (size_t i = 0; i < sentencepieces.size(); ++i) {
         freq[i] += freqs[n][i];
-        std::copy(inverteds[n][i].begin(), inverteds[n][i].end(),
-                  std::back_inserter(inverted[i]));
       }
     }
   }
@@ -496,11 +485,8 @@ TrainerModel::SentencePieces Trainer::PruneSentencePieces(
       // no alternatives. Keeps this entry.
       new_sentencepieces.push_back(sentencepieces[i]);
     } else {
-      float F = 0.0;  // the frequency of sentencepieces[i].
-      for (const int n : inverted[i]) {
-        F += sentences_[n].second;
-      }
-      F /= vsum;  // normalizes by all sentence frequency.
+      // Token-normalized frequency: proportion of token counts.
+      const float F = (sum == 0.0f) ? 0.0f : (freq[i] / sum);
 
       // The logprob with the sentencepiece[i].
       const float logprob_sp = std::log(static_cast<double>(freq[i])) - logsum;
@@ -512,8 +498,8 @@ TrainerModel::SentencePieces Trainer::PruneSentencePieces(
       const float logsum_alt = std::log(
           static_cast<double>(sum + freq[i] * (alternatives[i].size() - 1)));
 
-      // The frequencies of altenatives are increased by freq[i].
-      float logprob_alt = 0.0;
+      // The frequencies of alternatives are increased by freq[i].
+      float logprob_alt = 0.0f;
       for (const int n : alternatives[i]) {
         logprob_alt +=
             (std::log(static_cast<double>(freq[n] + freq[i])) - logsum_alt);
