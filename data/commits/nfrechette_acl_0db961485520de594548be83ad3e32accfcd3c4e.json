{
  "metadata": {
    "collection_date": "2026-02-03T20:04:20.251908",
    "repository": "https://github.com/nfrechette/acl",
    "repository_name": "nfrechette/acl"
  },
  "commit_info": {
    "old_sha": "672c57b64c09e16eeac9a728c84fbd2c0965a6a8",
    "new_sha": "0db961485520de594548be83ad3e32accfcd3c4e",
    "commit_message": [
      "feat(compression): add v2 bit rate optimization algorithm\n\nFaster than v1 and just as good"
    ],
    "commit_date": "2024-06-02T01:04:22+00:00",
    "patch": [
      "--- includes/acl/compression/impl/quantize.transform.h\n@@ -79,6 +79,8 @@\n // at each leaf and the dominant transform in object space in a single pass\n #define ACL_IMPL_VARIABLE_QUANTIZATION_ALGO_PRECISE\t\t1\n \n+#define ACL_IMPL_VARIABLE_QUANTIZATION_ALGO_PRECISE_V2\t2\n+\n // The currently used algorithm for variable bit rate optimization\n #define ACL_IMPL_VARIABLE_QUANTIZATION_ALGO\t\t\t\tACL_IMPL_VARIABLE_QUANTIZATION_ALGO_ORIGINAL\n \n@@ -891,7 +893,7 @@ namespace acl\n \t\t\treturn rtm::scalar_cast(max_error);\n \t\t}\n \n-#if ACL_IMPL_VARIABLE_QUANTIZATION_ALGO == ACL_IMPL_VARIABLE_QUANTIZATION_ALGO_PRECISE\n+#if ACL_IMPL_VARIABLE_QUANTIZATION_ALGO == ACL_IMPL_VARIABLE_QUANTIZATION_ALGO_PRECISE || ACL_IMPL_VARIABLE_QUANTIZATION_ALGO == ACL_IMPL_VARIABLE_QUANTIZATION_ALGO_PRECISE_V2\n \n \t\tinline float calculate_max_error_at_bit_rate_object(\n \t\t\tquantization_context& context, uint32_t transform_index_to_measure,\n@@ -994,6 +996,265 @@ namespace acl\n \t\t\treturn rtm::scalar_cast(max_error);\n \t\t}\n \n+#endif\n+\n+#if ACL_IMPL_VARIABLE_QUANTIZATION_ALGO == ACL_IMPL_VARIABLE_QUANTIZATION_ALGO_PRECISE_V2\n+\n+\t\t// Used when no non-uniform 3D scale is present\n+\t\tinline float calculate_max_error_at_bit_rate_object_cached(\n+\t\t\tquantization_context& context,\n+\t\t\tuint32_t transform_index_being_optimized, uint32_t transform_index_to_measure,\n+\t\t\tconst rtm::qvvf* additive_base_local_transforms,\n+\t\t\tconst rtm::qvvf* object_transforms_raw,\n+\t\t\tconst rtm::qvvf* cached_transforms_lossy,\n+\t\t\tfloat max_allowed_error)\n+\t\t{\n+\t\t\tconst itransform_error_metric* error_metric = context.error_metric;\n+\t\t\tconst bool has_additive_base = context.has_additive_base;\n+\t\t\tconst float sample_rate = context.sample_rate;\n+\t\t\tconst float clip_duration = context.clip_duration;\n+\t\t\tconst uint32_t num_transforms = context.num_bones;\n+\t\t\tconst uint32_t num_samples = context.num_samples;\n+\t\t\tconst additive_clip_format8 additive_format = context.clip.additive_format;\n+\n+\t\t\tconst auto calculate_error_impl = std::mem_fn(context.has_scale ? &itransform_error_metric::calculate_error : &itransform_error_metric::calculate_error_no_scale);\n+\n+\t\t\tconst uint32_t parent_transform_index = context.topology->transforms[transform_index_being_optimized].parent_index;\n+\n+\t\t\tconst rtm::scalarf error_threshold = rtm::scalar_set(context.metadata[transform_index_to_measure].precision);\n+\t\t\tconst float shell_distance = context.metadata[transform_index_to_measure].shell_distance;\n+\n+\t\t\titransform_error_metric::calculate_error_args calculate_error_args;\n+\t\t\tcalculate_error_args.transform0 = nullptr;\n+\t\t\tcalculate_error_args.transform1 = nullptr;\n+\t\t\tcalculate_error_args.construct_sphere_shell(shell_distance);\n+\n+\t\t\tcontext.local_query.build(transform_index_being_optimized, context.bit_rate_per_bone[transform_index_being_optimized]);\n+\n+\t\t\tfloat sample_indexf = float(context.segment_sample_start_index);\n+\t\t\trtm::scalarf max_error = rtm::scalar_set(0.0F);\n+\t\t\tconst rtm::scalarf max_allowed_error_f = rtm::scalar_set(max_allowed_error);\n+\n+\t\t\tfor (uint32_t sample_index = 0; sample_index < num_samples; ++sample_index)\n+\t\t\t{\n+\t\t\t\t// Sample our streams and calculate the error\n+\t\t\t\t// The sample time is calculated from the full clip duration to be consistent with decompression\n+\t\t\t\tconst float sample_time = rtm::scalar_min(sample_indexf / sample_rate, clip_duration);\n+\n+\t\t\t\trtm::qvvf local_transform_lossy = context.bit_rate_database.sample(context.local_query, sample_time);\n+\n+\t\t\t\t// Apply our additive onto our base\n+\t\t\t\tif (has_additive_base)\n+\t\t\t\t\tlocal_transform_lossy = rtm::qvv_normalize(acl::apply_additive_to_base(additive_format, additive_base_local_transforms[(sample_index * num_transforms) + transform_index_being_optimized], local_transform_lossy));\n+\n+\t\t\t\t// Use our local transform being optimized and convert the transform to measure into object space\n+\t\t\t\t// result = measured_to_transform * transform_being_optimized * transform_to_root\n+\t\t\t\trtm::qvvf parent_transform_to_root_lossy = rtm::qvv_identity();\n+\t\t\t\tif (parent_transform_index != k_invalid_track_index)\n+\t\t\t\t\tparent_transform_to_root_lossy = cached_transforms_lossy[(sample_index * num_transforms) + parent_transform_index];\n+\n+\t\t\t\tconst rtm::qvvf transform_to_root_lossy = rtm::qvv_normalize(rtm::qvv_mul(local_transform_lossy, parent_transform_to_root_lossy));\n+\n+\t\t\t\trtm::qvvf measured_to_transform_lossy = rtm::qvv_identity();\n+\t\t\t\tif (transform_index_being_optimized != transform_index_to_measure)\n+\t\t\t\t\tmeasured_to_transform_lossy = cached_transforms_lossy[(sample_index * num_transforms) + transform_index_to_measure];\n+\n+\t\t\t\tconst rtm::qvvf measured_to_root_lossy = rtm::qvv_normalize(rtm::qvv_mul(measured_to_transform_lossy, transform_to_root_lossy));\n+\t\t\t\tconst rtm::qvvf& measured_to_root_raw = object_transforms_raw[(sample_index * num_transforms) + transform_index_to_measure];\n+\n+\t\t\t\t// Measure the error\n+\t\t\t\tcalculate_error_args.transform0 = &measured_to_root_raw;\n+\t\t\t\tcalculate_error_args.transform1 = &measured_to_root_lossy;\n+\n+#if defined(RTM_COMPILER_MSVC) && defined(RTM_ARCH_X86) && RTM_COMPILER_MSVC == RTM_COMPILER_MSVC_2015\n+\t\t\t\t// VS2015 fails to generate the right x86 assembly, branch instead\n+\t\t\t\t(void)calculate_error_impl;\n+\t\t\t\tconst rtm::scalarf error = context.has_scale ? error_metric->calculate_error(calculate_error_args) : error_metric->calculate_error_no_scale(calculate_error_args);\n+#else\n+\t\t\t\tconst rtm::scalarf error = calculate_error_impl(error_metric, calculate_error_args);\n+#endif\n+\n+\t\t\t\tmax_error = rtm::scalar_max(max_error, error);\n+\t\t\t\tsample_indexf += 1.0F;\n+\n+\t\t\t\tif (rtm::scalar_greater_equal(error, max_allowed_error_f))\n+\t\t\t\t\tbreak;\t// The error is too high, early out\n+\t\t\t}\n+\n+\t\t\treturn rtm::scalar_cast(max_error);\n+\t\t}\n+\n+\t\t// Used when we have non-uniform 3D scale present\n+\t\tinline float calculate_max_error_at_bit_rate_object_cached_with_non_uniform_scale(\n+\t\t\tquantization_context& context,\n+\t\t\tuint32_t transform_index_being_optimized, uint32_t transform_index_to_measure,\n+\t\t\tconst uint32_t* transform_chain_indices, uint32_t transform_chain_length,\n+\t\t\tconst rtm::qvvf* additive_base_local_transforms,\n+\t\t\tconst rtm::qvvf* object_transforms_raw,\n+\t\t\tconst rtm::qvvf* cached_transforms_lossy,\n+\t\t\tfloat max_allowed_error)\n+\t\t{\n+\t\t\tconst itransform_error_metric* error_metric = context.error_metric;\n+\t\t\tconst bool has_additive_base = context.has_additive_base;\n+\t\t\tconst float sample_rate = context.sample_rate;\n+\t\t\tconst float clip_duration = context.clip_duration;\n+\t\t\tconst uint32_t num_transforms = context.num_bones;\n+\t\t\tconst uint32_t num_samples = context.num_samples;\n+\t\t\tconst additive_clip_format8 additive_format = context.clip.additive_format;\n+\n+\t\t\tconst auto calculate_error_impl = std::mem_fn(context.has_scale ? &itransform_error_metric::calculate_error : &itransform_error_metric::calculate_error_no_scale);\n+\n+\t\t\tconst uint32_t parent_transform_index = context.topology->transforms[transform_index_being_optimized].parent_index;\n+\n+\t\t\tconst rtm::scalarf error_threshold = rtm::scalar_set(context.metadata[transform_index_to_measure].precision);\n+\t\t\tconst float shell_distance = context.metadata[transform_index_to_measure].shell_distance;\n+\n+\t\t\titransform_error_metric::calculate_error_args calculate_error_args;\n+\t\t\tcalculate_error_args.transform0 = nullptr;\n+\t\t\tcalculate_error_args.transform1 = nullptr;\n+\t\t\tcalculate_error_args.construct_sphere_shell(shell_distance);\n+\n+\t\t\tcontext.local_query.build(transform_index_being_optimized, context.bit_rate_per_bone[transform_index_being_optimized]);\n+\n+\t\t\tfloat sample_indexf = float(context.segment_sample_start_index);\n+\t\t\trtm::scalarf max_error = rtm::scalar_set(0.0F);\n+\t\t\tconst rtm::scalarf max_allowed_error_f = rtm::scalar_set(max_allowed_error);\n+\n+\t\t\tfor (uint32_t sample_index = 0; sample_index < num_samples; ++sample_index)\n+\t\t\t{\n+\t\t\t\t// Sample our streams and calculate the error\n+\t\t\t\t// The sample time is calculated from the full clip duration to be consistent with decompression\n+\t\t\t\tconst float sample_time = rtm::scalar_min(sample_indexf / sample_rate, clip_duration);\n+\n+\t\t\t\trtm::qvvf local_transform_lossy = context.bit_rate_database.sample(context.local_query, sample_time);\n+\n+\t\t\t\t// Apply our additive onto our base\n+\t\t\t\tif (has_additive_base)\n+\t\t\t\t\tlocal_transform_lossy = rtm::qvv_normalize(acl::apply_additive_to_base(additive_format, additive_base_local_transforms[(sample_index * num_transforms) + transform_index_being_optimized], local_transform_lossy));\n+\n+\t\t\t\t// Use our local transform being optimized and convert the transform to measure into object space\n+\t\t\t\t// result = measured_to_transform * transform_being_optimized * transform_to_root\n+\t\t\t\trtm::qvvf parent_transform_to_root_lossy = rtm::qvv_identity();\n+\t\t\t\tif (parent_transform_index != k_invalid_track_index)\n+\t\t\t\t\tparent_transform_to_root_lossy = cached_transforms_lossy[(sample_index * num_transforms) + parent_transform_index];\n+\n+\t\t\t\tconst rtm::qvvf transform_to_root_lossy = rtm::qvv_normalize(rtm::qvv_mul(local_transform_lossy, parent_transform_to_root_lossy));\n+\n+\t\t\t\t// When non-uniform 3D scale is present, our cached transforms after optimization contain the local space transform\n+\t\t\t\t// We cannot leverage associativity to speed up computation, do it manually using the transform chain\n+\t\t\t\trtm::qvvf measured_to_root_lossy = transform_to_root_lossy;\n+\n+\t\t\t\t// Skip the transform currently being optimized\n+\t\t\t\tACL_ASSERT(transform_chain_indices[transform_chain_length - 1] == transform_index_being_optimized, \"Last chain transform index should be the transform being optimized\");\n+\t\t\t\tfor (const uint32_t chain_transform_index : make_reverse_iterator(transform_chain_indices, transform_chain_length - 1))\n+\t\t\t\t{\n+\t\t\t\t\tconst rtm::qvvf& chain_transform = cached_transforms_lossy[(sample_index * num_transforms) + chain_transform_index];\n+\t\t\t\t\tmeasured_to_root_lossy = rtm::qvv_normalize(rtm::qvv_mul(chain_transform, measured_to_root_lossy));\n+\t\t\t\t}\n+\n+\t\t\t\tconst rtm::qvvf& measured_to_root_raw = object_transforms_raw[(sample_index * num_transforms) + transform_index_to_measure];\n+\n+\t\t\t\t// Measure the error\n+\t\t\t\tcalculate_error_args.transform0 = &measured_to_root_raw;\n+\t\t\t\tcalculate_error_args.transform1 = &measured_to_root_lossy;\n+\n+#if defined(RTM_COMPILER_MSVC) && defined(RTM_ARCH_X86) && RTM_COMPILER_MSVC == RTM_COMPILER_MSVC_2015\n+\t\t\t\t// VS2015 fails to generate the right x86 assembly, branch instead\n+\t\t\t\t(void)calculate_error_impl;\n+\t\t\t\tconst rtm::scalarf error = context.has_scale ? error_metric->calculate_error(calculate_error_args) : error_metric->calculate_error_no_scale(calculate_error_args);\n+#else\n+\t\t\t\tconst rtm::scalarf error = calculate_error_impl(error_metric, calculate_error_args);\n+#endif\n+\n+\t\t\t\tmax_error = rtm::scalar_max(max_error, error);\n+\t\t\t\tsample_indexf += 1.0F;\n+\n+\t\t\t\tif (rtm::scalar_greater_equal(error, max_allowed_error_f))\n+\t\t\t\t\tbreak;\t// The error is too high, early out\n+\t\t\t}\n+\n+\t\t\treturn rtm::scalar_cast(max_error);\n+\t\t}\n+\n+\t\t// Used when no non-uniform 3D scale is present\n+\t\tinline void update_cached_transforms(\n+\t\t\tquantization_context& context,\n+\t\t\tuint32_t transform_index_being_optimized, uint32_t transform_index_to_measure,\n+\t\t\tconst rtm::qvvf* additive_base_local_transforms,\n+\t\t\trtm::qvvf* cached_transforms_lossy)\n+\t\t{\n+\t\t\tconst bool has_additive_base = context.has_additive_base;\n+\t\t\tconst float sample_rate = context.sample_rate;\n+\t\t\tconst float clip_duration = context.clip_duration;\n+\t\t\tconst uint32_t num_transforms = context.num_bones;\n+\t\t\tconst additive_clip_format8 additive_format = context.clip.additive_format;\n+\n+\t\t\tcontext.local_query.build(transform_index_being_optimized, context.bit_rate_per_bone[transform_index_being_optimized]);\n+\n+\t\t\tfloat sample_indexf = float(context.segment_sample_start_index);\n+\n+\t\t\tfor (uint32_t sample_index = 0; sample_index < context.num_samples; ++sample_index)\n+\t\t\t{\n+\t\t\t\t// Sample our streams and calculate the error\n+\t\t\t\t// The sample time is calculated from the full clip duration to be consistent with decompression\n+\t\t\t\tconst float sample_time = rtm::scalar_min(sample_indexf / sample_rate, clip_duration);\n+\n+\t\t\t\trtm::qvvf local_transform_lossy = context.bit_rate_database.sample(context.local_query, sample_time);\n+\n+\t\t\t\t// Apply our additive onto our base\n+\t\t\t\tif (has_additive_base)\n+\t\t\t\t\tlocal_transform_lossy = rtm::qvv_normalize(acl::apply_additive_to_base(additive_format, additive_base_local_transforms[(sample_index * num_transforms) + transform_index_being_optimized], local_transform_lossy));\n+\n+\t\t\t\t// Our cached transforms contains the combined measured_to_transform from some parent transform in the chain up to\n+\t\t\t\t// the transform we measure (e.g. leaf)\n+\t\t\t\trtm::qvvf measured_to_transform_lossy = rtm::qvv_identity();\n+\t\t\t\tif (transform_index_being_optimized != transform_index_to_measure)\n+\t\t\t\t\tmeasured_to_transform_lossy = cached_transforms_lossy[(sample_index * num_transforms) + transform_index_to_measure];\n+\n+\t\t\t\tmeasured_to_transform_lossy = rtm::qvv_normalize(rtm::qvv_mul(measured_to_transform_lossy, local_transform_lossy));\n+\n+\t\t\t\tcached_transforms_lossy[(sample_index * num_transforms) + transform_index_to_measure] = measured_to_transform_lossy;\n+\n+\t\t\t\tsample_indexf += 1.0F;\n+\t\t\t}\n+\t\t}\n+\n+\t\t// Used when we have non-uniform 3D scale present\n+\t\tinline void update_cached_transforms_with_non_uniform_scale(\n+\t\t\tquantization_context& context,\n+\t\t\tuint32_t transform_index_being_optimized,\n+\t\t\tconst rtm::qvvf* additive_base_local_transforms,\n+\t\t\trtm::qvvf* cached_transforms_lossy)\n+\t\t{\n+\t\t\tconst bool has_additive_base = context.has_additive_base;\n+\t\t\tconst float sample_rate = context.sample_rate;\n+\t\t\tconst float clip_duration = context.clip_duration;\n+\t\t\tconst uint32_t num_transforms = context.num_bones;\n+\t\t\tconst additive_clip_format8 additive_format = context.clip.additive_format;\n+\n+\t\t\tcontext.local_query.build(transform_index_being_optimized, context.bit_rate_per_bone[transform_index_being_optimized]);\n+\n+\t\t\tfloat sample_indexf = float(context.segment_sample_start_index);\n+\n+\t\t\tfor (uint32_t sample_index = 0; sample_index < context.num_samples; ++sample_index)\n+\t\t\t{\n+\t\t\t\t// Sample our streams and calculate the error\n+\t\t\t\t// The sample time is calculated from the full clip duration to be consistent with decompression\n+\t\t\t\tconst float sample_time = rtm::scalar_min(sample_indexf / sample_rate, clip_duration);\n+\n+\t\t\t\trtm::qvvf local_transform_lossy = context.bit_rate_database.sample(context.local_query, sample_time);\n+\n+\t\t\t\t// Apply our additive onto our base\n+\t\t\t\tif (has_additive_base)\n+\t\t\t\t\tlocal_transform_lossy = rtm::qvv_normalize(acl::apply_additive_to_base(additive_format, additive_base_local_transforms[(sample_index * num_transforms) + transform_index_being_optimized], local_transform_lossy));\n+\n+\t\t\t\t// When non-uniform 3D scale is present, our cached transforms after optimization contain the local space transform\n+\t\t\t\tcached_transforms_lossy[(sample_index * num_transforms) + transform_index_being_optimized] = local_transform_lossy;\n+\n+\t\t\t\tsample_indexf += 1.0F;\n+\t\t\t}\n+\t\t}\n+\n #endif\n \n \t\tinline void calculate_local_space_bit_rates(quantization_context& context)\n@@ -1278,7 +1539,7 @@ namespace acl\n \t\t\t}\n \t\t}\n \n-#elif ACL_IMPL_VARIABLE_QUANTIZATION_ALGO == ACL_IMPL_VARIABLE_QUANTIZATION_ALGO_PRECISE\n+#elif ACL_IMPL_VARIABLE_QUANTIZATION_ALGO == ACL_IMPL_VARIABLE_QUANTIZATION_ALGO_PRECISE || ACL_IMPL_VARIABLE_QUANTIZATION_ALGO == ACL_IMPL_VARIABLE_QUANTIZATION_ALGO_PRECISE_V2\n \n \t\tinline void initialize_bone_bit_rates(const segment_context& segment, rotation_format8 rotation_format, vector_format8 translation_format, vector_format8 scale_format, transform_bit_rates* out_bit_rate_per_bone)\n \t\t{\n@@ -1979,6 +2240,545 @@ namespace acl\n \t\t\tdeallocate_type_array(context.allocator, leaf_chain_transform_indices, num_transforms);\n \t\t}\n \n+#elif ACL_IMPL_VARIABLE_QUANTIZATION_ALGO == ACL_IMPL_VARIABLE_QUANTIZATION_ALGO_PRECISE_V2\n+\n+\t\t//////////////////////////////////////////////////////////////////////////\n+\t\t// [Bit Rate Optimization Algorithm]\n+\t\t//\n+\t\t// In order to properly calculate the error introduced by changing the bit rate, we need\n+\t\t// to measure the transforms most impacted by the change. These transforms form the\n+\t\t// critical transform set:\n+\t\t//     - Dominant transform (the one furthest away from ourself, using 3D Euclidean distance)\n+\t\t//     - All leaves below ourself (the ones furthest away from ourself, using Manhattan distance)\n+\t\t//\n+\t\t// We wish to measure the error in object/world space for each critical transform when testing a\n+\t\t// new bit rate. To that end, we need to carefully consider the best approach to avoid\n+\t\t// algorithmic complexity exploding.\n+\t\t//\n+\t\t// Let us use a single bone chain as an example:\n+\t\t//     r = (c2 * c1) * t * (p2 * p1)\n+\t\t// Where:\n+\t\t//     c2: a child transform of c1, also a leaf transform\n+\t\t//     c1: a child transform of t\n+\t\t//     t: the transform whose bit rate we are changing\n+\t\t//     p2: parent transform of t\n+\t\t//     p1: parent transform of p2, also a root transform\n+\t\t//     r: resulting local to world for c2\n+\t\t//\n+\t\t// Our key insight is that when 't' changes, the other transforms do not change. This means\n+\t\t// that we can pre-calculate (c2 * c1) and (p2 * p1) and re-use them over and over when testing\n+\t\t// each permutation. This converts our O(N) evaluation where N is the number of transforms\n+\t\t// into O(1) with just 2 multiplications to compute our final local to world transform for 'c2'.\n+\t\t//\n+\t\t// Another key insight is that we wish to start optimizing the leaf transforms first.\n+\t\t// A transform has a single parent, but it can have many children. By optimizing the children\n+\t\t// first, we force the parent to retain more precision to accommodate them but each child can\n+\t\t// use fewer bits. If we went the other way around, a less precise parent may force its children\n+\t\t// to retain more bits.\n+\t\t//\n+\t\t// Our desired algorithm is thus as such:\n+\t\t// for each transform X, sorted children first ...\n+\t\t//     for each bit rate permutation, sorted smallest first ...\n+\t\t//         for each critical transform of X ...\n+\t\t//             for each sample in segment ...\n+\t\t//                 Measure the error in object space, retain max error\n+\t\t//             if max error too high, break\n+\t\t//         if max error below precision threshold\n+\t\t//             update bit rate for X, break\n+\t\t//\n+\t\t// The algorithm complexity is thus as follows: O(T*P*S*C)\n+\t\t// Where:\n+\t\t//     T: number of transforms\n+\t\t//     P: number of permutations to try\n+\t\t//     S: number of samples in segment\n+\t\t//     C: number of critical transforms\n+\t\t//\n+\t\t// To facilitate the transform caching described above, we first compute every transform of\n+\t\t// every sample in object space. These represent the t * (p2 * p1) part above for each transform.\n+\t\t// This is reasonable because segments are fairly small and have a max of 32 samples.\n+\t\t// Our algorithm starts at the leaves. The (c2 * c1) portion is thus missing, conceptually we can\n+\t\t// use the identity instead. Once we find the best bit rate for each transform, we need to update\n+\t\t// our cached values so that our parent transforms can leverage them. We move on from there.\n+\t\t//\n+\t\t// Let us walk through an example for this transform chain (child left, parent right):\n+\t\t//     A, B, C, D\n+\t\t// A is a leaf while D is a root. The process here is shown for children, but the treatment of the dominant\n+\t\t// transform is similar.\n+\t\t//\n+\t\t// First we optimize A, it has no children and so only the cached dominant transform needs to be updated: itself.\n+\t\t// We have no children and so (c2 * c1) is the identity while (p2 * p1) is B's cached transform.\n+\t\t// We set A's cached transform to A * identity (because it has no children)\n+\t\t// Next, we move to optimize B. A's cached transform represents (c2 * c1) above while C's cached transform is (p2 * p1).\n+\t\t// We set A's cached transform to A * B (we roll B's transform into it).\n+\t\t// Next, we move to optimize C. A's cached transform represents (c2 * c1) while D's cached transform is (p2 * p1).\n+\t\t// We set A's cached transform to A * B * C.\n+\t\t// Finally, we move to optimize D. It has no parent and so the (p2 * p1) portion is the identity transform.\n+\t\t// We update A similarly and the process ends.\n+\t\t//\n+\t\t// Only leaf cached transforms and dominant transforms need to be updated. Other intermediary transforms can remain\n+\t\t// unchanged since they are no longer needed once optimized: their final values are rolled up into the cached critical\n+\t\t// transforms as we progress through the optimization process.\n+\t\t//\n+\t\t// Non-uniform 3D scale throws a wrench in the mix because Realtime Math's qvv type is not associative under multiplication\n+\t\t// when non-uniform scale is present. As such, the multiplication order is important and we cannot leverage caching\n+\t\t// as effectively. We have to calculate the object space transforms by traversing the transform chains manually.\n+\t\t// This is quite a bit slower, but thankfully, non-uniform 3D scale is uncommon. When it is, we take a slower path\n+\t\t// that does not leverage associativity. Instead, the cached transforms will contain local space values once they\n+\t\t// have been optimized. We then multiply them one by one using transform chains as needed.\n+\t\t//////////////////////////////////////////////////////////////////////////\n+\t\tinline void find_optimal_bit_rates(quantization_context& context)\n+\t\t{\n+\t\t\tACL_ASSERT(context.is_valid(), \"quantization_context isn't valid\");\n+\n+\t\t\tinitialize_bone_bit_rates(*context.segment, context.rotation_format, context.translation_format, context.scale_format, context.bit_rate_per_bone);\n+\n+\t\t\tconst uint32_t num_transforms = context.num_bones;\n+\t\t\tconst uint32_t num_samples = context.num_samples;\n+\t\t\tconst float sample_rate = context.sample_rate;\n+\t\t\tconst float clip_duration = context.clip_duration;\n+\t\t\tconst bool has_additive_base = context.has_additive_base;\n+\t\t\tconst additive_clip_format8 additive_format = context.clip.additive_format;\n+\n+\t\t\tconst bool rotation_supports_constant_tracks = context.segment->are_rotations_normalized;\n+\t\t\tconst bool translation_supports_constant_tracks = context.segment->are_translations_normalized;\n+\t\t\tconst bool scale_supports_constant_tracks = context.segment->are_scales_normalized;\n+\n+\t\t\trtm::qvvf* additive_base_local_transforms = has_additive_base ? allocate_type_array<rtm::qvvf>(context.allocator, num_transforms * num_samples) : nullptr;\n+\t\t\trtm::qvvf* object_transforms_raw = allocate_type_array<rtm::qvvf>(context.allocator, num_transforms * num_samples);\n+\t\t\trtm::qvvf* cached_transforms_lossy = allocate_type_array<rtm::qvvf>(context.allocator, num_transforms * num_samples);\n+\n+\t\t\tuint32_t* critical_transform_indices = allocate_type_array<uint32_t>(context.allocator, num_transforms);\n+\n+\t\t\tif (!context.all_local_query.is_bound())\n+\t\t\t\tcontext.all_local_query.bind(context.bit_rate_database);\n+\t\t\tcontext.all_local_query.build(context.bit_rate_per_bone);\n+\n+\t\t\t// Build our cached transforms by sampling everything and converting our segment to object space\n+\t\t\tfor (uint32_t sample_index = 0; sample_index < num_samples; ++sample_index)\n+\t\t\t{\n+\t\t\t\t// The sample time is calculated from the full clip duration to be consistent with decompression\n+\t\t\t\tconst float sample_time = rtm::scalar_min(float(context.segment->clip_sample_offset + sample_index) / sample_rate, clip_duration);\n+\n+\t\t\t\trtm::qvvf* object_pose_raw = object_transforms_raw + (sample_index * num_transforms);\n+\t\t\t\trtm::qvvf* cached_pose_lossy = cached_transforms_lossy + (sample_index * num_transforms);\n+\n+\t\t\t\t// In local space\n+\t\t\t\tsample_streams(context.raw_bone_streams, num_transforms, sample_time, object_pose_raw);\n+\t\t\t\tcontext.bit_rate_database.sample(context.all_local_query, sample_time, cached_pose_lossy, num_transforms);\n+\n+\t\t\t\tif (has_additive_base)\n+\t\t\t\t{\n+\t\t\t\t\trtm::qvvf* additive_base_pose_transforms = additive_base_local_transforms + (sample_index * num_transforms);\n+\n+\t\t\t\t\tconst float normalized_sample_time = context.additive_base_clip.num_samples > 1 ? (sample_time / clip_duration) : 0.0F;\n+\t\t\t\t\tconst float additive_sample_time = context.additive_base_clip.num_samples > 1 ? (normalized_sample_time * context.additive_base_clip.duration) : 0.0F;\n+\t\t\t\t\tsample_streams(context.additive_base_clip.segments[0].bone_streams, num_transforms, additive_sample_time, additive_base_pose_transforms);\n+\n+\t\t\t\t\t// Apply our additives onto our base\n+\t\t\t\t\tfor (uint32_t transform_index = 0; transform_index < num_transforms; ++transform_index)\n+\t\t\t\t\t{\n+\t\t\t\t\t\tobject_pose_raw[transform_index] = rtm::qvv_normalize(acl::apply_additive_to_base(additive_format, additive_base_pose_transforms[transform_index], object_pose_raw[transform_index]));\n+\t\t\t\t\t\tcached_pose_lossy[transform_index] = rtm::qvv_normalize(acl::apply_additive_to_base(additive_format, additive_base_pose_transforms[transform_index], cached_pose_lossy[transform_index]));\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\t// Convert our poses to object space\n+\t\t\t\tfor (uint32_t transform_index : context.topology->roots_first_iterator())\n+\t\t\t\t{\n+\t\t\t\t\tconst uint32_t parent_transform_index = context.topology->transforms[transform_index].parent_index;\n+\t\t\t\t\tif (parent_transform_index != k_invalid_track_index)\n+\t\t\t\t\t{\n+\t\t\t\t\t\tobject_pose_raw[transform_index] = rtm::qvv_normalize(rtm::qvv_mul(object_pose_raw[transform_index], object_pose_raw[parent_transform_index]));\n+\t\t\t\t\t\tcached_pose_lossy[transform_index] = rtm::qvv_normalize(rtm::qvv_mul(cached_pose_lossy[transform_index], cached_pose_lossy[parent_transform_index]));\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\t// If we have non-uniform 3D scale, we cannot rely on associativity, fall back to the transform chain\n+\t\t\tconst bool has_scale = context.has_scale;\n+\n+\t\t\tconst uint32_t max_num_transform_chains = context.topology->num_max_leaves_per_transform + 1;\t// +1 since we have a dominant transform as well\n+\t\t\tconst uint32_t max_chain_length = context.topology->max_leaf_depth + 1;\t\t\t\t\t\t\t// +1 since depth is 0-based\n+\n+\t\t\tuint32_t* transform_chain_indices = nullptr;\n+\t\t\tuint32_t** transform_chains = nullptr;\n+\t\t\tuint32_t* transform_chain_counts = nullptr;\n+\n+\t\t\tif (has_scale)\n+\t\t\t{\n+\t\t\t\ttransform_chain_indices = allocate_type_array<uint32_t>(context.allocator, max_num_transform_chains * max_chain_length);\n+\t\t\t\ttransform_chains = allocate_type_array<uint32_t*>(context.allocator, max_num_transform_chains);\n+\t\t\t\ttransform_chain_counts = allocate_type_array<uint32_t>(context.allocator, max_num_transform_chains);\n+\n+\t\t\t\tfor (uint32_t chain_index = 0; chain_index < max_num_transform_chains; ++chain_index)\n+\t\t\t\t\ttransform_chains[chain_index] = (chain_index * max_chain_length) + transform_chain_indices;\n+\t\t\t}\n+\n+\t\t\t// We try permutations from the lowest memory footprint to the highest.\n+\t\t\tconst uint8_t* const bit_rate_permutations_per_dofs[] =\n+\t\t\t{\n+\t\t\t\t&acl_impl::k_local_bit_rate_permutations_1_dof[0][0],\n+\t\t\t\t&acl_impl::k_local_bit_rate_permutations_2_dof[0][0],\n+\t\t\t\t&acl_impl::k_local_bit_rate_permutations_3_dof[0][0],\n+\t\t\t};\n+\t\t\tconst size_t num_bit_rate_permutations_per_dofs[] =\n+\t\t\t{\n+\t\t\t\tget_array_size(acl_impl::k_local_bit_rate_permutations_1_dof),\n+\t\t\t\tget_array_size(acl_impl::k_local_bit_rate_permutations_2_dof),\n+\t\t\t\tget_array_size(acl_impl::k_local_bit_rate_permutations_3_dof),\n+\t\t\t};\n+\n+\t\t\tfor (const uint32_t transform_index : context.topology->leaves_first_iterator())\n+\t\t\t{\n+\t\t\t\tconst transform_topology_t& transform_topology = context.topology->transforms[transform_index];\n+\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_BASIC_INFO\n+\t\t\t\tprintf(\"%8u: parent: %3u, dominant: %3u\\n\",\n+\t\t\t\t\ttransform_index, context.parent_transform_indices[transform_index],\n+\t\t\t\t\tcontext.shell_metadata_per_transform[transform_index].dominant_transform_index);\n+#endif\n+\n+\t\t\t\t// Find our critical transform set: leaves + dominant\n+\t\t\t\tuint32_t num_critical_transforms = 0;\n+\t\t\t\tfor (const uint32_t leaf_transform_index : make_iterator(transform_topology.leaves, transform_topology.num_leaves))\n+\t\t\t\t\tcritical_transform_indices[num_critical_transforms++] = leaf_transform_index;\n+\n+\t\t\t\tconst uint32_t dominant_transform_index = context.shell_metadata_per_transform[transform_index].dominant_transform_index;\n+\t\t\t\tif (!std::any_of(critical_transform_indices, critical_transform_indices + num_critical_transforms, [dominant_transform_index](uint32_t value) { return value == dominant_transform_index; }))\n+\t\t\t\t\tcritical_transform_indices[num_critical_transforms++] = dominant_transform_index;\n+\n+\t\t\t\t// Non-uniform 3D scale requires slower full chain processing because we can't leverage associativity\n+\t\t\t\tif (has_scale)\n+\t\t\t\t{\n+\t\t\t\t\t// Build our critical transform chains up to the transform we are optimizing\n+\t\t\t\t\tfor (uint32_t critical_chain_index = 0; critical_chain_index < num_critical_transforms; ++critical_chain_index)\n+\t\t\t\t\t{\n+\t\t\t\t\t\tconst uint32_t critical_transform_index = critical_transform_indices[critical_chain_index];\n+\t\t\t\t\t\tuint32_t* transform_chain = transform_chains[critical_chain_index];\n+\n+\t\t\t\t\t\tuint32_t chain_length = 0;\n+\t\t\t\t\t\tuint32_t chain_transform_index = critical_transform_index;\n+\n+\t\t\t\t\t\t// Add our critical transform index\n+\t\t\t\t\t\ttransform_chain[chain_length++] = chain_transform_index;\n+\n+\t\t\t\t\t\twhile (chain_transform_index != transform_index)\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\t// If we haven't reached our optimizing transform, add the next one\n+\t\t\t\t\t\t\tchain_transform_index = context.topology->transforms[chain_transform_index].parent_index;\n+\n+\t\t\t\t\t\t\ttransform_chain[chain_length++] = chain_transform_index;\n+\t\t\t\t\t\t}\n+\n+\t\t\t\t\t\ttransform_chain_counts[critical_chain_index] = chain_length;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\t// Bit rates at this point are one of three value:\n+\t\t\t\t// 0: if the segment track is normalized, it can be constant within the segment\n+\t\t\t\t// 1: if the segment track isn't normalized, it starts at the lowest bit rate\n+\t\t\t\t// 255: if the track is constant/default for the whole clip\n+\t\t\t\tconst transform_bit_rates bone_bit_rates = context.bit_rate_per_bone[transform_index];\n+\n+\t\t\t\tif (bone_bit_rates.rotation == k_invalid_bit_rate && bone_bit_rates.translation == k_invalid_bit_rate && bone_bit_rates.scale == k_invalid_bit_rate)\n+\t\t\t\t{\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_BASIC_INFO\n+\t\t\t\t\tconst float transform_precision = context.shell_metadata_per_transform[transform_index].precision;\n+\t\t\t\t\tconst float error = calculate_max_error_at_bit_rate_local(context, transform_index, error_scan_stop_condition::until_end_of_segment);\n+\t\t\t\t\tprintf(\"%8u: Best bit rates: [%3u, %3u, %3u](  0) @ %.4f%s (all constant)\\n\",\n+\t\t\t\t\t\ttransform_index, bone_bit_rates.rotation, bone_bit_rates.translation, bone_bit_rates.scale,\n+\t\t\t\t\t\terror, error < transform_precision ? \"\" : \" (too high)\");\n+#endif\n+\n+\t\t\t\t\t// Update our cached transforms using our existing bit rate\n+\t\t\t\t\tfor (const uint32_t critical_transform_index : make_iterator(critical_transform_indices, num_critical_transforms))\n+\t\t\t\t\t{\n+\t\t\t\t\t\tif (has_scale)\n+\t\t\t\t\t\t\tupdate_cached_transforms_with_non_uniform_scale(context, transform_index, additive_base_local_transforms, cached_transforms_lossy);\n+\t\t\t\t\t\telse\n+\t\t\t\t\t\t\tupdate_cached_transforms(context, transform_index, critical_transform_index, additive_base_local_transforms, cached_transforms_lossy);\n+\t\t\t\t\t}\n+\n+\t\t\t\t\tcontinue;\t// Every track bit rate is constant/default, nothing else to do\n+\t\t\t\t}\n+\n+\t\t\t\ttransform_bit_rates best_bit_rates = bone_bit_rates;\n+\t\t\t\tfloat best_error = 1.0E10F;\n+\t\t\t\tuint32_t prev_transform_size = ~0U;\n+\t\t\t\tbool is_error_good_enough = false;\n+\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_BASIC_INFO\n+#if 0\n+\t\t\t\tfloat best_permutation_group_optimization_room = FLT_MAX;\n+\t\t\t\tsize_t best_permutation_group_index = 0;\n+#endif\n+\t\t\t\tsize_t best_permutation_index = 0;\n+\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_VERBOSE_INFO\n+\t\t\t\tfloat best_transform_error = 1.0E10F;\n+\t\t\t\ttransform_bit_rates best_transform_bit_rates = bone_bit_rates;\n+#endif\n+#endif\n+\n+\t\t\t\t// Determine how many degrees of freedom we have to optimize our bit rates\n+\t\t\t\tuint32_t num_dof = 0;\n+\t\t\t\tnum_dof += bone_bit_rates.rotation != k_invalid_bit_rate ? 1 : 0;\n+\t\t\t\tnum_dof += bone_bit_rates.translation != k_invalid_bit_rate ? 1 : 0;\n+\t\t\t\tnum_dof += bone_bit_rates.scale != k_invalid_bit_rate ? 1 : 0;\n+\n+\t\t\t\tconst uint8_t* bit_rate_permutations_per_dof = bit_rate_permutations_per_dofs[num_dof - 1];\n+\t\t\t\tconst size_t num_bit_rate_permutations = num_bit_rate_permutations_per_dofs[num_dof - 1];\n+\n+\t\t\t\t// Our desired bit rates start with the initial value\n+\t\t\t\ttransform_bit_rates desired_bit_rates = bone_bit_rates;\n+\n+\t\t\t\tsize_t permutation_offset = 0;\n+\t\t\t\tfor (size_t permutation_index = 0; permutation_index < num_bit_rate_permutations; ++permutation_index)\n+\t\t\t\t{\n+\t\t\t\t\t// If a bit rate is variable, grab a permutation for it\n+\t\t\t\t\t// We'll only consume as many bit rates as we have degrees of freedom\n+\n+\t\t\t\t\tuint32_t transform_size = 0;\t// In bits\n+\n+\t\t\t\t\tif (desired_bit_rates.rotation != k_invalid_bit_rate)\n+\t\t\t\t\t{\n+\t\t\t\t\t\tdesired_bit_rates.rotation = bit_rate_permutations_per_dof[permutation_offset++];\n+\t\t\t\t\t\ttransform_size += get_num_bits_at_bit_rate(desired_bit_rates.rotation);\n+\t\t\t\t\t}\n+\n+\t\t\t\t\tif (desired_bit_rates.translation != k_invalid_bit_rate)\n+\t\t\t\t\t{\n+\t\t\t\t\t\tdesired_bit_rates.translation = bit_rate_permutations_per_dof[permutation_offset++];\n+\t\t\t\t\t\ttransform_size += get_num_bits_at_bit_rate(desired_bit_rates.translation);\n+\t\t\t\t\t}\n+\n+\t\t\t\t\tif (desired_bit_rates.scale != k_invalid_bit_rate)\n+\t\t\t\t\t{\n+\t\t\t\t\t\tdesired_bit_rates.scale = bit_rate_permutations_per_dof[permutation_offset++];\n+\t\t\t\t\t\ttransform_size += get_num_bits_at_bit_rate(desired_bit_rates.scale);\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t// If our inputs aren't normalized per segment, we can't store them on 0 bits because we'll have no\n+\t\t\t\t\t// segment range information. This occurs when we have a single segment. Skip those permutations.\n+\t\t\t\t\tif (!rotation_supports_constant_tracks && desired_bit_rates.rotation == 0)\n+\t\t\t\t\t\tcontinue;\n+\t\t\t\t\telse if (!translation_supports_constant_tracks && desired_bit_rates.translation == 0)\n+\t\t\t\t\t\tcontinue;\n+\t\t\t\t\telse if (!scale_supports_constant_tracks && desired_bit_rates.scale == 0)\n+\t\t\t\t\t\tcontinue;\n+\n+\t\t\t\t\tif (transform_size > prev_transform_size)\n+\t\t\t\t\t{\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_VERBOSE_INFO\n+\t\t\t\t\t\tprintf(\"%8u: [%3u | %3u | %3u] best with %2u bits @ %.4f\\n\", transform_index, best_transform_bit_rates.rotation, best_transform_bit_rates.translation, best_transform_bit_rates.scale, prev_transform_size, best_transform_error);\n+#endif\n+\n+\t\t\t\t\t\t// Reset\n+\t\t\t\t\t\tbest_transform_error = 1.0E10F;\n+\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_BASIC_INFO && 0\n+\t\t\t\t\t\tbest_permutation_group_optimization_room = FLT_MAX;\n+#endif\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t// If we already found a permutation that is good enough, we test all the others\n+\t\t\t\t\t// that have the same size. Once the size changes, we stop.\n+\t\t\t\t\tif (is_error_good_enough && transform_size != prev_transform_size)\n+\t\t\t\t\t\tbreak;\n+\n+\t\t\t\t\tprev_transform_size = transform_size;\n+\n+\t\t\t\t\tcontext.bit_rate_per_bone[transform_index] = desired_bit_rates;\n+\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_VERBOSE_INFO\n+\t\t\t\t\tprintf(\"            Measuring [%3u | %3u | %3u] (%2u bits) ...\\n\", desired_bit_rates.rotation, desired_bit_rates.translation, desired_bit_rates.scale, transform_size);\n+#endif\n+\n+\t\t\t\t\t// Calculate the error for each critical transform and find the least precise one\n+#if 0\n+\t\t\t\t\tfloat worst_critical_transform_room = 0.0F;\n+\t\t\t\t\tuint32_t worst_critical_transform_index = ~0U;\n+#endif\n+\n+\t\t\t\t\tfloat worst_critical_transform_error = 0.0F;\n+\t\t\t\t\tbool is_permutation_good_enough = true;\n+\n+\t\t\t\t\tfor (uint32_t critical_chain_index = 0; critical_chain_index < num_critical_transforms; ++critical_chain_index)\n+\t\t\t\t\t{\n+\t\t\t\t\t\tconst uint32_t critical_transform_index = critical_transform_indices[critical_chain_index];\n+\n+\t\t\t\t\t\tfloat critical_transform_error;\n+\t\t\t\t\t\tif (has_scale)\n+\t\t\t\t\t\t\tcritical_transform_error = calculate_max_error_at_bit_rate_object_cached_with_non_uniform_scale(\n+\t\t\t\t\t\t\t\tcontext,\n+\t\t\t\t\t\t\t\ttransform_index, critical_transform_index,\n+\t\t\t\t\t\t\t\ttransform_chains[critical_chain_index], transform_chain_counts[critical_chain_index],\n+\t\t\t\t\t\t\t\tadditive_base_local_transforms,\n+\t\t\t\t\t\t\t\tobject_transforms_raw,\n+\t\t\t\t\t\t\t\tcached_transforms_lossy,\n+\t\t\t\t\t\t\t\tbest_error);\n+\t\t\t\t\t\telse\n+\t\t\t\t\t\t\tcritical_transform_error = calculate_max_error_at_bit_rate_object_cached(\n+\t\t\t\t\t\t\t\tcontext,\n+\t\t\t\t\t\t\t\ttransform_index, critical_transform_index,\n+\t\t\t\t\t\t\t\tadditive_base_local_transforms,\n+\t\t\t\t\t\t\t\tobject_transforms_raw,\n+\t\t\t\t\t\t\t\tcached_transforms_lossy,\n+\t\t\t\t\t\t\t\tbest_error);\n+\n+\t\t\t\t\t\tconst float critical_transform_precision = context.shell_metadata_per_transform[critical_transform_index].precision;\n+\t\t\t\t\t\tis_permutation_good_enough &= critical_transform_error <= critical_transform_precision;\n+\n+\t\t\t\t\t\t// TODO: Try this out\n+#if 0\n+\t\t\t\t\t\t// We wish to find the critical transform that has the least room for further optimization\n+\t\t\t\t\t\t// This is the least precise critical transform\n+\t\t\t\t\t\t// To find the least precise, we compute the remaining optimization room: precision - error\n+\t\t\t\t\t\t// This algorithm uses the precision threshold as a target error to reach but not exceed\n+\t\t\t\t\t\t// As such, if the error is below our threshold (good), we want our positive room to be as close to zero as possible\n+\t\t\t\t\t\t// If the error is below our threshold (bad), we want our negative room to be as close to zero as possible\n+\t\t\t\t\t\t// If all our critical transforms are below their precision threshold, their values will be between [0.0, precision]\n+\t\t\t\t\t\t// and the least precise is the one with the largest value.\n+\t\t\t\t\t\t// If any critical transform is above their precision threshold, its value will be negative\n+\t\t\t\t\t\tconst float optimization_room = critical_transform_precision - critical_transform_error;\n+\n+\t\t\t\t\t\tif (worst_critical_transform_room >= 0.0F)\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\tif (optimization_room < 0.0F || optimization_room >= worst_critical_transform_room)\n+\t\t\t\t\t\t\t{\n+\t\t\t\t\t\t\t\tworst_critical_transform_room = optimization_room;\n+\t\t\t\t\t\t\t\tworst_critical_transform_index = critical_transform_index;\n+\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t}\n+\t\t\t\t\t\telse\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\tif (optimization_room < worst_critical_transform_room)\n+\t\t\t\t\t\t\t{\n+\t\t\t\t\t\t\t\tworst_critical_transform_room = optimization_room;\n+\t\t\t\t\t\t\t\tworst_critical_transform_index = critical_transform_index;\n+\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t}\n+#endif\n+\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_VERBOSE_INFO\n+\t\t\t\t\t\tprintf(\"            %8u @ %.4f\\n\", critical_transform_index, critical_transform_error);\n+#endif\n+\n+\t\t\t\t\t\t// We are only as precise as our least precise critical transform\n+\t\t\t\t\t\tworst_critical_transform_error = rtm::scalar_max(critical_transform_error, worst_critical_transform_error);\n+\n+\t\t\t\t\t\tif (critical_transform_error >= best_error)\n+\t\t\t\t\t\t\tbreak;\t// The error of this transform is too high, this permutation will not be selected\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t\n+\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_BASIC_INFO && 0\n+\t\t\t\t\t// Now that we found the least precise critical transform, we can use it to find the best permutation\n+\t\t\t\t\t// The best permutation will have positive optimization room as close to zero as possible\n+\t\t\t\t\t// If none of the permutations have positive optimization room, then the best one is as close to zero as well\n+\n+\t\t\t\t\t// Track the best permutation of its group (all permutations with same size)\n+\t\t\t\t\tif (best_permutation_group_optimization_room == FLT_MAX)\n+\t\t\t\t\t{\n+\t\t\t\t\t\t// First permutation of the group\n+\t\t\t\t\t\tbest_permutation_group_optimization_room = worst_critical_transform_room;\n+\t\t\t\t\t\tbest_permutation_group_index = permutation_index;\n+\t\t\t\t\t}\n+\t\t\t\t\telse if (worst_critical_transform_room >= 0.0F)\n+\t\t\t\t\t{\n+\t\t\t\t\t\t// This permutation is a good one and it meets our desired precision\n+\t\t\t\t\t\tif (best_permutation_group_optimization_room < 0.0F || worst_critical_transform_room < best_permutation_group_optimization_room)\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\tbest_permutation_group_optimization_room = worst_critical_transform_room;\n+\t\t\t\t\t\t\tbest_permutation_group_index = permutation_index;\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t\telse\n+\t\t\t\t\t{\n+\t\t\t\t\t\t// This permutation isn't meeting our desired precision\n+\t\t\t\t\t\tif (worst_critical_transform_room < best_permutation_group_optimization_room)\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\tbest_permutation_group_optimization_room = worst_critical_transform_room;\n+\t\t\t\t\t\t\tbest_permutation_group_index = permutation_index;\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+#endif\n+\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_VERBOSE_INFO\n+\t\t\t\t\tif (worst_critical_transform_error < best_transform_error)\n+\t\t\t\t\t{\n+\t\t\t\t\t\tbest_transform_error = worst_critical_transform_error;\n+\t\t\t\t\t\tbest_transform_bit_rates = desired_bit_rates;\n+\t\t\t\t\t}\n+#endif\n+\n+\t\t\t\t\tif (worst_critical_transform_error < best_error)\n+\t\t\t\t\t{\n+\t\t\t\t\t\tbest_error = worst_critical_transform_error;\n+\t\t\t\t\t\tbest_bit_rates = desired_bit_rates;\n+\t\t\t\t\t\tis_error_good_enough = is_permutation_good_enough;\n+\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_BASIC_INFO\n+\t\t\t\t\t\tbest_permutation_index = permutation_index;\n+#endif\n+\t\t\t\t\t}\n+\n+\t\t\t\t\tif (permutation_index + 1 == num_bit_rate_permutations)\n+\t\t\t\t\t{\n+\t\t\t\t\t\t// Last entry before we exit the loop\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_VERBOSE_INFO\n+\t\t\t\t\t\tprintf(\"%8u: [%3u | %3u | %3u] best with %2u bits @ %.4f\\n\", transform_index, best_transform_bit_rates.rotation, best_transform_bit_rates.translation, best_transform_bit_rates.scale, prev_transform_size, best_transform_error);\n+#endif\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_BASIC_INFO\n+\t\t\t\tprintf(\"%8u: Best bit rates: [%3u, %3u, %3u](%2u bits) perm#[%5u] @ %.4f%s (object)\\n\",\n+\t\t\t\t\ttransform_index, best_bit_rates.rotation, best_bit_rates.translation, best_bit_rates.scale,\n+\t\t\t\t\tbest_bit_rates.get_num_bits(), uint32_t(best_permutation_index), best_error, is_error_good_enough ? \"\" : \" (too high)\");\n+#endif\n+\n+\t\t\t\tcontext.bit_rate_per_bone[transform_index] = best_bit_rates;\n+\n+\t\t\t\t// Update our cached transforms using our new bit rate\n+\t\t\t\tfor (const uint32_t critical_transform_index : make_iterator(critical_transform_indices, num_critical_transforms))\n+\t\t\t\t{\n+\t\t\t\t\tif (has_scale)\n+\t\t\t\t\t\tupdate_cached_transforms_with_non_uniform_scale(context, transform_index, additive_base_local_transforms, cached_transforms_lossy);\n+\t\t\t\t\telse\n+\t\t\t\t\t\tupdate_cached_transforms(context, transform_index, critical_transform_index, additive_base_local_transforms, cached_transforms_lossy);\n+\t\t\t\t}\n+\t\t\t}\n+\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_SUMMARY_ONLY\n+\t\t\tuint32_t total_num_bits = 0;\n+\t\t\tfor (uint32_t transform_index = 0; transform_index < num_transforms; ++transform_index)\n+\t\t\t\ttotal_num_bits += context.bit_rate_per_bone[transform_index].get_num_bits();\n+\t\t\tprintf(\"Variable quantization optimization results (total size %u bits):\\n\", total_num_bits);\n+\t\t\tfor (uint32_t transform_index = 0; transform_index < num_transforms; ++transform_index)\n+\t\t\t{\n+\t\t\t\tconst float transform_precision = context.shell_metadata_per_transform[transform_index].precision;\n+\t\t\t\tconst transform_bit_rates& bone_bit_rate = context.bit_rate_per_bone[transform_index];\n+\n+\t\t\t\tconst uint32_t num_bones_in_chain = calculate_bone_chain_indices(context.clip, transform_index, context.chain_bone_indices);\n+\t\t\t\tconst float error = calculate_max_error_at_bit_rate_object(context, transform_index, context.chain_bone_indices, num_bones_in_chain);\n+\n+\t\t\t\tprintf(\"%8u: [%3u, %3u, %3u][%3u] @ %.4f%s\\n\", transform_index,\n+\t\t\t\t\tbone_bit_rate.rotation, bone_bit_rate.translation, bone_bit_rate.scale,\n+\t\t\t\t\tbone_bit_rate.get_num_bits(), error, error < transform_precision ? \"\" : \" (too high)\");\n+\t\t\t}\n+#endif\n+\n+\t\t\tdeallocate_type_array(context.allocator, additive_base_local_transforms, num_transforms);\n+\t\t\tdeallocate_type_array(context.allocator, object_transforms_raw, num_transforms * num_samples);\n+\t\t\tdeallocate_type_array(context.allocator, cached_transforms_lossy, num_transforms * num_samples);\n+\t\t\tdeallocate_type_array(context.allocator, critical_transform_indices, num_transforms);\n+\t\t\tdeallocate_type_array(context.allocator, transform_chain_indices, max_num_transform_chains * max_chain_length);\n+\t\t\tdeallocate_type_array(context.allocator, transform_chains, max_num_transform_chains);\n+\t\t\tdeallocate_type_array(context.allocator, transform_chain_counts, max_num_transform_chains);\n+\t\t}\n+\n #endif\n \n \t\t// Partitioning will be done as follow in two phases: calculating the error contribution for every frame and a global optimization pass."
    ],
    "files_changed": [
      {
        "filename": "includes/acl/compression/impl/quantize.transform.h",
        "status": "modified",
        "additions": 802,
        "deletions": 2,
        "changes": 804,
        "patch": "@@ -79,6 +79,8 @@\n // at each leaf and the dominant transform in object space in a single pass\n #define ACL_IMPL_VARIABLE_QUANTIZATION_ALGO_PRECISE\t\t1\n \n+#define ACL_IMPL_VARIABLE_QUANTIZATION_ALGO_PRECISE_V2\t2\n+\n // The currently used algorithm for variable bit rate optimization\n #define ACL_IMPL_VARIABLE_QUANTIZATION_ALGO\t\t\t\tACL_IMPL_VARIABLE_QUANTIZATION_ALGO_ORIGINAL\n \n@@ -891,7 +893,7 @@ namespace acl\n \t\t\treturn rtm::scalar_cast(max_error);\n \t\t}\n \n-#if ACL_IMPL_VARIABLE_QUANTIZATION_ALGO == ACL_IMPL_VARIABLE_QUANTIZATION_ALGO_PRECISE\n+#if ACL_IMPL_VARIABLE_QUANTIZATION_ALGO == ACL_IMPL_VARIABLE_QUANTIZATION_ALGO_PRECISE || ACL_IMPL_VARIABLE_QUANTIZATION_ALGO == ACL_IMPL_VARIABLE_QUANTIZATION_ALGO_PRECISE_V2\n \n \t\tinline float calculate_max_error_at_bit_rate_object(\n \t\t\tquantization_context& context, uint32_t transform_index_to_measure,\n@@ -994,6 +996,265 @@ namespace acl\n \t\t\treturn rtm::scalar_cast(max_error);\n \t\t}\n \n+#endif\n+\n+#if ACL_IMPL_VARIABLE_QUANTIZATION_ALGO == ACL_IMPL_VARIABLE_QUANTIZATION_ALGO_PRECISE_V2\n+\n+\t\t// Used when no non-uniform 3D scale is present\n+\t\tinline float calculate_max_error_at_bit_rate_object_cached(\n+\t\t\tquantization_context& context,\n+\t\t\tuint32_t transform_index_being_optimized, uint32_t transform_index_to_measure,\n+\t\t\tconst rtm::qvvf* additive_base_local_transforms,\n+\t\t\tconst rtm::qvvf* object_transforms_raw,\n+\t\t\tconst rtm::qvvf* cached_transforms_lossy,\n+\t\t\tfloat max_allowed_error)\n+\t\t{\n+\t\t\tconst itransform_error_metric* error_metric = context.error_metric;\n+\t\t\tconst bool has_additive_base = context.has_additive_base;\n+\t\t\tconst float sample_rate = context.sample_rate;\n+\t\t\tconst float clip_duration = context.clip_duration;\n+\t\t\tconst uint32_t num_transforms = context.num_bones;\n+\t\t\tconst uint32_t num_samples = context.num_samples;\n+\t\t\tconst additive_clip_format8 additive_format = context.clip.additive_format;\n+\n+\t\t\tconst auto calculate_error_impl = std::mem_fn(context.has_scale ? &itransform_error_metric::calculate_error : &itransform_error_metric::calculate_error_no_scale);\n+\n+\t\t\tconst uint32_t parent_transform_index = context.topology->transforms[transform_index_being_optimized].parent_index;\n+\n+\t\t\tconst rtm::scalarf error_threshold = rtm::scalar_set(context.metadata[transform_index_to_measure].precision);\n+\t\t\tconst float shell_distance = context.metadata[transform_index_to_measure].shell_distance;\n+\n+\t\t\titransform_error_metric::calculate_error_args calculate_error_args;\n+\t\t\tcalculate_error_args.transform0 = nullptr;\n+\t\t\tcalculate_error_args.transform1 = nullptr;\n+\t\t\tcalculate_error_args.construct_sphere_shell(shell_distance);\n+\n+\t\t\tcontext.local_query.build(transform_index_being_optimized, context.bit_rate_per_bone[transform_index_being_optimized]);\n+\n+\t\t\tfloat sample_indexf = float(context.segment_sample_start_index);\n+\t\t\trtm::scalarf max_error = rtm::scalar_set(0.0F);\n+\t\t\tconst rtm::scalarf max_allowed_error_f = rtm::scalar_set(max_allowed_error);\n+\n+\t\t\tfor (uint32_t sample_index = 0; sample_index < num_samples; ++sample_index)\n+\t\t\t{\n+\t\t\t\t// Sample our streams and calculate the error\n+\t\t\t\t// The sample time is calculated from the full clip duration to be consistent with decompression\n+\t\t\t\tconst float sample_time = rtm::scalar_min(sample_indexf / sample_rate, clip_duration);\n+\n+\t\t\t\trtm::qvvf local_transform_lossy = context.bit_rate_database.sample(context.local_query, sample_time);\n+\n+\t\t\t\t// Apply our additive onto our base\n+\t\t\t\tif (has_additive_base)\n+\t\t\t\t\tlocal_transform_lossy = rtm::qvv_normalize(acl::apply_additive_to_base(additive_format, additive_base_local_transforms[(sample_index * num_transforms) + transform_index_being_optimized], local_transform_lossy));\n+\n+\t\t\t\t// Use our local transform being optimized and convert the transform to measure into object space\n+\t\t\t\t// result = measured_to_transform * transform_being_optimized * transform_to_root\n+\t\t\t\trtm::qvvf parent_transform_to_root_lossy = rtm::qvv_identity();\n+\t\t\t\tif (parent_transform_index != k_invalid_track_index)\n+\t\t\t\t\tparent_transform_to_root_lossy = cached_transforms_lossy[(sample_index * num_transforms) + parent_transform_index];\n+\n+\t\t\t\tconst rtm::qvvf transform_to_root_lossy = rtm::qvv_normalize(rtm::qvv_mul(local_transform_lossy, parent_transform_to_root_lossy));\n+\n+\t\t\t\trtm::qvvf measured_to_transform_lossy = rtm::qvv_identity();\n+\t\t\t\tif (transform_index_being_optimized != transform_index_to_measure)\n+\t\t\t\t\tmeasured_to_transform_lossy = cached_transforms_lossy[(sample_index * num_transforms) + transform_index_to_measure];\n+\n+\t\t\t\tconst rtm::qvvf measured_to_root_lossy = rtm::qvv_normalize(rtm::qvv_mul(measured_to_transform_lossy, transform_to_root_lossy));\n+\t\t\t\tconst rtm::qvvf& measured_to_root_raw = object_transforms_raw[(sample_index * num_transforms) + transform_index_to_measure];\n+\n+\t\t\t\t// Measure the error\n+\t\t\t\tcalculate_error_args.transform0 = &measured_to_root_raw;\n+\t\t\t\tcalculate_error_args.transform1 = &measured_to_root_lossy;\n+\n+#if defined(RTM_COMPILER_MSVC) && defined(RTM_ARCH_X86) && RTM_COMPILER_MSVC == RTM_COMPILER_MSVC_2015\n+\t\t\t\t// VS2015 fails to generate the right x86 assembly, branch instead\n+\t\t\t\t(void)calculate_error_impl;\n+\t\t\t\tconst rtm::scalarf error = context.has_scale ? error_metric->calculate_error(calculate_error_args) : error_metric->calculate_error_no_scale(calculate_error_args);\n+#else\n+\t\t\t\tconst rtm::scalarf error = calculate_error_impl(error_metric, calculate_error_args);\n+#endif\n+\n+\t\t\t\tmax_error = rtm::scalar_max(max_error, error);\n+\t\t\t\tsample_indexf += 1.0F;\n+\n+\t\t\t\tif (rtm::scalar_greater_equal(error, max_allowed_error_f))\n+\t\t\t\t\tbreak;\t// The error is too high, early out\n+\t\t\t}\n+\n+\t\t\treturn rtm::scalar_cast(max_error);\n+\t\t}\n+\n+\t\t// Used when we have non-uniform 3D scale present\n+\t\tinline float calculate_max_error_at_bit_rate_object_cached_with_non_uniform_scale(\n+\t\t\tquantization_context& context,\n+\t\t\tuint32_t transform_index_being_optimized, uint32_t transform_index_to_measure,\n+\t\t\tconst uint32_t* transform_chain_indices, uint32_t transform_chain_length,\n+\t\t\tconst rtm::qvvf* additive_base_local_transforms,\n+\t\t\tconst rtm::qvvf* object_transforms_raw,\n+\t\t\tconst rtm::qvvf* cached_transforms_lossy,\n+\t\t\tfloat max_allowed_error)\n+\t\t{\n+\t\t\tconst itransform_error_metric* error_metric = context.error_metric;\n+\t\t\tconst bool has_additive_base = context.has_additive_base;\n+\t\t\tconst float sample_rate = context.sample_rate;\n+\t\t\tconst float clip_duration = context.clip_duration;\n+\t\t\tconst uint32_t num_transforms = context.num_bones;\n+\t\t\tconst uint32_t num_samples = context.num_samples;\n+\t\t\tconst additive_clip_format8 additive_format = context.clip.additive_format;\n+\n+\t\t\tconst auto calculate_error_impl = std::mem_fn(context.has_scale ? &itransform_error_metric::calculate_error : &itransform_error_metric::calculate_error_no_scale);\n+\n+\t\t\tconst uint32_t parent_transform_index = context.topology->transforms[transform_index_being_optimized].parent_index;\n+\n+\t\t\tconst rtm::scalarf error_threshold = rtm::scalar_set(context.metadata[transform_index_to_measure].precision);\n+\t\t\tconst float shell_distance = context.metadata[transform_index_to_measure].shell_distance;\n+\n+\t\t\titransform_error_metric::calculate_error_args calculate_error_args;\n+\t\t\tcalculate_error_args.transform0 = nullptr;\n+\t\t\tcalculate_error_args.transform1 = nullptr;\n+\t\t\tcalculate_error_args.construct_sphere_shell(shell_distance);\n+\n+\t\t\tcontext.local_query.build(transform_index_being_optimized, context.bit_rate_per_bone[transform_index_being_optimized]);\n+\n+\t\t\tfloat sample_indexf = float(context.segment_sample_start_index);\n+\t\t\trtm::scalarf max_error = rtm::scalar_set(0.0F);\n+\t\t\tconst rtm::scalarf max_allowed_error_f = rtm::scalar_set(max_allowed_error);\n+\n+\t\t\tfor (uint32_t sample_index = 0; sample_index < num_samples; ++sample_index)\n+\t\t\t{\n+\t\t\t\t// Sample our streams and calculate the error\n+\t\t\t\t// The sample time is calculated from the full clip duration to be consistent with decompression\n+\t\t\t\tconst float sample_time = rtm::scalar_min(sample_indexf / sample_rate, clip_duration);\n+\n+\t\t\t\trtm::qvvf local_transform_lossy = context.bit_rate_database.sample(context.local_query, sample_time);\n+\n+\t\t\t\t// Apply our additive onto our base\n+\t\t\t\tif (has_additive_base)\n+\t\t\t\t\tlocal_transform_lossy = rtm::qvv_normalize(acl::apply_additive_to_base(additive_format, additive_base_local_transforms[(sample_index * num_transforms) + transform_index_being_optimized], local_transform_lossy));\n+\n+\t\t\t\t// Use our local transform being optimized and convert the transform to measure into object space\n+\t\t\t\t// result = measured_to_transform * transform_being_optimized * transform_to_root\n+\t\t\t\trtm::qvvf parent_transform_to_root_lossy = rtm::qvv_identity();\n+\t\t\t\tif (parent_transform_index != k_invalid_track_index)\n+\t\t\t\t\tparent_transform_to_root_lossy = cached_transforms_lossy[(sample_index * num_transforms) + parent_transform_index];\n+\n+\t\t\t\tconst rtm::qvvf transform_to_root_lossy = rtm::qvv_normalize(rtm::qvv_mul(local_transform_lossy, parent_transform_to_root_lossy));\n+\n+\t\t\t\t// When non-uniform 3D scale is present, our cached transforms after optimization contain the local space transform\n+\t\t\t\t// We cannot leverage associativity to speed up computation, do it manually using the transform chain\n+\t\t\t\trtm::qvvf measured_to_root_lossy = transform_to_root_lossy;\n+\n+\t\t\t\t// Skip the transform currently being optimized\n+\t\t\t\tACL_ASSERT(transform_chain_indices[transform_chain_length - 1] == transform_index_being_optimized, \"Last chain transform index should be the transform being optimized\");\n+\t\t\t\tfor (const uint32_t chain_transform_index : make_reverse_iterator(transform_chain_indices, transform_chain_length - 1))\n+\t\t\t\t{\n+\t\t\t\t\tconst rtm::qvvf& chain_transform = cached_transforms_lossy[(sample_index * num_transforms) + chain_transform_index];\n+\t\t\t\t\tmeasured_to_root_lossy = rtm::qvv_normalize(rtm::qvv_mul(chain_transform, measured_to_root_lossy));\n+\t\t\t\t}\n+\n+\t\t\t\tconst rtm::qvvf& measured_to_root_raw = object_transforms_raw[(sample_index * num_transforms) + transform_index_to_measure];\n+\n+\t\t\t\t// Measure the error\n+\t\t\t\tcalculate_error_args.transform0 = &measured_to_root_raw;\n+\t\t\t\tcalculate_error_args.transform1 = &measured_to_root_lossy;\n+\n+#if defined(RTM_COMPILER_MSVC) && defined(RTM_ARCH_X86) && RTM_COMPILER_MSVC == RTM_COMPILER_MSVC_2015\n+\t\t\t\t// VS2015 fails to generate the right x86 assembly, branch instead\n+\t\t\t\t(void)calculate_error_impl;\n+\t\t\t\tconst rtm::scalarf error = context.has_scale ? error_metric->calculate_error(calculate_error_args) : error_metric->calculate_error_no_scale(calculate_error_args);\n+#else\n+\t\t\t\tconst rtm::scalarf error = calculate_error_impl(error_metric, calculate_error_args);\n+#endif\n+\n+\t\t\t\tmax_error = rtm::scalar_max(max_error, error);\n+\t\t\t\tsample_indexf += 1.0F;\n+\n+\t\t\t\tif (rtm::scalar_greater_equal(error, max_allowed_error_f))\n+\t\t\t\t\tbreak;\t// The error is too high, early out\n+\t\t\t}\n+\n+\t\t\treturn rtm::scalar_cast(max_error);\n+\t\t}\n+\n+\t\t// Used when no non-uniform 3D scale is present\n+\t\tinline void update_cached_transforms(\n+\t\t\tquantization_context& context,\n+\t\t\tuint32_t transform_index_being_optimized, uint32_t transform_index_to_measure,\n+\t\t\tconst rtm::qvvf* additive_base_local_transforms,\n+\t\t\trtm::qvvf* cached_transforms_lossy)\n+\t\t{\n+\t\t\tconst bool has_additive_base = context.has_additive_base;\n+\t\t\tconst float sample_rate = context.sample_rate;\n+\t\t\tconst float clip_duration = context.clip_duration;\n+\t\t\tconst uint32_t num_transforms = context.num_bones;\n+\t\t\tconst additive_clip_format8 additive_format = context.clip.additive_format;\n+\n+\t\t\tcontext.local_query.build(transform_index_being_optimized, context.bit_rate_per_bone[transform_index_being_optimized]);\n+\n+\t\t\tfloat sample_indexf = float(context.segment_sample_start_index);\n+\n+\t\t\tfor (uint32_t sample_index = 0; sample_index < context.num_samples; ++sample_index)\n+\t\t\t{\n+\t\t\t\t// Sample our streams and calculate the error\n+\t\t\t\t// The sample time is calculated from the full clip duration to be consistent with decompression\n+\t\t\t\tconst float sample_time = rtm::scalar_min(sample_indexf / sample_rate, clip_duration);\n+\n+\t\t\t\trtm::qvvf local_transform_lossy = context.bit_rate_database.sample(context.local_query, sample_time);\n+\n+\t\t\t\t// Apply our additive onto our base\n+\t\t\t\tif (has_additive_base)\n+\t\t\t\t\tlocal_transform_lossy = rtm::qvv_normalize(acl::apply_additive_to_base(additive_format, additive_base_local_transforms[(sample_index * num_transforms) + transform_index_being_optimized], local_transform_lossy));\n+\n+\t\t\t\t// Our cached transforms contains the combined measured_to_transform from some parent transform in the chain up to\n+\t\t\t\t// the transform we measure (e.g. leaf)\n+\t\t\t\trtm::qvvf measured_to_transform_lossy = rtm::qvv_identity();\n+\t\t\t\tif (transform_index_being_optimized != transform_index_to_measure)\n+\t\t\t\t\tmeasured_to_transform_lossy = cached_transforms_lossy[(sample_index * num_transforms) + transform_index_to_measure];\n+\n+\t\t\t\tmeasured_to_transform_lossy = rtm::qvv_normalize(rtm::qvv_mul(measured_to_transform_lossy, local_transform_lossy));\n+\n+\t\t\t\tcached_transforms_lossy[(sample_index * num_transforms) + transform_index_to_measure] = measured_to_transform_lossy;\n+\n+\t\t\t\tsample_indexf += 1.0F;\n+\t\t\t}\n+\t\t}\n+\n+\t\t// Used when we have non-uniform 3D scale present\n+\t\tinline void update_cached_transforms_with_non_uniform_scale(\n+\t\t\tquantization_context& context,\n+\t\t\tuint32_t transform_index_being_optimized,\n+\t\t\tconst rtm::qvvf* additive_base_local_transforms,\n+\t\t\trtm::qvvf* cached_transforms_lossy)\n+\t\t{\n+\t\t\tconst bool has_additive_base = context.has_additive_base;\n+\t\t\tconst float sample_rate = context.sample_rate;\n+\t\t\tconst float clip_duration = context.clip_duration;\n+\t\t\tconst uint32_t num_transforms = context.num_bones;\n+\t\t\tconst additive_clip_format8 additive_format = context.clip.additive_format;\n+\n+\t\t\tcontext.local_query.build(transform_index_being_optimized, context.bit_rate_per_bone[transform_index_being_optimized]);\n+\n+\t\t\tfloat sample_indexf = float(context.segment_sample_start_index);\n+\n+\t\t\tfor (uint32_t sample_index = 0; sample_index < context.num_samples; ++sample_index)\n+\t\t\t{\n+\t\t\t\t// Sample our streams and calculate the error\n+\t\t\t\t// The sample time is calculated from the full clip duration to be consistent with decompression\n+\t\t\t\tconst float sample_time = rtm::scalar_min(sample_indexf / sample_rate, clip_duration);\n+\n+\t\t\t\trtm::qvvf local_transform_lossy = context.bit_rate_database.sample(context.local_query, sample_time);\n+\n+\t\t\t\t// Apply our additive onto our base\n+\t\t\t\tif (has_additive_base)\n+\t\t\t\t\tlocal_transform_lossy = rtm::qvv_normalize(acl::apply_additive_to_base(additive_format, additive_base_local_transforms[(sample_index * num_transforms) + transform_index_being_optimized], local_transform_lossy));\n+\n+\t\t\t\t// When non-uniform 3D scale is present, our cached transforms after optimization contain the local space transform\n+\t\t\t\tcached_transforms_lossy[(sample_index * num_transforms) + transform_index_being_optimized] = local_transform_lossy;\n+\n+\t\t\t\tsample_indexf += 1.0F;\n+\t\t\t}\n+\t\t}\n+\n #endif\n \n \t\tinline void calculate_local_space_bit_rates(quantization_context& context)\n@@ -1278,7 +1539,7 @@ namespace acl\n \t\t\t}\n \t\t}\n \n-#elif ACL_IMPL_VARIABLE_QUANTIZATION_ALGO == ACL_IMPL_VARIABLE_QUANTIZATION_ALGO_PRECISE\n+#elif ACL_IMPL_VARIABLE_QUANTIZATION_ALGO == ACL_IMPL_VARIABLE_QUANTIZATION_ALGO_PRECISE || ACL_IMPL_VARIABLE_QUANTIZATION_ALGO == ACL_IMPL_VARIABLE_QUANTIZATION_ALGO_PRECISE_V2\n \n \t\tinline void initialize_bone_bit_rates(const segment_context& segment, rotation_format8 rotation_format, vector_format8 translation_format, vector_format8 scale_format, transform_bit_rates* out_bit_rate_per_bone)\n \t\t{\n@@ -1979,6 +2240,545 @@ namespace acl\n \t\t\tdeallocate_type_array(context.allocator, leaf_chain_transform_indices, num_transforms);\n \t\t}\n \n+#elif ACL_IMPL_VARIABLE_QUANTIZATION_ALGO == ACL_IMPL_VARIABLE_QUANTIZATION_ALGO_PRECISE_V2\n+\n+\t\t//////////////////////////////////////////////////////////////////////////\n+\t\t// [Bit Rate Optimization Algorithm]\n+\t\t//\n+\t\t// In order to properly calculate the error introduced by changing the bit rate, we need\n+\t\t// to measure the transforms most impacted by the change. These transforms form the\n+\t\t// critical transform set:\n+\t\t//     - Dominant transform (the one furthest away from ourself, using 3D Euclidean distance)\n+\t\t//     - All leaves below ourself (the ones furthest away from ourself, using Manhattan distance)\n+\t\t//\n+\t\t// We wish to measure the error in object/world space for each critical transform when testing a\n+\t\t// new bit rate. To that end, we need to carefully consider the best approach to avoid\n+\t\t// algorithmic complexity exploding.\n+\t\t//\n+\t\t// Let us use a single bone chain as an example:\n+\t\t//     r = (c2 * c1) * t * (p2 * p1)\n+\t\t// Where:\n+\t\t//     c2: a child transform of c1, also a leaf transform\n+\t\t//     c1: a child transform of t\n+\t\t//     t: the transform whose bit rate we are changing\n+\t\t//     p2: parent transform of t\n+\t\t//     p1: parent transform of p2, also a root transform\n+\t\t//     r: resulting local to world for c2\n+\t\t//\n+\t\t// Our key insight is that when 't' changes, the other transforms do not change. This means\n+\t\t// that we can pre-calculate (c2 * c1) and (p2 * p1) and re-use them over and over when testing\n+\t\t// each permutation. This converts our O(N) evaluation where N is the number of transforms\n+\t\t// into O(1) with just 2 multiplications to compute our final local to world transform for 'c2'.\n+\t\t//\n+\t\t// Another key insight is that we wish to start optimizing the leaf transforms first.\n+\t\t// A transform has a single parent, but it can have many children. By optimizing the children\n+\t\t// first, we force the parent to retain more precision to accommodate them but each child can\n+\t\t// use fewer bits. If we went the other way around, a less precise parent may force its children\n+\t\t// to retain more bits.\n+\t\t//\n+\t\t// Our desired algorithm is thus as such:\n+\t\t// for each transform X, sorted children first ...\n+\t\t//     for each bit rate permutation, sorted smallest first ...\n+\t\t//         for each critical transform of X ...\n+\t\t//             for each sample in segment ...\n+\t\t//                 Measure the error in object space, retain max error\n+\t\t//             if max error too high, break\n+\t\t//         if max error below precision threshold\n+\t\t//             update bit rate for X, break\n+\t\t//\n+\t\t// The algorithm complexity is thus as follows: O(T*P*S*C)\n+\t\t// Where:\n+\t\t//     T: number of transforms\n+\t\t//     P: number of permutations to try\n+\t\t//     S: number of samples in segment\n+\t\t//     C: number of critical transforms\n+\t\t//\n+\t\t// To facilitate the transform caching described above, we first compute every transform of\n+\t\t// every sample in object space. These represent the t * (p2 * p1) part above for each transform.\n+\t\t// This is reasonable because segments are fairly small and have a max of 32 samples.\n+\t\t// Our algorithm starts at the leaves. The (c2 * c1) portion is thus missing, conceptually we can\n+\t\t// use the identity instead. Once we find the best bit rate for each transform, we need to update\n+\t\t// our cached values so that our parent transforms can leverage them. We move on from there.\n+\t\t//\n+\t\t// Let us walk through an example for this transform chain (child left, parent right):\n+\t\t//     A, B, C, D\n+\t\t// A is a leaf while D is a root. The process here is shown for children, but the treatment of the dominant\n+\t\t// transform is similar.\n+\t\t//\n+\t\t// First we optimize A, it has no children and so only the cached dominant transform needs to be updated: itself.\n+\t\t// We have no children and so (c2 * c1) is the identity while (p2 * p1) is B's cached transform.\n+\t\t// We set A's cached transform to A * identity (because it has no children)\n+\t\t// Next, we move to optimize B. A's cached transform represents (c2 * c1) above while C's cached transform is (p2 * p1).\n+\t\t// We set A's cached transform to A * B (we roll B's transform into it).\n+\t\t// Next, we move to optimize C. A's cached transform represents (c2 * c1) while D's cached transform is (p2 * p1).\n+\t\t// We set A's cached transform to A * B * C.\n+\t\t// Finally, we move to optimize D. It has no parent and so the (p2 * p1) portion is the identity transform.\n+\t\t// We update A similarly and the process ends.\n+\t\t//\n+\t\t// Only leaf cached transforms and dominant transforms need to be updated. Other intermediary transforms can remain\n+\t\t// unchanged since they are no longer needed once optimized: their final values are rolled up into the cached critical\n+\t\t// transforms as we progress through the optimization process.\n+\t\t//\n+\t\t// Non-uniform 3D scale throws a wrench in the mix because Realtime Math's qvv type is not associative under multiplication\n+\t\t// when non-uniform scale is present. As such, the multiplication order is important and we cannot leverage caching\n+\t\t// as effectively. We have to calculate the object space transforms by traversing the transform chains manually.\n+\t\t// This is quite a bit slower, but thankfully, non-uniform 3D scale is uncommon. When it is, we take a slower path\n+\t\t// that does not leverage associativity. Instead, the cached transforms will contain local space values once they\n+\t\t// have been optimized. We then multiply them one by one using transform chains as needed.\n+\t\t//////////////////////////////////////////////////////////////////////////\n+\t\tinline void find_optimal_bit_rates(quantization_context& context)\n+\t\t{\n+\t\t\tACL_ASSERT(context.is_valid(), \"quantization_context isn't valid\");\n+\n+\t\t\tinitialize_bone_bit_rates(*context.segment, context.rotation_format, context.translation_format, context.scale_format, context.bit_rate_per_bone);\n+\n+\t\t\tconst uint32_t num_transforms = context.num_bones;\n+\t\t\tconst uint32_t num_samples = context.num_samples;\n+\t\t\tconst float sample_rate = context.sample_rate;\n+\t\t\tconst float clip_duration = context.clip_duration;\n+\t\t\tconst bool has_additive_base = context.has_additive_base;\n+\t\t\tconst additive_clip_format8 additive_format = context.clip.additive_format;\n+\n+\t\t\tconst bool rotation_supports_constant_tracks = context.segment->are_rotations_normalized;\n+\t\t\tconst bool translation_supports_constant_tracks = context.segment->are_translations_normalized;\n+\t\t\tconst bool scale_supports_constant_tracks = context.segment->are_scales_normalized;\n+\n+\t\t\trtm::qvvf* additive_base_local_transforms = has_additive_base ? allocate_type_array<rtm::qvvf>(context.allocator, num_transforms * num_samples) : nullptr;\n+\t\t\trtm::qvvf* object_transforms_raw = allocate_type_array<rtm::qvvf>(context.allocator, num_transforms * num_samples);\n+\t\t\trtm::qvvf* cached_transforms_lossy = allocate_type_array<rtm::qvvf>(context.allocator, num_transforms * num_samples);\n+\n+\t\t\tuint32_t* critical_transform_indices = allocate_type_array<uint32_t>(context.allocator, num_transforms);\n+\n+\t\t\tif (!context.all_local_query.is_bound())\n+\t\t\t\tcontext.all_local_query.bind(context.bit_rate_database);\n+\t\t\tcontext.all_local_query.build(context.bit_rate_per_bone);\n+\n+\t\t\t// Build our cached transforms by sampling everything and converting our segment to object space\n+\t\t\tfor (uint32_t sample_index = 0; sample_index < num_samples; ++sample_index)\n+\t\t\t{\n+\t\t\t\t// The sample time is calculated from the full clip duration to be consistent with decompression\n+\t\t\t\tconst float sample_time = rtm::scalar_min(float(context.segment->clip_sample_offset + sample_index) / sample_rate, clip_duration);\n+\n+\t\t\t\trtm::qvvf* object_pose_raw = object_transforms_raw + (sample_index * num_transforms);\n+\t\t\t\trtm::qvvf* cached_pose_lossy = cached_transforms_lossy + (sample_index * num_transforms);\n+\n+\t\t\t\t// In local space\n+\t\t\t\tsample_streams(context.raw_bone_streams, num_transforms, sample_time, object_pose_raw);\n+\t\t\t\tcontext.bit_rate_database.sample(context.all_local_query, sample_time, cached_pose_lossy, num_transforms);\n+\n+\t\t\t\tif (has_additive_base)\n+\t\t\t\t{\n+\t\t\t\t\trtm::qvvf* additive_base_pose_transforms = additive_base_local_transforms + (sample_index * num_transforms);\n+\n+\t\t\t\t\tconst float normalized_sample_time = context.additive_base_clip.num_samples > 1 ? (sample_time / clip_duration) : 0.0F;\n+\t\t\t\t\tconst float additive_sample_time = context.additive_base_clip.num_samples > 1 ? (normalized_sample_time * context.additive_base_clip.duration) : 0.0F;\n+\t\t\t\t\tsample_streams(context.additive_base_clip.segments[0].bone_streams, num_transforms, additive_sample_time, additive_base_pose_transforms);\n+\n+\t\t\t\t\t// Apply our additives onto our base\n+\t\t\t\t\tfor (uint32_t transform_index = 0; transform_index < num_transforms; ++transform_index)\n+\t\t\t\t\t{\n+\t\t\t\t\t\tobject_pose_raw[transform_index] = rtm::qvv_normalize(acl::apply_additive_to_base(additive_format, additive_base_pose_transforms[transform_index], object_pose_raw[transform_index]));\n+\t\t\t\t\t\tcached_pose_lossy[transform_index] = rtm::qvv_normalize(acl::apply_additive_to_base(additive_format, additive_base_pose_transforms[transform_index], cached_pose_lossy[transform_index]));\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\t// Convert our poses to object space\n+\t\t\t\tfor (uint32_t transform_index : context.topology->roots_first_iterator())\n+\t\t\t\t{\n+\t\t\t\t\tconst uint32_t parent_transform_index = context.topology->transforms[transform_index].parent_index;\n+\t\t\t\t\tif (parent_transform_index != k_invalid_track_index)\n+\t\t\t\t\t{\n+\t\t\t\t\t\tobject_pose_raw[transform_index] = rtm::qvv_normalize(rtm::qvv_mul(object_pose_raw[transform_index], object_pose_raw[parent_transform_index]));\n+\t\t\t\t\t\tcached_pose_lossy[transform_index] = rtm::qvv_normalize(rtm::qvv_mul(cached_pose_lossy[transform_index], cached_pose_lossy[parent_transform_index]));\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\t// If we have non-uniform 3D scale, we cannot rely on associativity, fall back to the transform chain\n+\t\t\tconst bool has_scale = context.has_scale;\n+\n+\t\t\tconst uint32_t max_num_transform_chains = context.topology->num_max_leaves_per_transform + 1;\t// +1 since we have a dominant transform as well\n+\t\t\tconst uint32_t max_chain_length = context.topology->max_leaf_depth + 1;\t\t\t\t\t\t\t// +1 since depth is 0-based\n+\n+\t\t\tuint32_t* transform_chain_indices = nullptr;\n+\t\t\tuint32_t** transform_chains = nullptr;\n+\t\t\tuint32_t* transform_chain_counts = nullptr;\n+\n+\t\t\tif (has_scale)\n+\t\t\t{\n+\t\t\t\ttransform_chain_indices = allocate_type_array<uint32_t>(context.allocator, max_num_transform_chains * max_chain_length);\n+\t\t\t\ttransform_chains = allocate_type_array<uint32_t*>(context.allocator, max_num_transform_chains);\n+\t\t\t\ttransform_chain_counts = allocate_type_array<uint32_t>(context.allocator, max_num_transform_chains);\n+\n+\t\t\t\tfor (uint32_t chain_index = 0; chain_index < max_num_transform_chains; ++chain_index)\n+\t\t\t\t\ttransform_chains[chain_index] = (chain_index * max_chain_length) + transform_chain_indices;\n+\t\t\t}\n+\n+\t\t\t// We try permutations from the lowest memory footprint to the highest.\n+\t\t\tconst uint8_t* const bit_rate_permutations_per_dofs[] =\n+\t\t\t{\n+\t\t\t\t&acl_impl::k_local_bit_rate_permutations_1_dof[0][0],\n+\t\t\t\t&acl_impl::k_local_bit_rate_permutations_2_dof[0][0],\n+\t\t\t\t&acl_impl::k_local_bit_rate_permutations_3_dof[0][0],\n+\t\t\t};\n+\t\t\tconst size_t num_bit_rate_permutations_per_dofs[] =\n+\t\t\t{\n+\t\t\t\tget_array_size(acl_impl::k_local_bit_rate_permutations_1_dof),\n+\t\t\t\tget_array_size(acl_impl::k_local_bit_rate_permutations_2_dof),\n+\t\t\t\tget_array_size(acl_impl::k_local_bit_rate_permutations_3_dof),\n+\t\t\t};\n+\n+\t\t\tfor (const uint32_t transform_index : context.topology->leaves_first_iterator())\n+\t\t\t{\n+\t\t\t\tconst transform_topology_t& transform_topology = context.topology->transforms[transform_index];\n+\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_BASIC_INFO\n+\t\t\t\tprintf(\"%8u: parent: %3u, dominant: %3u\\n\",\n+\t\t\t\t\ttransform_index, context.parent_transform_indices[transform_index],\n+\t\t\t\t\tcontext.shell_metadata_per_transform[transform_index].dominant_transform_index);\n+#endif\n+\n+\t\t\t\t// Find our critical transform set: leaves + dominant\n+\t\t\t\tuint32_t num_critical_transforms = 0;\n+\t\t\t\tfor (const uint32_t leaf_transform_index : make_iterator(transform_topology.leaves, transform_topology.num_leaves))\n+\t\t\t\t\tcritical_transform_indices[num_critical_transforms++] = leaf_transform_index;\n+\n+\t\t\t\tconst uint32_t dominant_transform_index = context.shell_metadata_per_transform[transform_index].dominant_transform_index;\n+\t\t\t\tif (!std::any_of(critical_transform_indices, critical_transform_indices + num_critical_transforms, [dominant_transform_index](uint32_t value) { return value == dominant_transform_index; }))\n+\t\t\t\t\tcritical_transform_indices[num_critical_transforms++] = dominant_transform_index;\n+\n+\t\t\t\t// Non-uniform 3D scale requires slower full chain processing because we can't leverage associativity\n+\t\t\t\tif (has_scale)\n+\t\t\t\t{\n+\t\t\t\t\t// Build our critical transform chains up to the transform we are optimizing\n+\t\t\t\t\tfor (uint32_t critical_chain_index = 0; critical_chain_index < num_critical_transforms; ++critical_chain_index)\n+\t\t\t\t\t{\n+\t\t\t\t\t\tconst uint32_t critical_transform_index = critical_transform_indices[critical_chain_index];\n+\t\t\t\t\t\tuint32_t* transform_chain = transform_chains[critical_chain_index];\n+\n+\t\t\t\t\t\tuint32_t chain_length = 0;\n+\t\t\t\t\t\tuint32_t chain_transform_index = critical_transform_index;\n+\n+\t\t\t\t\t\t// Add our critical transform index\n+\t\t\t\t\t\ttransform_chain[chain_length++] = chain_transform_index;\n+\n+\t\t\t\t\t\twhile (chain_transform_index != transform_index)\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\t// If we haven't reached our optimizing transform, add the next one\n+\t\t\t\t\t\t\tchain_transform_index = context.topology->transforms[chain_transform_index].parent_index;\n+\n+\t\t\t\t\t\t\ttransform_chain[chain_length++] = chain_transform_index;\n+\t\t\t\t\t\t}\n+\n+\t\t\t\t\t\ttransform_chain_counts[critical_chain_index] = chain_length;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\t// Bit rates at this point are one of three value:\n+\t\t\t\t// 0: if the segment track is normalized, it can be constant within the segment\n+\t\t\t\t// 1: if the segment track isn't normalized, it starts at the lowest bit rate\n+\t\t\t\t// 255: if the track is constant/default for the whole clip\n+\t\t\t\tconst transform_bit_rates bone_bit_rates = context.bit_rate_per_bone[transform_index];\n+\n+\t\t\t\tif (bone_bit_rates.rotation == k_invalid_bit_rate && bone_bit_rates.translation == k_invalid_bit_rate && bone_bit_rates.scale == k_invalid_bit_rate)\n+\t\t\t\t{\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_BASIC_INFO\n+\t\t\t\t\tconst float transform_precision = context.shell_metadata_per_transform[transform_index].precision;\n+\t\t\t\t\tconst float error = calculate_max_error_at_bit_rate_local(context, transform_index, error_scan_stop_condition::until_end_of_segment);\n+\t\t\t\t\tprintf(\"%8u: Best bit rates: [%3u, %3u, %3u](  0) @ %.4f%s (all constant)\\n\",\n+\t\t\t\t\t\ttransform_index, bone_bit_rates.rotation, bone_bit_rates.translation, bone_bit_rates.scale,\n+\t\t\t\t\t\terror, error < transform_precision ? \"\" : \" (too high)\");\n+#endif\n+\n+\t\t\t\t\t// Update our cached transforms using our existing bit rate\n+\t\t\t\t\tfor (const uint32_t critical_transform_index : make_iterator(critical_transform_indices, num_critical_transforms))\n+\t\t\t\t\t{\n+\t\t\t\t\t\tif (has_scale)\n+\t\t\t\t\t\t\tupdate_cached_transforms_with_non_uniform_scale(context, transform_index, additive_base_local_transforms, cached_transforms_lossy);\n+\t\t\t\t\t\telse\n+\t\t\t\t\t\t\tupdate_cached_transforms(context, transform_index, critical_transform_index, additive_base_local_transforms, cached_transforms_lossy);\n+\t\t\t\t\t}\n+\n+\t\t\t\t\tcontinue;\t// Every track bit rate is constant/default, nothing else to do\n+\t\t\t\t}\n+\n+\t\t\t\ttransform_bit_rates best_bit_rates = bone_bit_rates;\n+\t\t\t\tfloat best_error = 1.0E10F;\n+\t\t\t\tuint32_t prev_transform_size = ~0U;\n+\t\t\t\tbool is_error_good_enough = false;\n+\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_BASIC_INFO\n+#if 0\n+\t\t\t\tfloat best_permutation_group_optimization_room = FLT_MAX;\n+\t\t\t\tsize_t best_permutation_group_index = 0;\n+#endif\n+\t\t\t\tsize_t best_permutation_index = 0;\n+\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_VERBOSE_INFO\n+\t\t\t\tfloat best_transform_error = 1.0E10F;\n+\t\t\t\ttransform_bit_rates best_transform_bit_rates = bone_bit_rates;\n+#endif\n+#endif\n+\n+\t\t\t\t// Determine how many degrees of freedom we have to optimize our bit rates\n+\t\t\t\tuint32_t num_dof = 0;\n+\t\t\t\tnum_dof += bone_bit_rates.rotation != k_invalid_bit_rate ? 1 : 0;\n+\t\t\t\tnum_dof += bone_bit_rates.translation != k_invalid_bit_rate ? 1 : 0;\n+\t\t\t\tnum_dof += bone_bit_rates.scale != k_invalid_bit_rate ? 1 : 0;\n+\n+\t\t\t\tconst uint8_t* bit_rate_permutations_per_dof = bit_rate_permutations_per_dofs[num_dof - 1];\n+\t\t\t\tconst size_t num_bit_rate_permutations = num_bit_rate_permutations_per_dofs[num_dof - 1];\n+\n+\t\t\t\t// Our desired bit rates start with the initial value\n+\t\t\t\ttransform_bit_rates desired_bit_rates = bone_bit_rates;\n+\n+\t\t\t\tsize_t permutation_offset = 0;\n+\t\t\t\tfor (size_t permutation_index = 0; permutation_index < num_bit_rate_permutations; ++permutation_index)\n+\t\t\t\t{\n+\t\t\t\t\t// If a bit rate is variable, grab a permutation for it\n+\t\t\t\t\t// We'll only consume as many bit rates as we have degrees of freedom\n+\n+\t\t\t\t\tuint32_t transform_size = 0;\t// In bits\n+\n+\t\t\t\t\tif (desired_bit_rates.rotation != k_invalid_bit_rate)\n+\t\t\t\t\t{\n+\t\t\t\t\t\tdesired_bit_rates.rotation = bit_rate_permutations_per_dof[permutation_offset++];\n+\t\t\t\t\t\ttransform_size += get_num_bits_at_bit_rate(desired_bit_rates.rotation);\n+\t\t\t\t\t}\n+\n+\t\t\t\t\tif (desired_bit_rates.translation != k_invalid_bit_rate)\n+\t\t\t\t\t{\n+\t\t\t\t\t\tdesired_bit_rates.translation = bit_rate_permutations_per_dof[permutation_offset++];\n+\t\t\t\t\t\ttransform_size += get_num_bits_at_bit_rate(desired_bit_rates.translation);\n+\t\t\t\t\t}\n+\n+\t\t\t\t\tif (desired_bit_rates.scale != k_invalid_bit_rate)\n+\t\t\t\t\t{\n+\t\t\t\t\t\tdesired_bit_rates.scale = bit_rate_permutations_per_dof[permutation_offset++];\n+\t\t\t\t\t\ttransform_size += get_num_bits_at_bit_rate(desired_bit_rates.scale);\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t// If our inputs aren't normalized per segment, we can't store them on 0 bits because we'll have no\n+\t\t\t\t\t// segment range information. This occurs when we have a single segment. Skip those permutations.\n+\t\t\t\t\tif (!rotation_supports_constant_tracks && desired_bit_rates.rotation == 0)\n+\t\t\t\t\t\tcontinue;\n+\t\t\t\t\telse if (!translation_supports_constant_tracks && desired_bit_rates.translation == 0)\n+\t\t\t\t\t\tcontinue;\n+\t\t\t\t\telse if (!scale_supports_constant_tracks && desired_bit_rates.scale == 0)\n+\t\t\t\t\t\tcontinue;\n+\n+\t\t\t\t\tif (transform_size > prev_transform_size)\n+\t\t\t\t\t{\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_VERBOSE_INFO\n+\t\t\t\t\t\tprintf(\"%8u: [%3u | %3u | %3u] best with %2u bits @ %.4f\\n\", transform_index, best_transform_bit_rates.rotation, best_transform_bit_rates.translation, best_transform_bit_rates.scale, prev_transform_size, best_transform_error);\n+#endif\n+\n+\t\t\t\t\t\t// Reset\n+\t\t\t\t\t\tbest_transform_error = 1.0E10F;\n+\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_BASIC_INFO && 0\n+\t\t\t\t\t\tbest_permutation_group_optimization_room = FLT_MAX;\n+#endif\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t// If we already found a permutation that is good enough, we test all the others\n+\t\t\t\t\t// that have the same size. Once the size changes, we stop.\n+\t\t\t\t\tif (is_error_good_enough && transform_size != prev_transform_size)\n+\t\t\t\t\t\tbreak;\n+\n+\t\t\t\t\tprev_transform_size = transform_size;\n+\n+\t\t\t\t\tcontext.bit_rate_per_bone[transform_index] = desired_bit_rates;\n+\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_VERBOSE_INFO\n+\t\t\t\t\tprintf(\"            Measuring [%3u | %3u | %3u] (%2u bits) ...\\n\", desired_bit_rates.rotation, desired_bit_rates.translation, desired_bit_rates.scale, transform_size);\n+#endif\n+\n+\t\t\t\t\t// Calculate the error for each critical transform and find the least precise one\n+#if 0\n+\t\t\t\t\tfloat worst_critical_transform_room = 0.0F;\n+\t\t\t\t\tuint32_t worst_critical_transform_index = ~0U;\n+#endif\n+\n+\t\t\t\t\tfloat worst_critical_transform_error = 0.0F;\n+\t\t\t\t\tbool is_permutation_good_enough = true;\n+\n+\t\t\t\t\tfor (uint32_t critical_chain_index = 0; critical_chain_index < num_critical_transforms; ++critical_chain_index)\n+\t\t\t\t\t{\n+\t\t\t\t\t\tconst uint32_t critical_transform_index = critical_transform_indices[critical_chain_index];\n+\n+\t\t\t\t\t\tfloat critical_transform_error;\n+\t\t\t\t\t\tif (has_scale)\n+\t\t\t\t\t\t\tcritical_transform_error = calculate_max_error_at_bit_rate_object_cached_with_non_uniform_scale(\n+\t\t\t\t\t\t\t\tcontext,\n+\t\t\t\t\t\t\t\ttransform_index, critical_transform_index,\n+\t\t\t\t\t\t\t\ttransform_chains[critical_chain_index], transform_chain_counts[critical_chain_index],\n+\t\t\t\t\t\t\t\tadditive_base_local_transforms,\n+\t\t\t\t\t\t\t\tobject_transforms_raw,\n+\t\t\t\t\t\t\t\tcached_transforms_lossy,\n+\t\t\t\t\t\t\t\tbest_error);\n+\t\t\t\t\t\telse\n+\t\t\t\t\t\t\tcritical_transform_error = calculate_max_error_at_bit_rate_object_cached(\n+\t\t\t\t\t\t\t\tcontext,\n+\t\t\t\t\t\t\t\ttransform_index, critical_transform_index,\n+\t\t\t\t\t\t\t\tadditive_base_local_transforms,\n+\t\t\t\t\t\t\t\tobject_transforms_raw,\n+\t\t\t\t\t\t\t\tcached_transforms_lossy,\n+\t\t\t\t\t\t\t\tbest_error);\n+\n+\t\t\t\t\t\tconst float critical_transform_precision = context.shell_metadata_per_transform[critical_transform_index].precision;\n+\t\t\t\t\t\tis_permutation_good_enough &= critical_transform_error <= critical_transform_precision;\n+\n+\t\t\t\t\t\t// TODO: Try this out\n+#if 0\n+\t\t\t\t\t\t// We wish to find the critical transform that has the least room for further optimization\n+\t\t\t\t\t\t// This is the least precise critical transform\n+\t\t\t\t\t\t// To find the least precise, we compute the remaining optimization room: precision - error\n+\t\t\t\t\t\t// This algorithm uses the precision threshold as a target error to reach but not exceed\n+\t\t\t\t\t\t// As such, if the error is below our threshold (good), we want our positive room to be as close to zero as possible\n+\t\t\t\t\t\t// If the error is below our threshold (bad), we want our negative room to be as close to zero as possible\n+\t\t\t\t\t\t// If all our critical transforms are below their precision threshold, their values will be between [0.0, precision]\n+\t\t\t\t\t\t// and the least precise is the one with the largest value.\n+\t\t\t\t\t\t// If any critical transform is above their precision threshold, its value will be negative\n+\t\t\t\t\t\tconst float optimization_room = critical_transform_precision - critical_transform_error;\n+\n+\t\t\t\t\t\tif (worst_critical_transform_room >= 0.0F)\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\tif (optimization_room < 0.0F || optimization_room >= worst_critical_transform_room)\n+\t\t\t\t\t\t\t{\n+\t\t\t\t\t\t\t\tworst_critical_transform_room = optimization_room;\n+\t\t\t\t\t\t\t\tworst_critical_transform_index = critical_transform_index;\n+\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t}\n+\t\t\t\t\t\telse\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\tif (optimization_room < worst_critical_transform_room)\n+\t\t\t\t\t\t\t{\n+\t\t\t\t\t\t\t\tworst_critical_transform_room = optimization_room;\n+\t\t\t\t\t\t\t\tworst_critical_transform_index = critical_transform_index;\n+\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t}\n+#endif\n+\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_VERBOSE_INFO\n+\t\t\t\t\t\tprintf(\"            %8u @ %.4f\\n\", critical_transform_index, critical_transform_error);\n+#endif\n+\n+\t\t\t\t\t\t// We are only as precise as our least precise critical transform\n+\t\t\t\t\t\tworst_critical_transform_error = rtm::scalar_max(critical_transform_error, worst_critical_transform_error);\n+\n+\t\t\t\t\t\tif (critical_transform_error >= best_error)\n+\t\t\t\t\t\t\tbreak;\t// The error of this transform is too high, this permutation will not be selected\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t\n+\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_BASIC_INFO && 0\n+\t\t\t\t\t// Now that we found the least precise critical transform, we can use it to find the best permutation\n+\t\t\t\t\t// The best permutation will have positive optimization room as close to zero as possible\n+\t\t\t\t\t// If none of the permutations have positive optimization room, then the best one is as close to zero as well\n+\n+\t\t\t\t\t// Track the best permutation of its group (all permutations with same size)\n+\t\t\t\t\tif (best_permutation_group_optimization_room == FLT_MAX)\n+\t\t\t\t\t{\n+\t\t\t\t\t\t// First permutation of the group\n+\t\t\t\t\t\tbest_permutation_group_optimization_room = worst_critical_transform_room;\n+\t\t\t\t\t\tbest_permutation_group_index = permutation_index;\n+\t\t\t\t\t}\n+\t\t\t\t\telse if (worst_critical_transform_room >= 0.0F)\n+\t\t\t\t\t{\n+\t\t\t\t\t\t// This permutation is a good one and it meets our desired precision\n+\t\t\t\t\t\tif (best_permutation_group_optimization_room < 0.0F || worst_critical_transform_room < best_permutation_group_optimization_room)\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\tbest_permutation_group_optimization_room = worst_critical_transform_room;\n+\t\t\t\t\t\t\tbest_permutation_group_index = permutation_index;\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t\telse\n+\t\t\t\t\t{\n+\t\t\t\t\t\t// This permutation isn't meeting our desired precision\n+\t\t\t\t\t\tif (worst_critical_transform_room < best_permutation_group_optimization_room)\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\tbest_permutation_group_optimization_room = worst_critical_transform_room;\n+\t\t\t\t\t\t\tbest_permutation_group_index = permutation_index;\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+#endif\n+\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_VERBOSE_INFO\n+\t\t\t\t\tif (worst_critical_transform_error < best_transform_error)\n+\t\t\t\t\t{\n+\t\t\t\t\t\tbest_transform_error = worst_critical_transform_error;\n+\t\t\t\t\t\tbest_transform_bit_rates = desired_bit_rates;\n+\t\t\t\t\t}\n+#endif\n+\n+\t\t\t\t\tif (worst_critical_transform_error < best_error)\n+\t\t\t\t\t{\n+\t\t\t\t\t\tbest_error = worst_critical_transform_error;\n+\t\t\t\t\t\tbest_bit_rates = desired_bit_rates;\n+\t\t\t\t\t\tis_error_good_enough = is_permutation_good_enough;\n+\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_BASIC_INFO\n+\t\t\t\t\t\tbest_permutation_index = permutation_index;\n+#endif\n+\t\t\t\t\t}\n+\n+\t\t\t\t\tif (permutation_index + 1 == num_bit_rate_permutations)\n+\t\t\t\t\t{\n+\t\t\t\t\t\t// Last entry before we exit the loop\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_VERBOSE_INFO\n+\t\t\t\t\t\tprintf(\"%8u: [%3u | %3u | %3u] best with %2u bits @ %.4f\\n\", transform_index, best_transform_bit_rates.rotation, best_transform_bit_rates.translation, best_transform_bit_rates.scale, prev_transform_size, best_transform_error);\n+#endif\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_BASIC_INFO\n+\t\t\t\tprintf(\"%8u: Best bit rates: [%3u, %3u, %3u](%2u bits) perm#[%5u] @ %.4f%s (object)\\n\",\n+\t\t\t\t\ttransform_index, best_bit_rates.rotation, best_bit_rates.translation, best_bit_rates.scale,\n+\t\t\t\t\tbest_bit_rates.get_num_bits(), uint32_t(best_permutation_index), best_error, is_error_good_enough ? \"\" : \" (too high)\");\n+#endif\n+\n+\t\t\t\tcontext.bit_rate_per_bone[transform_index] = best_bit_rates;\n+\n+\t\t\t\t// Update our cached transforms using our new bit rate\n+\t\t\t\tfor (const uint32_t critical_transform_index : make_iterator(critical_transform_indices, num_critical_transforms))\n+\t\t\t\t{\n+\t\t\t\t\tif (has_scale)\n+\t\t\t\t\t\tupdate_cached_transforms_with_non_uniform_scale(context, transform_index, additive_base_local_transforms, cached_transforms_lossy);\n+\t\t\t\t\telse\n+\t\t\t\t\t\tupdate_cached_transforms(context, transform_index, critical_transform_index, additive_base_local_transforms, cached_transforms_lossy);\n+\t\t\t\t}\n+\t\t\t}\n+\n+#if ACL_IMPL_DEBUG_VARIABLE_QUANTIZATION >= ACL_IMPL_DEBUG_LEVEL_SUMMARY_ONLY\n+\t\t\tuint32_t total_num_bits = 0;\n+\t\t\tfor (uint32_t transform_index = 0; transform_index < num_transforms; ++transform_index)\n+\t\t\t\ttotal_num_bits += context.bit_rate_per_bone[transform_index].get_num_bits();\n+\t\t\tprintf(\"Variable quantization optimization results (total size %u bits):\\n\", total_num_bits);\n+\t\t\tfor (uint32_t transform_index = 0; transform_index < num_transforms; ++transform_index)\n+\t\t\t{\n+\t\t\t\tconst float transform_precision = context.shell_metadata_per_transform[transform_index].precision;\n+\t\t\t\tconst transform_bit_rates& bone_bit_rate = context.bit_rate_per_bone[transform_index];\n+\n+\t\t\t\tconst uint32_t num_bones_in_chain = calculate_bone_chain_indices(context.clip, transform_index, context.chain_bone_indices);\n+\t\t\t\tconst float error = calculate_max_error_at_bit_rate_object(context, transform_index, context.chain_bone_indices, num_bones_in_chain);\n+\n+\t\t\t\tprintf(\"%8u: [%3u, %3u, %3u][%3u] @ %.4f%s\\n\", transform_index,\n+\t\t\t\t\tbone_bit_rate.rotation, bone_bit_rate.translation, bone_bit_rate.scale,\n+\t\t\t\t\tbone_bit_rate.get_num_bits(), error, error < transform_precision ? \"\" : \" (too high)\");\n+\t\t\t}\n+#endif\n+\n+\t\t\tdeallocate_type_array(context.allocator, additive_base_local_transforms, num_transforms);\n+\t\t\tdeallocate_type_array(context.allocator, object_transforms_raw, num_transforms * num_samples);\n+\t\t\tdeallocate_type_array(context.allocator, cached_transforms_lossy, num_transforms * num_samples);\n+\t\t\tdeallocate_type_array(context.allocator, critical_transform_indices, num_transforms);\n+\t\t\tdeallocate_type_array(context.allocator, transform_chain_indices, max_num_transform_chains * max_chain_length);\n+\t\t\tdeallocate_type_array(context.allocator, transform_chains, max_num_transform_chains);\n+\t\t\tdeallocate_type_array(context.allocator, transform_chain_counts, max_num_transform_chains);\n+\t\t}\n+\n #endif\n \n \t\t// Partitioning will be done as follow in two phases: calculating the error contribution for every frame and a global optimization pass."
      }
    ],
    "lines_added": 802,
    "lines_removed": 2
  },
  "issues": [],
  "pull_requests": [],
  "build_info": {
    "old_build_script": [
      "apt-get update",
      "cmake -S /test_workspace/workspace/old -B /test_workspace/workspace/old/build -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=ON -DBUILD_TESTING=ON -DBENCHMARK_ENABLE_GTEST_TESTS=ON -DCATCH_BUILD_TESTING=ON -DBENCHMARK_ENABLE_TESTING=ON -DINCLUDE_UNIT_TESTS=ON -DBENCHMARK_USE_BUNDLED_GTEST=ON -DBENCHMARK_ENABLE_ASSEMBLY_TESTS=ON",
      "cmake --build /test_workspace/workspace/old/build -- -j 1"
    ],
    "new_build_script": [
      "apt-get update",
      "cmake -S /test_workspace/workspace/new -B /test_workspace/workspace/new/build -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=ON -DBUILD_TESTING=ON -DBENCHMARK_ENABLE_GTEST_TESTS=ON -DCATCH_BUILD_TESTING=ON -DBENCHMARK_ENABLE_TESTING=ON -DINCLUDE_UNIT_TESTS=ON -DBENCHMARK_USE_BUNDLED_GTEST=ON -DBENCHMARK_ENABLE_ASSEMBLY_TESTS=ON",
      "cmake --build /test_workspace/workspace/new/build -- -j 1"
    ],
    "old_test_script": [
      "cd /test_workspace/workspace/old/build",
      "ctest --output-on-failure"
    ],
    "new_test_script": [
      "cd /test_workspace/workspace/new/build",
      "ctest --output-on-failure"
    ],
    "build_system": "cmake"
  },
  "performance_analysis": {
    "is_significant": false,
    "p_value": 1.0,
    "is_pair_significant": false,
    "pair_p_value": 1.0,
    "is_binom_significant": false,
    "binom_p_value": 1.0,
    "is_wilcoxon_significant": false,
    "wilcoxon_p_value": 1.0,
    "is_mannwhitney_significant": false,
    "mannwhitney_p_value": 0.3808804664862381,
    "relative_improvement": 5.7470383595630477e-05,
    "absolute_improvement_ms": 14.999999999986358,
    "old_mean_ms": 261004.00000000003,
    "new_mean_ms": 260989.00000000003,
    "old_std_ms": 526.8946109370307,
    "new_std_ms": 640.4543107341301,
    "effect_size_cohens_d": 0.025578512218301475,
    "old_ci95_ms": [
      260807.25431885134,
      261200.7456811487
    ],
    "new_ci95_ms": [
      260749.85043005875,
      261228.1495699413
    ],
    "old_ci99_ms": [
      260738.84296777516,
      261269.15703222487
    ],
    "new_ci99_ms": [
      260666.69462662018,
      261311.30537337987
    ],
    "new_times_s": [
      261.64,
      260.61,
      261.38,
      260.88,
      260.94,
      260.79,
      260.36,
      260.44,
      260.51,
      261.63,
      263.88,
      260.77,
      261.04,
      260.88,
      261.05,
      260.62,
      260.74,
      260.87,
      261.12,
      261.0,
      261.17,
      260.96,
      260.84,
      260.49,
      260.66,
      261.8,
      260.39,
      260.74,
      261.09,
      261.17,
      260.85
    ],
    "old_times_s": [
      261.41,
      260.79,
      261.24,
      260.93,
      260.68,
      260.38,
      261.0,
      260.89,
      261.3,
      260.94,
      260.82,
      263.04,
      262.38,
      260.97,
      260.88,
      260.7,
      260.68,
      260.86,
      260.5,
      260.7,
      260.7,
      261.15,
      260.68,
      260.74,
      260.95,
      261.34,
      260.65,
      261.13,
      260.96,
      260.81,
      261.33
    ]
  },
  "tests": {
    "total_tests": 9,
    "significant_improvements": 0,
    "significant_improvements_tests": [],
    "significant_regressions": 0,
    "significant_regressions_tests": [],
    "significant_pair_improvements": 0,
    "significant_pair_improvements_tests": [],
    "significant_pair_regressions": 0,
    "significant_pair_regressions_tests": [],
    "significant_binom_improvements": 0,
    "significant_binom_improvements_tests": [],
    "significant_binom_regressions": 0,
    "significant_binom_regressions_tests": [],
    "significant_wilcoxon_improvements": 0,
    "significant_wilcoxon_improvements_tests": [],
    "significant_wilcoxon_regressions": 0,
    "significant_wilcoxon_regressions_tests": [],
    "significant_mannwhitney_improvements": 0,
    "significant_mannwhitney_improvements_tests": [],
    "significant_mannwhitney_regressions": 0,
    "significant_mannwhitney_regressions_tests": [],
    "tests": [
      {
        "test_name": "scalar",
        "is_significant": false,
        "p_value": 1.0,
        "is_pair_significant": false,
        "pair_p_value": 1.0,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999993480755726,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.9273651841355476,
        "relative_improvement": -0.0011783189316575465,
        "absolute_improvement_ms": -1.071428571428834,
        "old_mean_ms": 909.2857142857141,
        "new_mean_ms": 910.357142857143,
        "old_std_ms": 7.16398990247412,
        "new_std_ms": 4.28791830452067,
        "effect_size_cohens_d": -0.18148210641040166,
        "old_ci95_ms": [
          906.5078090003269,
          912.0636195711014
        ],
        "new_ci95_ms": [
          908.6944617138707,
          912.0198240004153
        ],
        "old_ci99_ms": [
          905.5345785223551,
          913.0368500490732
        ],
        "new_ci99_ms": [
          908.1119465459512,
          912.6023391683347
        ],
        "new_times": [
          0.91,
          0.91,
          0.91,
          0.91,
          0.91,
          0.93,
          0.91,
          0.91,
          0.91,
          0.91,
          0.91,
          0.91,
          0.91,
          0.91,
          0.9,
          0.91,
          0.91,
          0.91,
          0.91,
          0.91,
          0.91,
          0.91,
          0.91,
          0.91,
          0.91,
          0.91,
          0.91,
          0.91
        ],
        "old_times": [
          0.91,
          0.91,
          0.91,
          0.91,
          0.91,
          0.91,
          0.91,
          0.9,
          0.9,
          0.91,
          0.91,
          0.91,
          0.91,
          0.91,
          0.91,
          0.9,
          0.91,
          0.91,
          0.91,
          0.9,
          0.91,
          0.91,
          0.91,
          0.91,
          0.91,
          0.91,
          0.94,
          0.9
        ]
      },
      {
        "test_name": "unpack_scalarf_uXX_unsafe",
        "is_significant": false,
        "p_value": 0.9999999031674129,
        "is_pair_significant": false,
        "pair_p_value": 1.0,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999999999880863,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.11132561130121577,
        "relative_improvement": 0.0004923042626118585,
        "absolute_improvement_ms": 26.949152542357524,
        "old_mean_ms": 54740.84745762711,
        "new_mean_ms": 54713.89830508475,
        "old_std_ms": 2713.009073879098,
        "new_std_ms": 2735.2299386095574,
        "effect_size_cohens_d": 0.009892711513065273,
        "old_ci95_ms": [
          54033.833442258976,
          55447.86147299525
        ],
        "new_ci95_ms": [
          54001.09350082863,
          55426.70310934088
        ],
        "old_ci99_ms": [
          53800.164659973336,
          55681.53025528089
        ],
        "new_ci99_ms": [
          53765.51085748999,
          55662.28575267951
        ],
        "new_times": [
          57.15,
          51.88,
          57.32,
          51.97,
          57.27,
          51.85,
          57.26,
          51.82,
          57.28,
          51.87,
          57.19,
          51.81,
          57.15,
          51.82,
          57.13,
          51.97,
          57.52,
          53.03,
          59.17,
          51.91,
          57.26,
          51.94,
          57.53,
          51.84,
          57.26,
          51.95,
          57.43,
          51.91,
          57.3,
          51.92,
          57.26,
          51.89,
          57.57,
          51.88,
          57.36,
          51.94,
          57.32,
          51.96,
          57.18,
          52.06,
          57.38,
          51.92,
          57.26,
          51.83,
          57.22,
          51.89,
          57.24,
          52.98,
          57.17,
          51.95,
          57.27,
          51.85,
          57.27,
          51.97,
          57.39,
          51.85,
          57.47,
          51.82,
          57.26
        ],
        "old_times": [
          57.24,
          52.05,
          57.2,
          51.97,
          57.25,
          52.0,
          57.28,
          51.85,
          57.23,
          52.04,
          57.31,
          51.96,
          57.29,
          51.84,
          57.4,
          51.96,
          57.35,
          51.92,
          57.24,
          54.26,
          57.27,
          51.9,
          58.44,
          51.9,
          57.45,
          51.93,
          57.41,
          51.93,
          57.27,
          51.91,
          57.55,
          51.91,
          57.32,
          51.93,
          57.18,
          51.9,
          57.21,
          51.89,
          57.43,
          52.0,
          57.25,
          51.98,
          57.3,
          51.94,
          57.31,
          51.97,
          57.47,
          52.02,
          57.54,
          51.94,
          57.38,
          52.03,
          57.3,
          51.96,
          57.43,
          51.97,
          57.39,
          51.91,
          57.25
        ]
      },
      {
        "test_name": "pack_vector4_64",
        "is_significant": false,
        "p_value": 1.0,
        "is_pair_significant": false,
        "pair_p_value": 1.0,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999999393422746,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 1.0,
        "relative_improvement": 0.0,
        "absolute_improvement_ms": 0.0,
        "old_mean_ms": 40.0,
        "new_mean_ms": 40.0,
        "old_std_ms": 0.0,
        "new_std_ms": 0.0,
        "effect_size_cohens_d": "NaN",
        "old_ci95_ms": [
          40.0,
          40.0
        ],
        "new_ci95_ms": [
          40.0,
          40.0
        ],
        "old_ci99_ms": [
          40.0,
          40.0
        ],
        "new_ci99_ms": [
          40.0,
          40.0
        ],
        "new_times": [
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04
        ],
        "old_times": [
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04
        ]
      },
      {
        "test_name": "pack_vector4_XX",
        "is_significant": false,
        "p_value": 0.999999782716567,
        "is_pair_significant": false,
        "pair_p_value": 1.0,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999999999881674,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.6103182348099374,
        "relative_improvement": -0.0004112452735352399,
        "absolute_improvement_ms": -6.101694915255251,
        "old_mean_ms": 14837.118644067798,
        "new_mean_ms": 14843.220338983052,
        "old_std_ms": 777.2765248132199,
        "new_std_ms": 777.5213505838128,
        "effect_size_cohens_d": -0.007848859245515713,
        "old_ci95_ms": [
          14634.55927847237,
          15039.678009663223
        ],
        "new_ci95_ms": [
          14640.597171444317,
          15045.843506521787
        ],
        "old_ci99_ms": [
          14567.613221859065,
          15106.624066276529
        ],
        "new_ci99_ms": [
          14573.630028230069,
          15112.810649736035
        ],
        "new_times": [
          15.59,
          14.05,
          15.62,
          14.08,
          15.6,
          13.99,
          15.64,
          14.08,
          15.55,
          13.97,
          15.56,
          14.06,
          15.6,
          14.04,
          15.56,
          14.1,
          15.6,
          14.18,
          15.63,
          14.12,
          15.56,
          14.11,
          15.58,
          14.04,
          15.54,
          14.01,
          15.55,
          14.06,
          15.5,
          14.0,
          15.59,
          14.0,
          15.56,
          14.05,
          15.56,
          14.07,
          15.58,
          14.04,
          15.83,
          14.04,
          15.58,
          14.12,
          15.62,
          14.14,
          15.55,
          13.98,
          15.63,
          14.05,
          15.58,
          14.09,
          15.61,
          14.03,
          15.59,
          14.06,
          15.55,
          14.06,
          15.85,
          14.17,
          15.6
        ],
        "old_times": [
          15.78,
          14.03,
          15.67,
          14.09,
          15.55,
          14.06,
          15.55,
          14.02,
          15.61,
          14.07,
          15.58,
          14.04,
          15.73,
          14.11,
          15.62,
          14.05,
          15.58,
          14.09,
          15.58,
          13.99,
          15.52,
          14.07,
          15.62,
          13.98,
          15.59,
          14.03,
          15.49,
          14.02,
          15.55,
          14.06,
          15.59,
          14.07,
          15.56,
          14.03,
          15.62,
          14.06,
          15.6,
          14.13,
          15.54,
          14.01,
          15.53,
          14.03,
          15.51,
          14.02,
          15.72,
          14.13,
          15.56,
          14.08,
          15.55,
          14.02,
          15.58,
          14.1,
          15.64,
          14.13,
          15.62,
          14.02,
          15.59,
          14.06,
          15.56
        ]
      },
      {
        "test_name": "pack_vector3_48",
        "is_significant": false,
        "p_value": 1.0,
        "is_pair_significant": false,
        "pair_p_value": 1.0,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999999393422746,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 1.0,
        "relative_improvement": 0.0,
        "absolute_improvement_ms": 0.0,
        "old_mean_ms": 30.000000000000004,
        "new_mean_ms": 30.000000000000004,
        "old_std_ms": 3.5331118393247232e-15,
        "new_std_ms": 3.5331118393247232e-15,
        "effect_size_cohens_d": 0.0,
        "old_ci95_ms": [
          30.000000000000004,
          30.000000000000004
        ],
        "new_ci95_ms": [
          30.000000000000004,
          30.000000000000004
        ],
        "old_ci99_ms": [
          30.0,
          30.000000000000007
        ],
        "new_ci99_ms": [
          30.0,
          30.000000000000007
        ],
        "new_times": [
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03
        ],
        "old_times": [
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03
        ]
      },
      {
        "test_name": "decay_vector3_48",
        "is_significant": false,
        "p_value": 1.0,
        "is_pair_significant": false,
        "pair_p_value": 1.0,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999999393422746,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 1.0,
        "relative_improvement": 0.0,
        "absolute_improvement_ms": 0.0,
        "old_mean_ms": 20.0,
        "new_mean_ms": 20.0,
        "old_std_ms": 0.0,
        "new_std_ms": 0.0,
        "effect_size_cohens_d": "NaN",
        "old_ci95_ms": [
          20.0,
          20.0
        ],
        "new_ci95_ms": [
          20.0,
          20.0
        ],
        "old_ci99_ms": [
          20.0,
          20.0
        ],
        "new_ci99_ms": [
          20.0,
          20.0
        ],
        "new_times": [
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02
        ],
        "old_times": [
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02
        ]
      },
      {
        "test_name": "pack_vector3_XX",
        "is_significant": false,
        "p_value": 1.0,
        "is_pair_significant": false,
        "pair_p_value": 1.0,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.999999999988096,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.5631016499224464,
        "relative_improvement": -0.00015395559708225668,
        "absolute_improvement_ms": -4.915254237289446,
        "old_mean_ms": 31926.4406779661,
        "new_mean_ms": 31931.355932203387,
        "old_std_ms": 854.1375216573617,
        "new_std_ms": 851.5087170815848,
        "effect_size_cohens_d": -0.005763502756656604,
        "old_ci95_ms": [
          31703.85122750027,
          32149.030128431932
        ],
        "new_ci95_ms": [
          31709.451551941205,
          32153.26031246557
        ],
        "old_ci99_ms": [
          31630.285209416597,
          32222.5961465156
        ],
        "new_ci99_ms": [
          31636.111950189865,
          32226.599914216913
        ],
        "new_times": [
          32.75,
          31.13,
          32.91,
          31.12,
          32.81,
          31.08,
          32.68,
          31.03,
          32.83,
          31.09,
          32.62,
          31.09,
          32.7,
          31.08,
          32.7,
          31.03,
          32.74,
          30.86,
          32.73,
          31.04,
          32.79,
          31.08,
          32.75,
          31.17,
          32.7,
          31.21,
          32.74,
          31.07,
          32.68,
          31.11,
          32.72,
          31.01,
          32.75,
          31.19,
          32.82,
          31.04,
          32.85,
          31.12,
          32.8,
          31.16,
          32.73,
          31.06,
          32.79,
          30.93,
          32.71,
          31.15,
          32.89,
          31.07,
          32.8,
          30.99,
          32.62,
          30.93,
          32.82,
          31.14,
          32.77,
          31.12,
          32.78,
          31.1,
          32.77
        ],
        "old_times": [
          32.74,
          31.21,
          32.8,
          31.17,
          32.75,
          31.03,
          32.74,
          30.96,
          32.68,
          31.03,
          32.78,
          31.1,
          32.75,
          31.48,
          32.66,
          31.1,
          32.76,
          31.1,
          32.77,
          31.08,
          32.85,
          30.94,
          32.83,
          31.15,
          32.72,
          31.0,
          32.86,
          31.0,
          32.79,
          30.78,
          32.69,
          31.09,
          32.68,
          31.08,
          32.72,
          31.09,
          32.71,
          31.04,
          32.72,
          31.2,
          32.72,
          31.15,
          32.58,
          30.89,
          32.76,
          31.1,
          32.72,
          31.1,
          32.71,
          30.72,
          32.76,
          31.16,
          32.86,
          31.07,
          32.8,
          30.96,
          32.81,
          31.32,
          32.84
        ]
      },
      {
        "test_name": "decay_vector3_XX",
        "is_significant": false,
        "p_value": 1.0,
        "is_pair_significant": false,
        "pair_p_value": 1.0,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999987407945603,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.6083274758421102,
        "relative_improvement": -0.0006758278891642518,
        "absolute_improvement_ms": -1.071428571428834,
        "old_mean_ms": 1585.3571428571427,
        "new_mean_ms": 1586.4285714285716,
        "old_std_ms": 6.372477195601855,
        "new_std_ms": 7.310208850583787,
        "effect_size_cohens_d": -0.15624434890327146,
        "old_ci95_ms": [
          1582.886154158993,
          1587.8281315552924
        ],
        "new_ci95_ms": [
          1583.5939683540603,
          1589.2631745030828
        ],
        "old_ci99_ms": [
          1582.020450952907,
          1588.6938347613784
        ],
        "new_ci99_ms": [
          1582.6008739819883,
          1590.2562688751548
        ],
        "new_times": [
          1.59,
          1.59,
          1.6,
          1.61,
          1.58,
          1.59,
          1.58,
          1.59,
          1.59,
          1.59,
          1.58,
          1.58,
          1.58,
          1.58,
          1.59,
          1.58,
          1.58,
          1.59,
          1.58,
          1.59,
          1.59,
          1.59,
          1.58,
          1.58,
          1.59,
          1.59,
          1.58,
          1.58
        ],
        "old_times": [
          1.59,
          1.59,
          1.59,
          1.59,
          1.58,
          1.59,
          1.59,
          1.58,
          1.59,
          1.58,
          1.58,
          1.58,
          1.58,
          1.58,
          1.58,
          1.59,
          1.58,
          1.6,
          1.59,
          1.59,
          1.59,
          1.59,
          1.57,
          1.59,
          1.58,
          1.58,
          1.59,
          1.58
        ]
      },
      {
        "test_name": "pack_vector2_XX",
        "is_significant": false,
        "p_value": 0.9999999741453712,
        "is_pair_significant": false,
        "pair_p_value": 1.0,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999999999881288,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.574733266058739,
        "relative_improvement": -0.00013450968164005654,
        "absolute_improvement_ms": -3.728813559316535,
        "old_mean_ms": 27721.525423728817,
        "new_mean_ms": 27725.254237288133,
        "old_std_ms": 1333.7512738698272,
        "new_std_ms": 1323.118515728191,
        "effect_size_cohens_d": -0.002806899844412882,
        "old_ci95_ms": [
          27373.94794869561,
          28069.102898762023
        ],
        "new_ci95_ms": [
          27380.447674118266,
          28070.060800458003
        ],
        "old_ci99_ms": [
          27259.073273547,
          28183.97757391063
        ],
        "new_ci99_ms": [
          27266.488787888764,
          28184.0196866875
        ],
        "new_times": [
          28.97,
          26.52,
          29.12,
          26.39,
          28.87,
          26.33,
          29.36,
          26.43,
          29.0,
          26.36,
          28.93,
          26.38,
          28.89,
          26.35,
          28.98,
          26.53,
          29.39,
          26.5,
          29.03,
          26.46,
          28.87,
          26.21,
          29.09,
          26.63,
          28.96,
          26.41,
          29.01,
          26.34,
          29.01,
          26.39,
          29.02,
          26.36,
          28.99,
          26.34,
          29.17,
          26.45,
          29.0,
          26.53,
          28.96,
          26.34,
          28.93,
          26.26,
          29.05,
          26.4,
          28.98,
          26.26,
          28.87,
          26.34,
          29.07,
          26.29,
          28.83,
          26.49,
          28.99,
          26.43,
          29.04,
          26.35,
          28.96,
          26.4,
          28.98
        ],
        "old_times": [
          28.99,
          26.51,
          29.0,
          26.44,
          28.95,
          26.35,
          28.9,
          26.36,
          28.92,
          26.42,
          29.01,
          26.34,
          28.92,
          26.4,
          29.02,
          26.35,
          29.02,
          26.35,
          29.03,
          26.36,
          28.97,
          26.63,
          29.21,
          26.31,
          29.12,
          26.43,
          28.99,
          26.37,
          29.03,
          26.51,
          28.85,
          26.38,
          29.11,
          26.27,
          28.94,
          26.35,
          29.03,
          26.29,
          28.89,
          26.59,
          29.1,
          26.31,
          29.07,
          26.32,
          29.04,
          26.34,
          28.91,
          26.33,
          29.27,
          26.37,
          29.14,
          26.32,
          28.98,
          26.31,
          28.9,
          26.33,
          28.97,
          26.38,
          29.27
        ]
      }
    ]
  },
  "logs": {
    "full_log_path": "/logs/full.log",
    "config_log_path": "/logs/config.log",
    "build_log_path": "/logs/build.log",
    "test_log_path": "/logs/test.log",
    "build_success": true,
    "test_success": true
  },
  "raw_timing_data": {
    "warmup_runs": 1,
    "measurement_runs": 30,
    "min_exec_time_improvement": 0.05,
    "min_p_value": 0.05
  }
}