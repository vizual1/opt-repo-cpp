{
  "metadata": {
    "collection_date": "2026-02-03T20:01:42.249079",
    "repository": "https://github.com/google/highway",
    "repository_name": "google/highway"
  },
  "commit_info": {
    "old_sha": "a3daf48d2a27232d3f10a9c38b1625e9e818fce4",
    "new_sha": "895e520d99be0fbe538cac2044c7b9ef3fff1101",
    "commit_message": [
      "ThreadPool 1.2x in-CCX, 1.3x cross-CCX latency reduction: avoid WakeAll\n\nPiperOrigin-RevId: 726462980"
    ],
    "commit_date": "2025-02-13T14:41:25+00:00",
    "patch": [
      "--- hwy/contrib/thread_pool/thread_pool.h\n@@ -119,15 +119,15 @@ class ShuffledIota {\n // We want predictable struct/class sizes so we can reason about cache lines.\n #pragma pack(push, 1)\n \n-enum class PoolWaitMode : uint32_t { kBlock, kSpin };\n+// Same values as PoolCommands::kSetBlock and kSetSpin, verified there.\n+enum class PoolWaitMode : uint32_t { kBlock = 3, kSpin = 4 };\n \n // Worker's private working set.\n class PoolWorker {  // HWY_ALIGNMENT bytes\n   static constexpr size_t kMaxVictims = 4;\n \n  public:\n   PoolWorker(size_t thread, size_t num_workers) {\n-    wait_mode_ = PoolWaitMode::kBlock;\n     num_victims_ = static_cast<uint32_t>(HWY_MIN(kMaxVictims, num_workers));\n \n     const Divisor div_workers(static_cast<uint32_t>(num_workers));\n@@ -149,13 +149,6 @@ class PoolWorker {  // HWY_ALIGNMENT bytes\n   }\n   ~PoolWorker() = default;\n \n-  void SetWaitMode(PoolWaitMode wait_mode) {\n-    wait_mode_.store(wait_mode, std::memory_order_release);\n-  }\n-  PoolWaitMode WorkerGetWaitMode() const {\n-    return wait_mode_.load(std::memory_order_acquire);\n-  }\n-\n   hwy::Span<const uint32_t> Victims() const {\n     return hwy::Span<const uint32_t>(victims_.data(),\n                                      static_cast<size_t>(num_victims_));\n@@ -180,11 +173,10 @@ class PoolWorker {  // HWY_ALIGNMENT bytes\n   std::atomic<uint64_t> begin_;\n   std::atomic<uint64_t> end_;  // only changes during SetRange\n \n-  std::atomic<PoolWaitMode> wait_mode_;  // (32-bit)\n   uint32_t num_victims_;                 // <= kPoolMaxVictims\n   std::array<uint32_t, kMaxVictims> victims_;\n \n-  uint8_t padding_[HWY_ALIGNMENT - 16 - 8 - sizeof(victims_)];\n+  uint8_t padding_[HWY_ALIGNMENT - 16 - 4 - sizeof(victims_)];\n };\n static_assert(sizeof(PoolWorker) == HWY_ALIGNMENT, \"\");\n \n@@ -228,29 +220,36 @@ class PoolTasks {  // 32 bytes\n };\n \n // Modified by main thread, shared with all workers.\n-class PoolCommands {  // 16 bytes\n+class PoolCommands {  // 8 bytes\n   static constexpr uint32_t kInitial = 0;\n   static constexpr uint32_t kMask = 0xF;  // for command, rest is ABA counter.\n   static constexpr size_t kShift = hwy::CeilLog2(kMask);\n \n  public:\n   static constexpr uint32_t kTerminate = 1;\n   static constexpr uint32_t kWork = 2;\n-  static constexpr uint32_t kNop = 3;\n+  static constexpr uint32_t kSetBlock = 3;\n+  static constexpr uint32_t kSetSpin = 4;\n+  // Same value so we can assign PoolWaitMode from the command.\n+  static_assert(static_cast<uint32_t>(PoolWaitMode::kBlock) == kSetBlock);\n+  static_assert(static_cast<uint32_t>(PoolWaitMode::kSpin) == kSetSpin);\n \n   // Workers must initialize their copy to this so that they wait for the first\n   // command as intended.\n   static uint32_t WorkerInitialSeqCmd() { return kInitial; }\n \n   // Sends `cmd` to all workers.\n-  void Broadcast(uint32_t cmd) {\n+  void Broadcast(PoolWaitMode wait_mode, uint32_t cmd) {\n     HWY_DASSERT(cmd <= kMask);\n     const uint32_t epoch = ++epoch_;\n     const uint32_t seq_cmd = (epoch << kShift) | cmd;\n     seq_cmd_.store(seq_cmd, std::memory_order_release);\n \n-    // Wake any worker whose wait_mode_ is or was kBlock.\n-    WakeAll(seq_cmd_);\n+    // Only call WakeAll, which involves a syscall, if the threads are actually\n+    // blocking. This is enabled by a barrier in SetWaitMode.\n+    if (HWY_UNLIKELY(wait_mode == PoolWaitMode::kBlock)) {\n+      WakeAll(seq_cmd_);\n+    }\n \n     // Workers are either starting up, or waiting for a command. Either way,\n     // they will not miss this command, so no need to wait for them here.\n@@ -332,6 +331,7 @@ struct alignas(HWY_ALIGNMENT) PoolMem {\n \n   PoolTasks tasks;\n   PoolCommands commands;\n+  static_assert(sizeof(tasks) + sizeof(commands) <= HWY_ALIGNMENT);\n   // barrier is more write-heavy, hence keep in another cache line.\n   uint8_t padding[HWY_ALIGNMENT - sizeof(tasks) - sizeof(commands)];\n \n@@ -525,31 +525,33 @@ static inline void SetThreadName(const char* format, int thread) {\n //\n // For load-balancing, we use work stealing in random order.\n class ThreadPool {\n+  // Ensures ThreadFunc variable and class member start with the same value.\n+  static constexpr PoolWaitMode kInitialWaitMode = PoolWaitMode::kBlock;\n+\n   static void ThreadFunc(size_t thread, size_t num_workers, PoolMem* mem) {\n     HWY_DASSERT(thread < num_workers);\n     SetThreadName(\"worker%03zu\", static_cast<int>(thread));\n \n     // Ensure mem is ready to use (synchronize with PoolMemOwner's fence).\n     std::atomic_thread_fence(std::memory_order_acquire);\n \n-    PoolWorker& worker = mem->Worker(thread);\n+    PoolWaitMode wait_mode = kInitialWaitMode;\n     PoolCommands& commands = mem->commands;\n     uint32_t prev_seq_cmd = PoolCommands::WorkerInitialSeqCmd();\n \n     for (;;) {\n-      const PoolWaitMode wait_mode = worker.WorkerGetWaitMode();\n       const uint32_t command =\n           commands.WorkerWaitForNewCommand(wait_mode, prev_seq_cmd);\n       if (HWY_UNLIKELY(command == PoolCommands::kTerminate)) {\n         return;  // exits thread\n       } else if (HWY_LIKELY(command == PoolCommands::kWork)) {\n         ParallelFor::WorkerRun(thread, num_workers, *mem);\n-        mem->barrier.WorkerArrive(thread);\n-      } else if (command == PoolCommands::kNop) {\n-        // do nothing - used to change wait mode\n       } else {\n-        HWY_DASSERT(false);  // unknown command\n+        HWY_DASSERT(command == PoolCommands::kSetBlock ||\n+                    command == PoolCommands::kSetSpin);\n+        wait_mode = static_cast<PoolWaitMode>(command);\n       }\n+      mem->barrier.WorkerArrive(thread);\n     }\n   }\n \n@@ -584,7 +586,8 @@ class ThreadPool {\n   // Waits for all threads to exit.\n   ~ThreadPool() {\n     PoolMem& mem = *owner_.Mem();\n-    mem.commands.Broadcast(PoolCommands::kTerminate);  // requests threads exit\n+    // Requests threads exit. No barrier required, we wait for them below.\n+    mem.commands.Broadcast(wait_mode_, PoolCommands::kTerminate);\n \n     for (std::thread& thread : threads_) {\n       HWY_ASSERT(thread.joinable());\n@@ -604,22 +607,25 @@ class ThreadPool {\n   // but wastes power when waiting over long intervals. Inexpensive, OK to call\n   // multiple times, but not concurrently with any `Run`.\n   void SetWaitMode(PoolWaitMode mode) {\n+    PoolMem& mem = *owner_.Mem();\n+    const size_t num_workers = NumWorkers();\n+\n     // Run must not be active, otherwise we may overwrite the previous command\n     // before it is seen by all workers.\n     HWY_DASSERT(busy_.fetch_add(1) == 0);\n \n-    PoolMem& mem = *owner_.Mem();\n+    mem.barrier.Reset();\n \n-    // For completeness/consistency, set on all workers, including the main\n-    // thread, even though it will never wait for a command.\n-    for (size_t thread = 0; thread < owner_.NumWorkers(); ++thread) {\n-      mem.Worker(thread).SetWaitMode(mode);\n-    }\n+    HWY_DASSERT(mode == PoolWaitMode::kBlock || mode == PoolWaitMode::kSpin);\n+    mem.commands.Broadcast(wait_mode_, static_cast<uint32_t>(mode));\n+\n+    // Wait for all to ACK so that we can avoid a syscall in Broadcast.\n+    mem.barrier.WorkerArrive(num_workers - 1);\n+    mem.barrier.WaitAll(num_workers);\n \n-    // Send a no-op command so that workers wake as soon as possible. Skip the\n-    // expensive barrier - workers may miss this command, but it is fine for\n-    // them to wake up later and get the next actual command.\n-    mem.commands.Broadcast(PoolCommands::kNop);\n+    // Change after all threads have set their local variable and use this in\n+    // subsequent calls to Broadcast.\n+    wait_mode_ = mode;\n \n     HWY_DASSERT(busy_.fetch_add(-1) == 1);\n   }\n@@ -641,7 +647,7 @@ class ThreadPool {\n       HWY_DASSERT(busy_.fetch_add(1) == 0);\n \n       mem.barrier.Reset();\n-      mem.commands.Broadcast(PoolCommands::kWork);\n+      mem.commands.Broadcast(wait_mode_, PoolCommands::kWork);\n \n       // Also perform work on main thread instead of busy-waiting.\n       const size_t thread = num_workers - 1;\n@@ -682,6 +688,7 @@ class ThreadPool {\n   std::vector<std::thread> threads_;\n \n   PoolMemOwner owner_;\n+  PoolWaitMode wait_mode_ = kInitialWaitMode;\n \n   // In debug builds, detects if functions are re-entered; always present so\n   // that the memory layout does not change."
    ],
    "files_changed": [
      {
        "filename": "hwy/contrib/thread_pool/thread_pool.h",
        "status": "modified",
        "additions": 41,
        "deletions": 34,
        "changes": 75,
        "patch": "@@ -119,15 +119,15 @@ class ShuffledIota {\n // We want predictable struct/class sizes so we can reason about cache lines.\n #pragma pack(push, 1)\n \n-enum class PoolWaitMode : uint32_t { kBlock, kSpin };\n+// Same values as PoolCommands::kSetBlock and kSetSpin, verified there.\n+enum class PoolWaitMode : uint32_t { kBlock = 3, kSpin = 4 };\n \n // Worker's private working set.\n class PoolWorker {  // HWY_ALIGNMENT bytes\n   static constexpr size_t kMaxVictims = 4;\n \n  public:\n   PoolWorker(size_t thread, size_t num_workers) {\n-    wait_mode_ = PoolWaitMode::kBlock;\n     num_victims_ = static_cast<uint32_t>(HWY_MIN(kMaxVictims, num_workers));\n \n     const Divisor div_workers(static_cast<uint32_t>(num_workers));\n@@ -149,13 +149,6 @@ class PoolWorker {  // HWY_ALIGNMENT bytes\n   }\n   ~PoolWorker() = default;\n \n-  void SetWaitMode(PoolWaitMode wait_mode) {\n-    wait_mode_.store(wait_mode, std::memory_order_release);\n-  }\n-  PoolWaitMode WorkerGetWaitMode() const {\n-    return wait_mode_.load(std::memory_order_acquire);\n-  }\n-\n   hwy::Span<const uint32_t> Victims() const {\n     return hwy::Span<const uint32_t>(victims_.data(),\n                                      static_cast<size_t>(num_victims_));\n@@ -180,11 +173,10 @@ class PoolWorker {  // HWY_ALIGNMENT bytes\n   std::atomic<uint64_t> begin_;\n   std::atomic<uint64_t> end_;  // only changes during SetRange\n \n-  std::atomic<PoolWaitMode> wait_mode_;  // (32-bit)\n   uint32_t num_victims_;                 // <= kPoolMaxVictims\n   std::array<uint32_t, kMaxVictims> victims_;\n \n-  uint8_t padding_[HWY_ALIGNMENT - 16 - 8 - sizeof(victims_)];\n+  uint8_t padding_[HWY_ALIGNMENT - 16 - 4 - sizeof(victims_)];\n };\n static_assert(sizeof(PoolWorker) == HWY_ALIGNMENT, \"\");\n \n@@ -228,29 +220,36 @@ class PoolTasks {  // 32 bytes\n };\n \n // Modified by main thread, shared with all workers.\n-class PoolCommands {  // 16 bytes\n+class PoolCommands {  // 8 bytes\n   static constexpr uint32_t kInitial = 0;\n   static constexpr uint32_t kMask = 0xF;  // for command, rest is ABA counter.\n   static constexpr size_t kShift = hwy::CeilLog2(kMask);\n \n  public:\n   static constexpr uint32_t kTerminate = 1;\n   static constexpr uint32_t kWork = 2;\n-  static constexpr uint32_t kNop = 3;\n+  static constexpr uint32_t kSetBlock = 3;\n+  static constexpr uint32_t kSetSpin = 4;\n+  // Same value so we can assign PoolWaitMode from the command.\n+  static_assert(static_cast<uint32_t>(PoolWaitMode::kBlock) == kSetBlock);\n+  static_assert(static_cast<uint32_t>(PoolWaitMode::kSpin) == kSetSpin);\n \n   // Workers must initialize their copy to this so that they wait for the first\n   // command as intended.\n   static uint32_t WorkerInitialSeqCmd() { return kInitial; }\n \n   // Sends `cmd` to all workers.\n-  void Broadcast(uint32_t cmd) {\n+  void Broadcast(PoolWaitMode wait_mode, uint32_t cmd) {\n     HWY_DASSERT(cmd <= kMask);\n     const uint32_t epoch = ++epoch_;\n     const uint32_t seq_cmd = (epoch << kShift) | cmd;\n     seq_cmd_.store(seq_cmd, std::memory_order_release);\n \n-    // Wake any worker whose wait_mode_ is or was kBlock.\n-    WakeAll(seq_cmd_);\n+    // Only call WakeAll, which involves a syscall, if the threads are actually\n+    // blocking. This is enabled by a barrier in SetWaitMode.\n+    if (HWY_UNLIKELY(wait_mode == PoolWaitMode::kBlock)) {\n+      WakeAll(seq_cmd_);\n+    }\n \n     // Workers are either starting up, or waiting for a command. Either way,\n     // they will not miss this command, so no need to wait for them here.\n@@ -332,6 +331,7 @@ struct alignas(HWY_ALIGNMENT) PoolMem {\n \n   PoolTasks tasks;\n   PoolCommands commands;\n+  static_assert(sizeof(tasks) + sizeof(commands) <= HWY_ALIGNMENT);\n   // barrier is more write-heavy, hence keep in another cache line.\n   uint8_t padding[HWY_ALIGNMENT - sizeof(tasks) - sizeof(commands)];\n \n@@ -525,31 +525,33 @@ static inline void SetThreadName(const char* format, int thread) {\n //\n // For load-balancing, we use work stealing in random order.\n class ThreadPool {\n+  // Ensures ThreadFunc variable and class member start with the same value.\n+  static constexpr PoolWaitMode kInitialWaitMode = PoolWaitMode::kBlock;\n+\n   static void ThreadFunc(size_t thread, size_t num_workers, PoolMem* mem) {\n     HWY_DASSERT(thread < num_workers);\n     SetThreadName(\"worker%03zu\", static_cast<int>(thread));\n \n     // Ensure mem is ready to use (synchronize with PoolMemOwner's fence).\n     std::atomic_thread_fence(std::memory_order_acquire);\n \n-    PoolWorker& worker = mem->Worker(thread);\n+    PoolWaitMode wait_mode = kInitialWaitMode;\n     PoolCommands& commands = mem->commands;\n     uint32_t prev_seq_cmd = PoolCommands::WorkerInitialSeqCmd();\n \n     for (;;) {\n-      const PoolWaitMode wait_mode = worker.WorkerGetWaitMode();\n       const uint32_t command =\n           commands.WorkerWaitForNewCommand(wait_mode, prev_seq_cmd);\n       if (HWY_UNLIKELY(command == PoolCommands::kTerminate)) {\n         return;  // exits thread\n       } else if (HWY_LIKELY(command == PoolCommands::kWork)) {\n         ParallelFor::WorkerRun(thread, num_workers, *mem);\n-        mem->barrier.WorkerArrive(thread);\n-      } else if (command == PoolCommands::kNop) {\n-        // do nothing - used to change wait mode\n       } else {\n-        HWY_DASSERT(false);  // unknown command\n+        HWY_DASSERT(command == PoolCommands::kSetBlock ||\n+                    command == PoolCommands::kSetSpin);\n+        wait_mode = static_cast<PoolWaitMode>(command);\n       }\n+      mem->barrier.WorkerArrive(thread);\n     }\n   }\n \n@@ -584,7 +586,8 @@ class ThreadPool {\n   // Waits for all threads to exit.\n   ~ThreadPool() {\n     PoolMem& mem = *owner_.Mem();\n-    mem.commands.Broadcast(PoolCommands::kTerminate);  // requests threads exit\n+    // Requests threads exit. No barrier required, we wait for them below.\n+    mem.commands.Broadcast(wait_mode_, PoolCommands::kTerminate);\n \n     for (std::thread& thread : threads_) {\n       HWY_ASSERT(thread.joinable());\n@@ -604,22 +607,25 @@ class ThreadPool {\n   // but wastes power when waiting over long intervals. Inexpensive, OK to call\n   // multiple times, but not concurrently with any `Run`.\n   void SetWaitMode(PoolWaitMode mode) {\n+    PoolMem& mem = *owner_.Mem();\n+    const size_t num_workers = NumWorkers();\n+\n     // Run must not be active, otherwise we may overwrite the previous command\n     // before it is seen by all workers.\n     HWY_DASSERT(busy_.fetch_add(1) == 0);\n \n-    PoolMem& mem = *owner_.Mem();\n+    mem.barrier.Reset();\n \n-    // For completeness/consistency, set on all workers, including the main\n-    // thread, even though it will never wait for a command.\n-    for (size_t thread = 0; thread < owner_.NumWorkers(); ++thread) {\n-      mem.Worker(thread).SetWaitMode(mode);\n-    }\n+    HWY_DASSERT(mode == PoolWaitMode::kBlock || mode == PoolWaitMode::kSpin);\n+    mem.commands.Broadcast(wait_mode_, static_cast<uint32_t>(mode));\n+\n+    // Wait for all to ACK so that we can avoid a syscall in Broadcast.\n+    mem.barrier.WorkerArrive(num_workers - 1);\n+    mem.barrier.WaitAll(num_workers);\n \n-    // Send a no-op command so that workers wake as soon as possible. Skip the\n-    // expensive barrier - workers may miss this command, but it is fine for\n-    // them to wake up later and get the next actual command.\n-    mem.commands.Broadcast(PoolCommands::kNop);\n+    // Change after all threads have set their local variable and use this in\n+    // subsequent calls to Broadcast.\n+    wait_mode_ = mode;\n \n     HWY_DASSERT(busy_.fetch_add(-1) == 1);\n   }\n@@ -641,7 +647,7 @@ class ThreadPool {\n       HWY_DASSERT(busy_.fetch_add(1) == 0);\n \n       mem.barrier.Reset();\n-      mem.commands.Broadcast(PoolCommands::kWork);\n+      mem.commands.Broadcast(wait_mode_, PoolCommands::kWork);\n \n       // Also perform work on main thread instead of busy-waiting.\n       const size_t thread = num_workers - 1;\n@@ -682,6 +688,7 @@ class ThreadPool {\n   std::vector<std::thread> threads_;\n \n   PoolMemOwner owner_;\n+  PoolWaitMode wait_mode_ = kInitialWaitMode;\n \n   // In debug builds, detects if functions are re-entered; always present so\n   // that the memory layout does not change."
      }
    ],
    "lines_added": 41,
    "lines_removed": 34
  },
  "issues": [],
  "pull_requests": [],
  "build_info": {
    "old_build_script": [
      "apt-get update",
      "cmake -S /test_workspace/workspace/old -B /test_workspace/workspace/old/build -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=ON -DHWY_ENABLE_TESTS=ON -DBUILD_TESTING=ON",
      "cmake --build /test_workspace/workspace/old/build -- -j 1"
    ],
    "new_build_script": [
      "apt-get update",
      "cmake -S /test_workspace/workspace/new -B /test_workspace/workspace/new/build -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=ON -DHWY_ENABLE_TESTS=ON -DBUILD_TESTING=ON",
      "cmake --build /test_workspace/workspace/new/build -- -j 1"
    ],
    "old_test_script": [
      "cd /test_workspace/workspace/old/build",
      "ctest --output-on-failure"
    ],
    "new_test_script": [
      "cd /test_workspace/workspace/new/build",
      "ctest --output-on-failure"
    ],
    "build_system": "cmake"
  },
  "performance_analysis": {
    "is_significant": false,
    "p_value": 1.0,
    "is_pair_significant": false,
    "pair_p_value": 1.0,
    "is_binom_significant": false,
    "binom_p_value": 1.0,
    "is_wilcoxon_significant": false,
    "wilcoxon_p_value": 0.9999991338918834,
    "is_mannwhitney_significant": false,
    "mannwhitney_p_value": 0.9984488700812412,
    "relative_improvement": -0.00836792730363152,
    "absolute_improvement_ms": -426.6666666666694,
    "old_mean_ms": 50988.33333333333,
    "new_mean_ms": 51415.0,
    "old_std_ms": 446.41161872573804,
    "new_std_ms": 521.5940421703327,
    "effect_size_cohens_d": -0.8788907009957666,
    "old_ci95_ms": [
      50821.64049538103,
      51155.02617128564
    ],
    "new_ci95_ms": [
      51220.23358375714,
      51609.76641624286
    ],
    "old_ci99_ms": [
      50763.67895745824,
      51212.98770920841
    ],
    "new_ci99_ms": [
      51152.51045203882,
      51677.48954796118
    ],
    "new_times_s": [
      50.6,
      50.81,
      50.54,
      50.65,
      50.76,
      50.93,
      50.59,
      51.86,
      50.91,
      51.05,
      50.91,
      50.75,
      51.55,
      50.84,
      51.33,
      51.82,
      51.27,
      51.9,
      51.5,
      52.02,
      51.86,
      51.86,
      51.78,
      51.95,
      51.95,
      52.03,
      52.0,
      51.95,
      51.88,
      51.63,
      51.57
    ],
    "old_times_s": [
      50.76,
      50.41,
      51.52,
      50.56,
      50.97,
      50.49,
      50.26,
      50.35,
      50.47,
      50.27,
      50.87,
      51.56,
      50.49,
      51.12,
      50.77,
      51.16,
      51.45,
      50.86,
      50.79,
      52.09,
      51.18,
      51.2,
      51.22,
      51.23,
      51.21,
      51.57,
      51.35,
      51.26,
      51.18,
      50.87,
      50.92
    ]
  },
  "tests": {
    "total_tests": 4,
    "significant_improvements": 0,
    "significant_improvements_tests": [],
    "significant_regressions": 1,
    "significant_regressions_tests": [
      "ThreadPoolTest.TestCounter"
    ],
    "significant_pair_improvements": 0,
    "significant_pair_improvements_tests": [],
    "significant_pair_regressions": 1,
    "significant_pair_regressions_tests": [
      "ThreadPoolTest.TestCounter"
    ],
    "significant_binom_improvements": 0,
    "significant_binom_improvements_tests": [],
    "significant_binom_regressions": 1,
    "significant_binom_regressions_tests": [
      "ThreadPoolTest.TestCounter"
    ],
    "significant_wilcoxon_improvements": 0,
    "significant_wilcoxon_improvements_tests": [],
    "significant_wilcoxon_regressions": 1,
    "significant_wilcoxon_regressions_tests": [
      "ThreadPoolTest.TestCounter"
    ],
    "significant_mannwhitney_improvements": 0,
    "significant_mannwhitney_improvements_tests": [],
    "significant_mannwhitney_regressions": 1,
    "significant_mannwhitney_regressions_tests": [
      "ThreadPoolTest.TestCounter"
    ],
    "tests": [
      {
        "test_name": "NanobenchmarkTest.RunTest",
        "is_significant": false,
        "p_value": 0.9857949833371734,
        "is_pair_significant": false,
        "pair_p_value": 0.9686674672072835,
        "is_binom_significant": false,
        "binom_p_value": 0.9821509309113026,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9540297478197928,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.8232093824314797,
        "relative_improvement": -0.04356060606060597,
        "absolute_improvement_ms": -16.42857142857135,
        "old_mean_ms": 377.14285714285717,
        "new_mean_ms": 393.5714285714285,
        "old_std_ms": 56.69000453128059,
        "new_std_ms": 62.96467473552343,
        "effect_size_cohens_d": -0.2742229432011353,
        "old_ci95_ms": [
          355.1607682008161,
          399.1249460848982
        ],
        "new_ci95_ms": [
          369.1562765232532,
          417.9865806196038
        ],
        "old_ci99_ms": [
          347.4594117001394,
          406.8263025855749
        ],
        "new_ci99_ms": [
          360.6025039297116,
          426.5403532131454
        ],
        "new_times": [
          0.39,
          0.36,
          0.45,
          0.37,
          0.6,
          0.4,
          0.37,
          0.42,
          0.33,
          0.37,
          0.34,
          0.33,
          0.4,
          0.34,
          0.34,
          0.34,
          0.39,
          0.42,
          0.43,
          0.3,
          0.33,
          0.47,
          0.49,
          0.35,
          0.38,
          0.45,
          0.42,
          0.44
        ],
        "old_times": [
          0.4,
          0.38,
          0.3,
          0.32,
          0.36,
          0.31,
          0.34,
          0.43,
          0.51,
          0.37,
          0.38,
          0.29,
          0.38,
          0.42,
          0.43,
          0.35,
          0.35,
          0.4,
          0.5,
          0.43,
          0.41,
          0.31,
          0.32,
          0.45,
          0.34,
          0.39,
          0.33,
          0.36
        ]
      },
      {
        "test_name": "ThreadPoolTest.TestCounter",
        "is_significant": false,
        "p_value": 0.9999908184728765,
        "is_pair_significant": false,
        "pair_p_value": 0.9999997735466535,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999981188383212,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.9999958472917199,
        "relative_improvement": -0.9702380952380953,
        "absolute_improvement_ms": -58.214285714285715,
        "old_mean_ms": 60.000000000000014,
        "new_mean_ms": 118.21428571428574,
        "old_std_ms": 32.087842395985895,
        "new_std_ms": 59.320446255193865,
        "effect_size_cohens_d": -1.2206982566313502,
        "old_ci95_ms": [
          47.55763363685124,
          72.44236636314878
        ],
        "new_ci95_ms": [
          95.21221795216871,
          141.21635347640273
        ],
        "old_ci99_ms": [
          43.19848927494419,
          76.80151072505583
        ],
        "new_ci99_ms": [
          87.15351504382087,
          149.27505638475057
        ],
        "new_times": [
          0.09,
          0.06,
          0.06,
          0.05,
          0.07,
          0.08,
          0.06,
          0.08,
          0.09,
          0.06,
          0.08,
          0.06,
          0.07,
          0.07,
          0.08,
          0.09,
          0.26,
          0.16,
          0.18,
          0.2,
          0.18,
          0.19,
          0.14,
          0.15,
          0.17,
          0.21,
          0.14,
          0.18
        ],
        "old_times": [
          0.03,
          0.04,
          0.03,
          0.04,
          0.05,
          0.04,
          0.04,
          0.06,
          0.03,
          0.03,
          0.04,
          0.04,
          0.06,
          0.04,
          0.03,
          0.04,
          0.05,
          0.11,
          0.06,
          0.06,
          0.05,
          0.06,
          0.09,
          0.11,
          0.07,
          0.13,
          0.14,
          0.11
        ]
      },
      {
        "test_name": "TopologyTest.TestTopology",
        "is_significant": false,
        "p_value": 1.0,
        "is_pair_significant": false,
        "pair_p_value": 1.0,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999999393422746,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 1.0,
        "relative_improvement": 0.0,
        "absolute_improvement_ms": 0.0,
        "old_mean_ms": 10.0,
        "new_mean_ms": 10.0,
        "old_std_ms": 0.0,
        "new_std_ms": 0.0,
        "effect_size_cohens_d": "NaN",
        "old_ci95_ms": [
          10.0,
          10.0
        ],
        "new_ci95_ms": [
          10.0,
          10.0
        ],
        "old_ci99_ms": [
          10.0,
          10.0
        ],
        "new_ci99_ms": [
          10.0,
          10.0
        ],
        "new_times": [
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01
        ],
        "old_times": [
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01
        ]
      },
      {
        "test_name": "TopologyTest.TestCaches",
        "is_significant": false,
        "p_value": 1.0,
        "is_pair_significant": false,
        "pair_p_value": 1.0,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999999393422746,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 1.0,
        "relative_improvement": 0.0,
        "absolute_improvement_ms": 0.0,
        "old_mean_ms": 10.0,
        "new_mean_ms": 10.0,
        "old_std_ms": 0.0,
        "new_std_ms": 0.0,
        "effect_size_cohens_d": "NaN",
        "old_ci95_ms": [
          10.0,
          10.0
        ],
        "new_ci95_ms": [
          10.0,
          10.0
        ],
        "old_ci99_ms": [
          10.0,
          10.0
        ],
        "new_ci99_ms": [
          10.0,
          10.0
        ],
        "new_times": [
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01
        ],
        "old_times": [
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01
        ]
      }
    ]
  },
  "logs": {
    "full_log_path": "/logs/full.log",
    "config_log_path": "/logs/config.log",
    "build_log_path": "/logs/build.log",
    "test_log_path": "/logs/test.log",
    "build_success": true,
    "test_success": true
  },
  "raw_timing_data": {
    "warmup_runs": 1,
    "measurement_runs": 30,
    "min_exec_time_improvement": 0.05,
    "min_p_value": 0.05
  }
}