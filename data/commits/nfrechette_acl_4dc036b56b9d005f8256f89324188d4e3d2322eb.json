{
  "metadata": {
    "collection_date": "2026-02-03T20:04:23.180053",
    "repository": "https://github.com/nfrechette/acl",
    "repository_name": "nfrechette/acl"
  },
  "commit_info": {
    "old_sha": "440b92291679fab142db3bac2346436a2455b18b",
    "new_sha": "4dc036b56b9d005f8256f89324188d4e3d2322eb",
    "commit_message": [
      "feat(math): enable new NEON vec3 unpack with variable bit rate\n\n20% faster"
    ],
    "commit_date": "2025-05-11T21:34:58+00:00",
    "patch": [
      "--- includes/acl/math/vector4_packing.h\n@@ -986,61 +986,183 @@ namespace acl\n \t{\n \t\tACL_ASSERT(num_bits <= 23, \"This function does not support reading more than 23 bits per component\");\n \n-\t\tstruct PackedTableEntry\n+\t\t// We use at most 23 bits per component and so we only care about the\n+\t\t// first 23*3+7=76 bits as we might need to shift up to 7 bits past our byte\n+\t\t// offset. That means we care about the first 10 bytes.\n+\t\t// Our X component will live within bytes 0-4, Y within 0-6, and Z within 0-9\n+\t\t// depending on: our initial bit offset and how many bits per component we have\n+\t\t// For each number of bits per component, we can build a selection mask from our 16-byte\n+\t\t// value.\n+\t\t// num bits: {bit range from MSB} = {byte range from MSB}\n+\t\t// 0 : dummy, not used\n+\t\t// 1 : {[0,8],  [1,9],   [2,10]}  = {[0,1,2,3], [0,1,2,3],   [0,1,2,3]}\n+\t\t// 2 : {[0,9],  [2,11],  [4,13]}  = {[0,1,2,3], [0,1,2,3],   [0,1,2,3]}\n+\t\t// 3 : {[0,10], [3,13],  [6,16]}  = {[0,1,2,3], [0,1,2,3],   [0,1,2,3]}\n+\t\t// 4 : {[0,11], [4,15],  [8,19]}  = {[0,1,2,3], [0,1,2,3],   [0,1,2,3]}\n+\t\t// 5 : {[0,12], [5,17],  [10,22]} = {[0,1,2,3], [0,1,2,3],   [0,1,2,3]}\n+\t\t// 6 : {[0,13], [6,19],  [12,25]} = {[0,1,2,3], [0,1,2,3],   [0,1,2,3]}\n+\t\t// 7 : {[0,14], [7,21],  [14,28]} = {[0,1,2,3], [0,1,2,3],   [0,1,2,3]}\n+\t\t// 8 : {[0,15], [8,23],  [16,31]} = {[0,1,2,3], [0,1,2,3],   [0,1,2,3]}\n+\t\t// 9 : {[0,16], [9,25],  [18,34]} = {[0,1,2,3], [1,2,3,4],   [2,3,4,5]}\n+\t\t// 10: {[0,17], [10,27], [20,37]} = {[0,1,2,3], [1,2,3,4],   [2,3,4,5]}\n+\t\t// 11: {[0,18], [11,29], [22,40]} = {[0,1,2,3], [1,2,3,4],   [2,3,4,5]}\n+\t\t// 12: {[0,19], [12,31], [24,43]} = {[0,1,2,3], [1,2,3,4],   [2,3,4,5]}\n+\t\t// 13: {[0,20], [13,33], [26,46]} = {[0,1,2,3], [1,2,3,4],   [2,3,4,5]}\n+\t\t// 14: {[0,21], [14,35], [28,49]} = {[0,1,2,3], [1,2,3,4],   [2,3,4,5,6]}\n+\t\t// 15: {[0,22], [15,37], [30,52]} = {[0,1,2,3], [1,2,3,4],   [2,3,4,5,6]}\n+\t\t// 16: {[0,23], [16,39], [32,55]} = {[0,1,2,3], [1,2,3,4],   [2,3,4,5,6]}\n+\t\t// 17: {[0,24], [17,41], [34,58]} = {[0,1,2,3], [2,3,4,5],   [4,5,6,7]}\n+\t\t// 18: {[0,25], [18,43], [36,61]} = {[0,1,2,3], [2,3,4,5],   [4,5,6,7]}\n+\t\t// 19: {[0,26], [19,45], [38,64]} = {[0,1,2,3], [2,3,4,5],   [4,5,6,7,8]}\n+\t\t// 20: {[0,27], [20,47], [40,67]} = {[0,1,2,3], [2,3,4,5],   [5,6,7,8]}\n+\t\t// 21: {[0,28], [21,49], [42,70]} = {[0,1,2,3], [2,3,4,5,6], [5,6,7,8]}\n+\t\t// 22: {[0,29], [22,51], [44,73]} = {[0,1,2,3], [2,3,4,5,6], [5,6,7,8,9]}\n+\t\t// 23: {[0,30], [23,53], [46,76]} = {[0,1,2,3], [2,3,4,5,6], [5,6,7,8,9]}\n+\t\t// As we can see, some values require 5 bytes to reconstruct. As such, we need to use\n+\t\t// 64-bit values for each lane until we shift out the excess. If we need 8 bytes\n+\t\t// per mask for each lane, then it becomes obvious that X and Y can use the\n+\t\t// same mask value: they both live within the first 8 bytes. The Z lane is different.\n+\t\t// We can build two masks for it: one for values below 16, and another for values\n+\t\t// equal or above. This allows us to easily select the mask based on the 5th bit:\n+\t\t// if set, the value is 16 or above. We thus need just 3 mask values:\n+\t\t// XY: {0,1,2,3,4,5,6,7}\n+\t\t// Z: {0,1,2,3,4,5,6,7} and {4,5,6,7,8,9,10,11}\n+\t\t// Z's first mask can thus share the one used by XY.\n+\t\t//\n+\t\t// We can use the shuffle to also perform the byte swap operation trivially and treat\n+\t\t// the resulting 64-bit numbers normally.\n+\t\t//\n+\t\t// Each lane now contains the required bits but we must shift by an amount specific to\n+\t\t// each lane and finally we must mask out the extra bits. The mask can trivially be computed.\n+\t\t// This leaves the shift offset to figure out.\n+\t\t// With NEON, we do not have a SIMD right shift that takes an integer in each lane but\n+\t\t// we do have a SIMD left shift. If we use a negative shift offset, it then becomes a\n+\t\t// truncating right shift (see vshlq_u32 and the USHL instruction).\n+\t\t// For each SIMD lane, we want to shift by a custom amount plus the base bit offset.\n+\t\t// num bits: {bit range from MSB} = {right shift offset}\n+\t\t// 0 : dummy, not used\n+\t\t// 1 : {[0],  [1],  [2]}\n+\t\t// 2 : {[0],  [2],  [4]}\n+\t\t// 3 : {[0],  [3],  [6]}\n+\t\t// 4 : {[0],  [4],  [8]}\n+\t\t// 5 : {[0],  [5],  [10]}\n+\t\t// 6 : {[0],  [6],  [12]}\n+\t\t// 7 : {[0],  [7],  [14]}\n+\t\t// 8 : {[0],  [8],  [16]}\n+\t\t// 9 : {[0],  [9],  [18]}\n+\t\t// 10: {[0],  [10], [20]}\n+\t\t// 11: {[0],  [11], [22]}\n+\t\t// 12: {[0],  [12], [24]}\n+\t\t// 13: {[0],  [13], [26]}\n+\t\t// 14: {[0],  [14], [28]}\n+\t\t// 15: {[0],  [15], [30]}\n+\t\t// 16: {[0],  [16], [0]}\n+\t\t// 17: {[0],  [17], [2]}\n+\t\t// 18: {[0],  [18], [4]}\n+\t\t// 19: {[0],  [19], [6]}\n+\t\t// 20: {[0],  [20], [8]}\n+\t\t// 21: {[0],  [21], [10]}\n+\t\t// 22: {[0],  [22], [12]}\n+\t\t// 23: {[0],  [23], [14]}\n+\t\t// For the XY lanes, because the first byte is byte 0, the shift offset is simply how\n+\t\t// many bites the previous lane consumed: always 0 for X, and num bits for Y.\n+\t\t// Z is different for values 16 and above because the first byte is the 4th. This\n+\t\t// byte starts at bit offset 32 and so we must shift by that amount plus the extra bits\n+\t\t// consumed by the prior lane in that byte. It so happens to start at that bit offset.\n+\t\t// These values can easily be synthetized to avoid a potential cache miss and minimize\n+\t\t// the number of constants we have.\n+\n+\t\tstruct NEONConstants_t\n \t\t{\n-\t\t\texplicit constexpr PackedTableEntry(uint8_t num_bits_)\n+\t\t\texplicit constexpr NEONConstants_t(int32_t num_bits_)\n \t\t\t\t: max_value(num_bits_ == 0 ? 1.0F : (1.0F / float((1 << num_bits_) - 1)))\n-\t\t\t\t, mask((1U << num_bits_) - 1)\n+\t\t\t\t, shift_offset_x(0)\n+\t\t\t\t, shift_offset_y(static_cast<uint8_t>(num_bits_))\n+\t\t\t\t, shift_offset_z(static_cast<uint8_t>((num_bits_ % 16) * 2))\n+\t\t\t\t, shift_num_bits(-int8_t(64 - num_bits_))\n \t\t\t{}\n \n \t\t\tfloat max_value;\n-\t\t\tuint32_t mask;\n+\n+\t\t\tuint8_t shift_offset_x;\n+\t\t\tuint8_t shift_offset_y;\n+\t\t\tuint8_t shift_offset_z;\n+\t\t\tint8_t shift_num_bits;\n \t\t};\n \n-\t\talignas(64) static constexpr PackedTableEntry k_packed_constants[24] =\n+\t\t// Total size: 8 * 24 = 192 (3 cache lines)\n+\t\t// Align to 256 bytes to avoid straddling over a page boundary\n+\t\talignas(256) static constexpr NEONConstants_t k_packed_constants[24] =\n \t\t{\n-\t\t\tPackedTableEntry(0), PackedTableEntry(1), PackedTableEntry(2), PackedTableEntry(3),\n-\t\t\tPackedTableEntry(4), PackedTableEntry(5), PackedTableEntry(6), PackedTableEntry(7),\n-\t\t\tPackedTableEntry(8), PackedTableEntry(9), PackedTableEntry(10), PackedTableEntry(11),\n-\t\t\tPackedTableEntry(12), PackedTableEntry(13), PackedTableEntry(14), PackedTableEntry(15),\n-\t\t\tPackedTableEntry(16), PackedTableEntry(17), PackedTableEntry(18), PackedTableEntry(19),\n-\t\t\tPackedTableEntry(20), PackedTableEntry(21), PackedTableEntry(22), PackedTableEntry(23),\n+\t\t\tNEONConstants_t(0), NEONConstants_t(1), NEONConstants_t(2), NEONConstants_t(3),\n+\t\t\tNEONConstants_t(4), NEONConstants_t(5), NEONConstants_t(6), NEONConstants_t(7),\n+\t\t\tNEONConstants_t(8), NEONConstants_t(9), NEONConstants_t(10), NEONConstants_t(11),\n+\t\t\tNEONConstants_t(12), NEONConstants_t(13), NEONConstants_t(14), NEONConstants_t(15),\n+\t\t\tNEONConstants_t(16), NEONConstants_t(17), NEONConstants_t(18), NEONConstants_t(19),\n+\t\t\tNEONConstants_t(20), NEONConstants_t(21), NEONConstants_t(22), NEONConstants_t(23),\n \t\t};\n \n-\t\tconst uint32_t bit_shift = 32 - num_bits;\n-#if defined(RTM_COMPILER_MSVC)\n-\t\t// MSVC uses an alias\n-\t\tuint32x4_t mask = vdupq_n_u32(static_cast<int32_t>(k_packed_constants[num_bits].mask));\n-#else\n-\t\tuint32x4_t mask = vdupq_n_u32(k_packed_constants[num_bits].mask);\n-#endif\n-\t\tfloat inv_max_value = k_packed_constants[num_bits].max_value;\n+\t\tconst uint32_t byte_offset = bit_offset / 8;\n+\t\tconst uint32_t base_bit_offset = bit_offset % 8;\n \n-\t\tuint32_t byte_offset = bit_offset / 8;\n-\t\tuint32_t vector_u32 = unaligned_load<uint32_t>(vector_data + byte_offset);\n-\t\tvector_u32 = byte_swap(vector_u32);\n-\t\tconst uint32_t x32 = (vector_u32 >> (bit_shift - (bit_offset % 8)));\n+\t\t// Load 16 bytes\n+\t\tconst uint8x16_t raw_bytes = vld1q_u8(vector_data + byte_offset);\n \n-\t\tbit_offset += num_bits;\n+\t\t// Select and swizzle using our mask\n+\t\tconst uint8_t swizzle_mask_z_offset = static_cast<uint8_t>((num_bits >> 2) & 0x04);\t// num_bits >= 16 ? 4 : 0\n \n-\t\tbyte_offset = bit_offset / 8;\n-\t\tvector_u32 = unaligned_load<uint32_t>(vector_data + byte_offset);\n-\t\tvector_u32 = byte_swap(vector_u32);\n-\t\tconst uint32_t y32 = (vector_u32 >> (bit_shift - (bit_offset % 8)));\n+#if defined(RTM_NEON64_INTRINSICS)\n+\t\tconst uint8x16_t swizzle_mask_base = vreinterpretq_u8_u64(vmovq_n_u64(0x0001020304050607ULL));\n+\t\tconst uint8x16_t swizzle_mask_xy = swizzle_mask_base;\n+\t\tconst uint8x16_t swizzle_mask_zw = vaddq_u8(swizzle_mask_base, vmovq_n_u8(swizzle_mask_z_offset));\n \n-\t\tbit_offset += num_bits;\n+\t\tuint64x2_t xy = vreinterpretq_u64_u8(vqtbl1q_u8(raw_bytes, swizzle_mask_xy));\n+\t\tuint64x2_t zw = vreinterpretq_u64_u8(vqtbl1q_u8(raw_bytes, swizzle_mask_zw));\n+#else\n+\t\tconst uint8x8_t swizzle_mask_base = vreinterpret_u8_u64(vmov_n_u64(0x0001020304050607ULL));\n+\t\tconst uint8x8x2_t raw_bytes_split = { vget_low_u8(raw_bytes), vget_high_u8(raw_bytes) };\n+\t\tconst uint8x8_t swizzle_mask_xy = swizzle_mask_base;\n+\t\tconst uint8x8_t swizzle_mask_zw = vadd_u8(swizzle_mask_base, vmov_n_u8(swizzle_mask_z_offset));\n \n-\t\tbyte_offset = bit_offset / 8;\n-\t\tvector_u32 = unaligned_load<uint32_t>(vector_data + byte_offset);\n-\t\tvector_u32 = byte_swap(vector_u32);\n-\t\tconst uint32_t z32 = (vector_u32 >> (bit_shift - (bit_offset % 8)));\n+\t\tuint64x2_t xy = vdupq_lane_u64(vreinterpret_u64_u8(vtbl1_u8(vget_low_u8(raw_bytes), swizzle_mask_xy)), 0);\n+\t\tuint64x2_t zw = vdupq_lane_u64(vreinterpret_u64_u8(vtbl2_u8(raw_bytes_split, swizzle_mask_zw)), 0);\n+#endif\n \n-\t\tuint32x2_t xy = vcreate_u32(uint64_t(x32) | (uint64_t(y32) << 32));\n-\t\tuint32x2_t z = vcreate_u32(uint64_t(z32));\n-\t\tuint32x4_t value_u32 = vcombine_u32(xy, z);\n-\t\tvalue_u32 = vandq_u32(value_u32, mask);\n-\t\tfloat32x4_t value_f32 = vcvtq_f32_u32(value_u32);\n-\t\treturn vmulq_n_f32(value_f32, inv_max_value);\n+\t\t// Even though it is easy to compute the shift offsets on demand, we pre-compute them\n+\t\t// and load them here. We already pay the price of a load instruction for the inverse\n+\t\t// max value float which is too expensive to compute on demand. As such, we tack on\n+\t\t// another 4 bytes for the shift offsets and unpack them here. This uses fewer instructions.\n+\t\tconst int8x8_t raw_constant_bytes_s8 = vld1_s8((const int8_t*)&k_packed_constants[num_bits]);\n+\t\tconst int16x8_t raw_constant_bytes_s16 = vmovl_s8(raw_constant_bytes_s8);\n+\t\tconst int32x4_t raw_shift_offsets_s32 = vmovl_s16(vget_high_s16(raw_constant_bytes_s16));\n+\t\tconst int64x2_t base_shift_offset_xy = vmovl_s32(vget_low_s32(raw_shift_offsets_s32));\n+\t\tconst int64x2_t base_shift_offset_zw = vmovl_s32(vget_high_s32(raw_shift_offsets_s32));\n+\n+\t\t// Shift out the extra bits\n+\t\tconst int64x2_t base_bit_offset_s64 = vreinterpretq_s64_u64(vmovq_n_u64(base_bit_offset));\n+\t\tconst int64x2_t shift_offset_xy = vaddq_s64(base_bit_offset_s64, base_shift_offset_xy);\n+\t\tconst int64x2_t shift_offset_zw = vaddq_s64(base_bit_offset_s64, base_shift_offset_zw);\n+\n+\t\t// Shift left to truncate the extra leading bits\n+\t\txy = vshlq_u64(xy, shift_offset_xy);\n+\t\tzw = vshlq_u64(zw, shift_offset_zw);\n+\n+\t\t// Shift right to bring them in the right place at the bottom\n+\t\tconst int64x2_t shift_num_bits = vdupq_lane_s64(vget_high_s64(base_shift_offset_zw), 0);\n+\t\txy = vshlq_u64(xy, shift_num_bits);\n+\t\tzw = vshlq_u64(zw, shift_num_bits);\n+\n+\t\t// Combine and mask our the extra bits\n+\t\t// As u64, we have: {x, y}, but when we cast to u32, we get: {x, _, y, _}\n+#if defined(RTM_NEON64_INTRINSICS)\n+\t\tconst uint32x4_t xyzw_u32 = vuzp1q_u32(vreinterpretq_u32_u64(xy), vreinterpretq_u32_u64(zw));\n+#else\n+\t\tconst uint32x4_t xyzw_u32 = vuzpq_u32(vreinterpretq_u32_u64(xy), vreinterpretq_u32_u64(zw)).val[0];\n+#endif\n+\n+\t\t// Convert to float and re-scale\n+\t\tconst float32x4_t xyzw_f32 = vcvtq_f32_u32(xyzw_u32);\n+\t\treturn vmulq_n_f32(xyzw_f32, vget_lane_f32(vreinterpret_f32_s8(raw_constant_bytes_s8), 0));\n \t}\n #else\n \t// Assumes the 'vector_data' is in big-endian order and padded in order to load up to 16 bytes from it"
    ],
    "files_changed": [
      {
        "filename": "includes/acl/math/vector4_packing.h",
        "status": "modified",
        "additions": 161,
        "deletions": 39,
        "changes": 200,
        "patch": "@@ -986,61 +986,183 @@ namespace acl\n \t{\n \t\tACL_ASSERT(num_bits <= 23, \"This function does not support reading more than 23 bits per component\");\n \n-\t\tstruct PackedTableEntry\n+\t\t// We use at most 23 bits per component and so we only care about the\n+\t\t// first 23*3+7=76 bits as we might need to shift up to 7 bits past our byte\n+\t\t// offset. That means we care about the first 10 bytes.\n+\t\t// Our X component will live within bytes 0-4, Y within 0-6, and Z within 0-9\n+\t\t// depending on: our initial bit offset and how many bits per component we have\n+\t\t// For each number of bits per component, we can build a selection mask from our 16-byte\n+\t\t// value.\n+\t\t// num bits: {bit range from MSB} = {byte range from MSB}\n+\t\t// 0 : dummy, not used\n+\t\t// 1 : {[0,8],  [1,9],   [2,10]}  = {[0,1,2,3], [0,1,2,3],   [0,1,2,3]}\n+\t\t// 2 : {[0,9],  [2,11],  [4,13]}  = {[0,1,2,3], [0,1,2,3],   [0,1,2,3]}\n+\t\t// 3 : {[0,10], [3,13],  [6,16]}  = {[0,1,2,3], [0,1,2,3],   [0,1,2,3]}\n+\t\t// 4 : {[0,11], [4,15],  [8,19]}  = {[0,1,2,3], [0,1,2,3],   [0,1,2,3]}\n+\t\t// 5 : {[0,12], [5,17],  [10,22]} = {[0,1,2,3], [0,1,2,3],   [0,1,2,3]}\n+\t\t// 6 : {[0,13], [6,19],  [12,25]} = {[0,1,2,3], [0,1,2,3],   [0,1,2,3]}\n+\t\t// 7 : {[0,14], [7,21],  [14,28]} = {[0,1,2,3], [0,1,2,3],   [0,1,2,3]}\n+\t\t// 8 : {[0,15], [8,23],  [16,31]} = {[0,1,2,3], [0,1,2,3],   [0,1,2,3]}\n+\t\t// 9 : {[0,16], [9,25],  [18,34]} = {[0,1,2,3], [1,2,3,4],   [2,3,4,5]}\n+\t\t// 10: {[0,17], [10,27], [20,37]} = {[0,1,2,3], [1,2,3,4],   [2,3,4,5]}\n+\t\t// 11: {[0,18], [11,29], [22,40]} = {[0,1,2,3], [1,2,3,4],   [2,3,4,5]}\n+\t\t// 12: {[0,19], [12,31], [24,43]} = {[0,1,2,3], [1,2,3,4],   [2,3,4,5]}\n+\t\t// 13: {[0,20], [13,33], [26,46]} = {[0,1,2,3], [1,2,3,4],   [2,3,4,5]}\n+\t\t// 14: {[0,21], [14,35], [28,49]} = {[0,1,2,3], [1,2,3,4],   [2,3,4,5,6]}\n+\t\t// 15: {[0,22], [15,37], [30,52]} = {[0,1,2,3], [1,2,3,4],   [2,3,4,5,6]}\n+\t\t// 16: {[0,23], [16,39], [32,55]} = {[0,1,2,3], [1,2,3,4],   [2,3,4,5,6]}\n+\t\t// 17: {[0,24], [17,41], [34,58]} = {[0,1,2,3], [2,3,4,5],   [4,5,6,7]}\n+\t\t// 18: {[0,25], [18,43], [36,61]} = {[0,1,2,3], [2,3,4,5],   [4,5,6,7]}\n+\t\t// 19: {[0,26], [19,45], [38,64]} = {[0,1,2,3], [2,3,4,5],   [4,5,6,7,8]}\n+\t\t// 20: {[0,27], [20,47], [40,67]} = {[0,1,2,3], [2,3,4,5],   [5,6,7,8]}\n+\t\t// 21: {[0,28], [21,49], [42,70]} = {[0,1,2,3], [2,3,4,5,6], [5,6,7,8]}\n+\t\t// 22: {[0,29], [22,51], [44,73]} = {[0,1,2,3], [2,3,4,5,6], [5,6,7,8,9]}\n+\t\t// 23: {[0,30], [23,53], [46,76]} = {[0,1,2,3], [2,3,4,5,6], [5,6,7,8,9]}\n+\t\t// As we can see, some values require 5 bytes to reconstruct. As such, we need to use\n+\t\t// 64-bit values for each lane until we shift out the excess. If we need 8 bytes\n+\t\t// per mask for each lane, then it becomes obvious that X and Y can use the\n+\t\t// same mask value: they both live within the first 8 bytes. The Z lane is different.\n+\t\t// We can build two masks for it: one for values below 16, and another for values\n+\t\t// equal or above. This allows us to easily select the mask based on the 5th bit:\n+\t\t// if set, the value is 16 or above. We thus need just 3 mask values:\n+\t\t// XY: {0,1,2,3,4,5,6,7}\n+\t\t// Z: {0,1,2,3,4,5,6,7} and {4,5,6,7,8,9,10,11}\n+\t\t// Z's first mask can thus share the one used by XY.\n+\t\t//\n+\t\t// We can use the shuffle to also perform the byte swap operation trivially and treat\n+\t\t// the resulting 64-bit numbers normally.\n+\t\t//\n+\t\t// Each lane now contains the required bits but we must shift by an amount specific to\n+\t\t// each lane and finally we must mask out the extra bits. The mask can trivially be computed.\n+\t\t// This leaves the shift offset to figure out.\n+\t\t// With NEON, we do not have a SIMD right shift that takes an integer in each lane but\n+\t\t// we do have a SIMD left shift. If we use a negative shift offset, it then becomes a\n+\t\t// truncating right shift (see vshlq_u32 and the USHL instruction).\n+\t\t// For each SIMD lane, we want to shift by a custom amount plus the base bit offset.\n+\t\t// num bits: {bit range from MSB} = {right shift offset}\n+\t\t// 0 : dummy, not used\n+\t\t// 1 : {[0],  [1],  [2]}\n+\t\t// 2 : {[0],  [2],  [4]}\n+\t\t// 3 : {[0],  [3],  [6]}\n+\t\t// 4 : {[0],  [4],  [8]}\n+\t\t// 5 : {[0],  [5],  [10]}\n+\t\t// 6 : {[0],  [6],  [12]}\n+\t\t// 7 : {[0],  [7],  [14]}\n+\t\t// 8 : {[0],  [8],  [16]}\n+\t\t// 9 : {[0],  [9],  [18]}\n+\t\t// 10: {[0],  [10], [20]}\n+\t\t// 11: {[0],  [11], [22]}\n+\t\t// 12: {[0],  [12], [24]}\n+\t\t// 13: {[0],  [13], [26]}\n+\t\t// 14: {[0],  [14], [28]}\n+\t\t// 15: {[0],  [15], [30]}\n+\t\t// 16: {[0],  [16], [0]}\n+\t\t// 17: {[0],  [17], [2]}\n+\t\t// 18: {[0],  [18], [4]}\n+\t\t// 19: {[0],  [19], [6]}\n+\t\t// 20: {[0],  [20], [8]}\n+\t\t// 21: {[0],  [21], [10]}\n+\t\t// 22: {[0],  [22], [12]}\n+\t\t// 23: {[0],  [23], [14]}\n+\t\t// For the XY lanes, because the first byte is byte 0, the shift offset is simply how\n+\t\t// many bites the previous lane consumed: always 0 for X, and num bits for Y.\n+\t\t// Z is different for values 16 and above because the first byte is the 4th. This\n+\t\t// byte starts at bit offset 32 and so we must shift by that amount plus the extra bits\n+\t\t// consumed by the prior lane in that byte. It so happens to start at that bit offset.\n+\t\t// These values can easily be synthetized to avoid a potential cache miss and minimize\n+\t\t// the number of constants we have.\n+\n+\t\tstruct NEONConstants_t\n \t\t{\n-\t\t\texplicit constexpr PackedTableEntry(uint8_t num_bits_)\n+\t\t\texplicit constexpr NEONConstants_t(int32_t num_bits_)\n \t\t\t\t: max_value(num_bits_ == 0 ? 1.0F : (1.0F / float((1 << num_bits_) - 1)))\n-\t\t\t\t, mask((1U << num_bits_) - 1)\n+\t\t\t\t, shift_offset_x(0)\n+\t\t\t\t, shift_offset_y(static_cast<uint8_t>(num_bits_))\n+\t\t\t\t, shift_offset_z(static_cast<uint8_t>((num_bits_ % 16) * 2))\n+\t\t\t\t, shift_num_bits(-int8_t(64 - num_bits_))\n \t\t\t{}\n \n \t\t\tfloat max_value;\n-\t\t\tuint32_t mask;\n+\n+\t\t\tuint8_t shift_offset_x;\n+\t\t\tuint8_t shift_offset_y;\n+\t\t\tuint8_t shift_offset_z;\n+\t\t\tint8_t shift_num_bits;\n \t\t};\n \n-\t\talignas(64) static constexpr PackedTableEntry k_packed_constants[24] =\n+\t\t// Total size: 8 * 24 = 192 (3 cache lines)\n+\t\t// Align to 256 bytes to avoid straddling over a page boundary\n+\t\talignas(256) static constexpr NEONConstants_t k_packed_constants[24] =\n \t\t{\n-\t\t\tPackedTableEntry(0), PackedTableEntry(1), PackedTableEntry(2), PackedTableEntry(3),\n-\t\t\tPackedTableEntry(4), PackedTableEntry(5), PackedTableEntry(6), PackedTableEntry(7),\n-\t\t\tPackedTableEntry(8), PackedTableEntry(9), PackedTableEntry(10), PackedTableEntry(11),\n-\t\t\tPackedTableEntry(12), PackedTableEntry(13), PackedTableEntry(14), PackedTableEntry(15),\n-\t\t\tPackedTableEntry(16), PackedTableEntry(17), PackedTableEntry(18), PackedTableEntry(19),\n-\t\t\tPackedTableEntry(20), PackedTableEntry(21), PackedTableEntry(22), PackedTableEntry(23),\n+\t\t\tNEONConstants_t(0), NEONConstants_t(1), NEONConstants_t(2), NEONConstants_t(3),\n+\t\t\tNEONConstants_t(4), NEONConstants_t(5), NEONConstants_t(6), NEONConstants_t(7),\n+\t\t\tNEONConstants_t(8), NEONConstants_t(9), NEONConstants_t(10), NEONConstants_t(11),\n+\t\t\tNEONConstants_t(12), NEONConstants_t(13), NEONConstants_t(14), NEONConstants_t(15),\n+\t\t\tNEONConstants_t(16), NEONConstants_t(17), NEONConstants_t(18), NEONConstants_t(19),\n+\t\t\tNEONConstants_t(20), NEONConstants_t(21), NEONConstants_t(22), NEONConstants_t(23),\n \t\t};\n \n-\t\tconst uint32_t bit_shift = 32 - num_bits;\n-#if defined(RTM_COMPILER_MSVC)\n-\t\t// MSVC uses an alias\n-\t\tuint32x4_t mask = vdupq_n_u32(static_cast<int32_t>(k_packed_constants[num_bits].mask));\n-#else\n-\t\tuint32x4_t mask = vdupq_n_u32(k_packed_constants[num_bits].mask);\n-#endif\n-\t\tfloat inv_max_value = k_packed_constants[num_bits].max_value;\n+\t\tconst uint32_t byte_offset = bit_offset / 8;\n+\t\tconst uint32_t base_bit_offset = bit_offset % 8;\n \n-\t\tuint32_t byte_offset = bit_offset / 8;\n-\t\tuint32_t vector_u32 = unaligned_load<uint32_t>(vector_data + byte_offset);\n-\t\tvector_u32 = byte_swap(vector_u32);\n-\t\tconst uint32_t x32 = (vector_u32 >> (bit_shift - (bit_offset % 8)));\n+\t\t// Load 16 bytes\n+\t\tconst uint8x16_t raw_bytes = vld1q_u8(vector_data + byte_offset);\n \n-\t\tbit_offset += num_bits;\n+\t\t// Select and swizzle using our mask\n+\t\tconst uint8_t swizzle_mask_z_offset = static_cast<uint8_t>((num_bits >> 2) & 0x04);\t// num_bits >= 16 ? 4 : 0\n \n-\t\tbyte_offset = bit_offset / 8;\n-\t\tvector_u32 = unaligned_load<uint32_t>(vector_data + byte_offset);\n-\t\tvector_u32 = byte_swap(vector_u32);\n-\t\tconst uint32_t y32 = (vector_u32 >> (bit_shift - (bit_offset % 8)));\n+#if defined(RTM_NEON64_INTRINSICS)\n+\t\tconst uint8x16_t swizzle_mask_base = vreinterpretq_u8_u64(vmovq_n_u64(0x0001020304050607ULL));\n+\t\tconst uint8x16_t swizzle_mask_xy = swizzle_mask_base;\n+\t\tconst uint8x16_t swizzle_mask_zw = vaddq_u8(swizzle_mask_base, vmovq_n_u8(swizzle_mask_z_offset));\n \n-\t\tbit_offset += num_bits;\n+\t\tuint64x2_t xy = vreinterpretq_u64_u8(vqtbl1q_u8(raw_bytes, swizzle_mask_xy));\n+\t\tuint64x2_t zw = vreinterpretq_u64_u8(vqtbl1q_u8(raw_bytes, swizzle_mask_zw));\n+#else\n+\t\tconst uint8x8_t swizzle_mask_base = vreinterpret_u8_u64(vmov_n_u64(0x0001020304050607ULL));\n+\t\tconst uint8x8x2_t raw_bytes_split = { vget_low_u8(raw_bytes), vget_high_u8(raw_bytes) };\n+\t\tconst uint8x8_t swizzle_mask_xy = swizzle_mask_base;\n+\t\tconst uint8x8_t swizzle_mask_zw = vadd_u8(swizzle_mask_base, vmov_n_u8(swizzle_mask_z_offset));\n \n-\t\tbyte_offset = bit_offset / 8;\n-\t\tvector_u32 = unaligned_load<uint32_t>(vector_data + byte_offset);\n-\t\tvector_u32 = byte_swap(vector_u32);\n-\t\tconst uint32_t z32 = (vector_u32 >> (bit_shift - (bit_offset % 8)));\n+\t\tuint64x2_t xy = vdupq_lane_u64(vreinterpret_u64_u8(vtbl1_u8(vget_low_u8(raw_bytes), swizzle_mask_xy)), 0);\n+\t\tuint64x2_t zw = vdupq_lane_u64(vreinterpret_u64_u8(vtbl2_u8(raw_bytes_split, swizzle_mask_zw)), 0);\n+#endif\n \n-\t\tuint32x2_t xy = vcreate_u32(uint64_t(x32) | (uint64_t(y32) << 32));\n-\t\tuint32x2_t z = vcreate_u32(uint64_t(z32));\n-\t\tuint32x4_t value_u32 = vcombine_u32(xy, z);\n-\t\tvalue_u32 = vandq_u32(value_u32, mask);\n-\t\tfloat32x4_t value_f32 = vcvtq_f32_u32(value_u32);\n-\t\treturn vmulq_n_f32(value_f32, inv_max_value);\n+\t\t// Even though it is easy to compute the shift offsets on demand, we pre-compute them\n+\t\t// and load them here. We already pay the price of a load instruction for the inverse\n+\t\t// max value float which is too expensive to compute on demand. As such, we tack on\n+\t\t// another 4 bytes for the shift offsets and unpack them here. This uses fewer instructions.\n+\t\tconst int8x8_t raw_constant_bytes_s8 = vld1_s8((const int8_t*)&k_packed_constants[num_bits]);\n+\t\tconst int16x8_t raw_constant_bytes_s16 = vmovl_s8(raw_constant_bytes_s8);\n+\t\tconst int32x4_t raw_shift_offsets_s32 = vmovl_s16(vget_high_s16(raw_constant_bytes_s16));\n+\t\tconst int64x2_t base_shift_offset_xy = vmovl_s32(vget_low_s32(raw_shift_offsets_s32));\n+\t\tconst int64x2_t base_shift_offset_zw = vmovl_s32(vget_high_s32(raw_shift_offsets_s32));\n+\n+\t\t// Shift out the extra bits\n+\t\tconst int64x2_t base_bit_offset_s64 = vreinterpretq_s64_u64(vmovq_n_u64(base_bit_offset));\n+\t\tconst int64x2_t shift_offset_xy = vaddq_s64(base_bit_offset_s64, base_shift_offset_xy);\n+\t\tconst int64x2_t shift_offset_zw = vaddq_s64(base_bit_offset_s64, base_shift_offset_zw);\n+\n+\t\t// Shift left to truncate the extra leading bits\n+\t\txy = vshlq_u64(xy, shift_offset_xy);\n+\t\tzw = vshlq_u64(zw, shift_offset_zw);\n+\n+\t\t// Shift right to bring them in the right place at the bottom\n+\t\tconst int64x2_t shift_num_bits = vdupq_lane_s64(vget_high_s64(base_shift_offset_zw), 0);\n+\t\txy = vshlq_u64(xy, shift_num_bits);\n+\t\tzw = vshlq_u64(zw, shift_num_bits);\n+\n+\t\t// Combine and mask our the extra bits\n+\t\t// As u64, we have: {x, y}, but when we cast to u32, we get: {x, _, y, _}\n+#if defined(RTM_NEON64_INTRINSICS)\n+\t\tconst uint32x4_t xyzw_u32 = vuzp1q_u32(vreinterpretq_u32_u64(xy), vreinterpretq_u32_u64(zw));\n+#else\n+\t\tconst uint32x4_t xyzw_u32 = vuzpq_u32(vreinterpretq_u32_u64(xy), vreinterpretq_u32_u64(zw)).val[0];\n+#endif\n+\n+\t\t// Convert to float and re-scale\n+\t\tconst float32x4_t xyzw_f32 = vcvtq_f32_u32(xyzw_u32);\n+\t\treturn vmulq_n_f32(xyzw_f32, vget_lane_f32(vreinterpret_f32_s8(raw_constant_bytes_s8), 0));\n \t}\n #else\n \t// Assumes the 'vector_data' is in big-endian order and padded in order to load up to 16 bytes from it"
      }
    ],
    "lines_added": 161,
    "lines_removed": 39
  },
  "issues": [],
  "pull_requests": [],
  "build_info": {
    "old_build_script": [
      "apt-get update",
      "cmake -S /test_workspace/workspace/old -B /test_workspace/workspace/old/build -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=ON -DBUILD_TESTING=ON -DCATCH_BUILD_TESTING=ON -DBENCHMARK_ENABLE_TESTING=ON -DINCLUDE_UNIT_TESTS=ON -DBENCHMARK_ENABLE_ASSEMBLY_TESTS=ON -DBENCHMARK_USE_BUNDLED_GTEST=ON -DBENCHMARK_ENABLE_GTEST_TESTS=ON",
      "cmake --build /test_workspace/workspace/old/build -- -j 1"
    ],
    "new_build_script": [
      "apt-get update",
      "cmake -S /test_workspace/workspace/new -B /test_workspace/workspace/new/build -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=ON -DBUILD_TESTING=ON -DCATCH_BUILD_TESTING=ON -DBENCHMARK_ENABLE_TESTING=ON -DINCLUDE_UNIT_TESTS=ON -DBENCHMARK_ENABLE_ASSEMBLY_TESTS=ON -DBENCHMARK_USE_BUNDLED_GTEST=ON -DBENCHMARK_ENABLE_GTEST_TESTS=ON",
      "cmake --build /test_workspace/workspace/new/build -- -j 1"
    ],
    "old_test_script": [
      "cd /test_workspace/workspace/old/build",
      "ctest --output-on-failure"
    ],
    "new_test_script": [
      "cd /test_workspace/workspace/new/build",
      "ctest --output-on-failure"
    ],
    "build_system": "cmake"
  },
  "performance_analysis": {
    "is_significant": false,
    "p_value": 1.0,
    "is_pair_significant": false,
    "pair_p_value": 1.0,
    "is_binom_significant": false,
    "binom_p_value": 1.0,
    "is_wilcoxon_significant": false,
    "wilcoxon_p_value": 0.9999991344368026,
    "is_mannwhitney_significant": false,
    "mannwhitney_p_value": 0.039756890557733314,
    "relative_improvement": 0.00028001856561443613,
    "absolute_improvement_ms": 73.00000000009277,
    "old_mean_ms": 260697.00000000006,
    "new_mean_ms": 260623.99999999997,
    "old_std_ms": 139.213306934314,
    "new_std_ms": 252.30796726386922,
    "effect_size_cohens_d": 0.35825733373269647,
    "old_ci95_ms": [
      260645.0168968724,
      260748.9831031277
    ],
    "new_ci95_ms": [
      260529.78665667068,
      260718.21334332923
    ],
    "old_ci99_ms": [
      260626.94161157345,
      260767.05838842667
    ],
    "new_ci99_ms": [
      260497.02729916442,
      260750.97270083553
    ],
    "new_times_s": [
      260.73,
      260.89,
      260.4,
      260.7,
      260.73,
      260.73,
      260.58,
      261.28,
      260.43,
      260.56,
      260.76,
      260.48,
      260.59,
      260.52,
      260.6,
      260.54,
      260.62,
      260.91,
      260.7,
      260.7,
      260.83,
      260.57,
      260.44,
      260.92,
      260.83,
      260.67,
      260.61,
      260.47,
      260.47,
      259.74,
      260.45
    ],
    "old_times_s": [
      261.31,
      260.8,
      260.7,
      260.88,
      260.32,
      260.73,
      260.71,
      260.67,
      260.62,
      260.71,
      260.5,
      260.56,
      260.65,
      260.86,
      260.8,
      260.71,
      260.73,
      260.8,
      260.76,
      260.68,
      260.53,
      260.74,
      260.45,
      260.62,
      260.91,
      260.95,
      260.73,
      260.55,
      260.85,
      260.73,
      260.66
    ]
  },
  "tests": {
    "total_tests": 9,
    "significant_improvements": 0,
    "significant_improvements_tests": [],
    "significant_regressions": 0,
    "significant_regressions_tests": [],
    "significant_pair_improvements": 0,
    "significant_pair_improvements_tests": [],
    "significant_pair_regressions": 0,
    "significant_pair_regressions_tests": [],
    "significant_binom_improvements": 0,
    "significant_binom_improvements_tests": [],
    "significant_binom_regressions": 0,
    "significant_binom_regressions_tests": [],
    "significant_wilcoxon_improvements": 0,
    "significant_wilcoxon_improvements_tests": [],
    "significant_wilcoxon_regressions": 0,
    "significant_wilcoxon_regressions_tests": [],
    "significant_mannwhitney_improvements": 0,
    "significant_mannwhitney_improvements_tests": [],
    "significant_mannwhitney_regressions": 0,
    "significant_mannwhitney_regressions_tests": [],
    "tests": [
      {
        "test_name": "scalar",
        "is_significant": false,
        "p_value": 1.0,
        "is_pair_significant": false,
        "pair_p_value": 1.0,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999985892458129,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.7219138946310668,
        "relative_improvement": -0.002438033319788796,
        "absolute_improvement_ms": -2.142857142857113,
        "old_mean_ms": 878.9285714285713,
        "new_mean_ms": 881.0714285714284,
        "old_std_ms": 5.669467095138414,
        "new_std_ms": 9.560445408144778,
        "effect_size_cohens_d": -0.27264383161388017,
        "old_ci95_ms": [
          876.7301815894853,
          881.1269612676573
        ],
        "new_ci95_ms": [
          877.3642748496219,
          884.7785822932349
        ],
        "old_ci99_ms": [
          875.9599825459409,
          881.8971603112017
        ],
        "new_ci99_ms": [
          876.0654850717386,
          886.0773720711181
        ],
        "new_times": [
          0.92,
          0.88,
          0.88,
          0.88,
          0.88,
          0.87,
          0.88,
          0.88,
          0.87,
          0.88,
          0.88,
          0.88,
          0.88,
          0.88,
          0.88,
          0.88,
          0.88,
          0.89,
          0.88,
          0.87,
          0.88,
          0.88,
          0.88,
          0.87,
          0.9,
          0.88,
          0.88,
          0.88
        ],
        "old_times": [
          0.88,
          0.87,
          0.88,
          0.88,
          0.88,
          0.88,
          0.89,
          0.88,
          0.88,
          0.88,
          0.88,
          0.87,
          0.89,
          0.87,
          0.88,
          0.89,
          0.88,
          0.88,
          0.88,
          0.88,
          0.87,
          0.87,
          0.87,
          0.88,
          0.88,
          0.88,
          0.88,
          0.88
        ]
      },
      {
        "test_name": "unpack_scalarf_uXX_unsafe",
        "is_significant": false,
        "p_value": 0.9999999523249191,
        "is_pair_significant": false,
        "pair_p_value": 1.0,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999999999882268,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.28404582955518654,
        "relative_improvement": 0.00014997047456282613,
        "absolute_improvement_ms": 8.135593220337967,
        "old_mean_ms": 54247.96610169491,
        "new_mean_ms": 54239.83050847457,
        "old_std_ms": 2646.544122423532,
        "new_std_ms": 2642.775116351165,
        "effect_size_cohens_d": 0.003076233741104193,
        "old_ci95_ms": [
          53558.27294701327,
          54937.65925637656
        ],
        "new_ci95_ms": [
          53551.119562124935,
          54928.54145482421
        ],
        "old_ci99_ms": [
          53330.328725113664,
          55165.60347827616
        ],
        "new_ci99_ms": [
          53323.49996098235,
          55156.1610559668
        ],
        "new_times": [
          56.85,
          51.18,
          56.94,
          51.54,
          56.84,
          51.54,
          56.84,
          51.55,
          56.88,
          51.64,
          56.79,
          52.35,
          56.82,
          51.43,
          56.83,
          51.61,
          56.78,
          51.53,
          56.85,
          51.47,
          56.79,
          51.52,
          56.83,
          51.61,
          56.84,
          51.55,
          56.84,
          51.53,
          56.82,
          51.52,
          56.83,
          51.6,
          56.98,
          51.65,
          56.8,
          51.64,
          56.81,
          51.53,
          56.89,
          51.61,
          56.75,
          51.51,
          56.69,
          51.61,
          56.94,
          51.62,
          56.84,
          51.61,
          56.83,
          51.62,
          56.75,
          51.64,
          56.94,
          51.51,
          56.76,
          51.57,
          56.26,
          51.5,
          56.75
        ],
        "old_times": [
          56.89,
          51.62,
          56.83,
          51.56,
          56.89,
          51.6,
          56.51,
          51.62,
          56.8,
          51.57,
          56.85,
          51.53,
          56.93,
          51.55,
          56.82,
          51.54,
          56.76,
          51.55,
          56.77,
          51.58,
          56.71,
          51.55,
          56.87,
          51.62,
          56.84,
          51.61,
          56.88,
          51.57,
          56.85,
          51.57,
          56.91,
          51.6,
          56.9,
          51.6,
          56.91,
          51.62,
          56.82,
          51.57,
          56.8,
          51.53,
          56.75,
          51.51,
          56.66,
          51.56,
          56.82,
          51.61,
          56.9,
          51.67,
          56.84,
          51.66,
          56.87,
          51.52,
          56.93,
          51.56,
          56.9,
          51.65,
          56.79,
          51.52,
          56.81
        ]
      },
      {
        "test_name": "pack_vector4_64",
        "is_significant": false,
        "p_value": 1.0,
        "is_pair_significant": false,
        "pair_p_value": 1.0,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999999393422746,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 1.0,
        "relative_improvement": 0.0,
        "absolute_improvement_ms": 0.0,
        "old_mean_ms": 40.0,
        "new_mean_ms": 40.0,
        "old_std_ms": 0.0,
        "new_std_ms": 0.0,
        "effect_size_cohens_d": "NaN",
        "old_ci95_ms": [
          40.0,
          40.0
        ],
        "new_ci95_ms": [
          40.0,
          40.0
        ],
        "old_ci99_ms": [
          40.0,
          40.0
        ],
        "new_ci99_ms": [
          40.0,
          40.0
        ],
        "new_times": [
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04
        ],
        "old_times": [
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04,
          0.04
        ]
      },
      {
        "test_name": "pack_vector4_XX",
        "is_significant": false,
        "p_value": 0.9999996827230935,
        "is_pair_significant": false,
        "pair_p_value": 1.0,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999999999903161,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.33223780690367355,
        "relative_improvement": 0.00039231950500490147,
        "absolute_improvement_ms": 5.9322033898308035,
        "old_mean_ms": 15120.847457627118,
        "new_mean_ms": 15114.915254237287,
        "old_std_ms": 792.8479615429023,
        "new_std_ms": 791.8798517394432,
        "effect_size_cohens_d": 0.007486714416401204,
        "old_ci95_ms": [
          14914.230153518585,
          15327.464761735651
        ],
        "new_ci95_ms": [
          14908.550240917624,
          15321.280267556951
        ],
        "old_ci99_ms": [
          14845.942944494807,
          15395.75197075943
        ],
        "new_ci99_ms": [
          14840.346414231588,
          15389.484094242986
        ],
        "new_times": [
          15.89,
          14.32,
          15.88,
          14.31,
          15.94,
          14.31,
          15.94,
          14.32,
          15.81,
          14.34,
          15.88,
          14.33,
          15.89,
          14.31,
          15.88,
          14.32,
          15.88,
          14.32,
          15.9,
          14.31,
          15.88,
          14.31,
          15.88,
          14.31,
          15.9,
          14.31,
          15.89,
          14.31,
          15.87,
          14.33,
          15.88,
          14.34,
          15.92,
          14.32,
          15.87,
          14.31,
          15.89,
          14.32,
          15.89,
          14.31,
          15.88,
          14.31,
          15.89,
          14.33,
          15.89,
          14.31,
          15.89,
          14.31,
          15.88,
          14.31,
          15.88,
          14.34,
          15.9,
          14.3,
          15.87,
          14.3,
          15.88,
          14.31,
          15.88
        ],
        "old_times": [
          15.89,
          14.37,
          15.88,
          14.33,
          15.9,
          14.3,
          15.86,
          14.32,
          15.89,
          14.31,
          15.88,
          14.32,
          15.88,
          14.33,
          15.88,
          14.33,
          15.9,
          14.3,
          15.89,
          14.34,
          15.88,
          14.32,
          15.88,
          14.31,
          15.88,
          14.36,
          15.88,
          14.31,
          15.88,
          14.3,
          15.88,
          14.31,
          15.94,
          14.31,
          15.9,
          14.32,
          15.88,
          14.32,
          15.88,
          14.31,
          16.03,
          14.31,
          15.88,
          14.32,
          15.88,
          14.32,
          15.88,
          14.31,
          15.88,
          14.34,
          15.88,
          14.33,
          15.9,
          14.31,
          15.96,
          14.35,
          15.89,
          14.32,
          15.89
        ]
      },
      {
        "test_name": "pack_vector3_48",
        "is_significant": false,
        "p_value": 0.9339976305658879,
        "is_pair_significant": false,
        "pair_p_value": 0.9213207083087084,
        "is_binom_significant": false,
        "binom_p_value": 0.9999999962747097,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999952147757805,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.5,
        "relative_improvement": 0.011627906976744196,
        "absolute_improvement_ms": 0.357142857142858,
        "old_mean_ms": 30.71428571428572,
        "new_mean_ms": 30.35714285714286,
        "old_std_ms": 3.7796447300922735,
        "new_std_ms": 1.8898223650461368,
        "effect_size_cohens_d": 0.1195228609334396,
        "old_ci95_ms": [
          29.248692488228375,
          32.17987894034306
        ],
        "new_ci95_ms": [
          29.624346244114186,
          31.089939470171533
        ],
        "old_ci99_ms": [
          28.735226459198806,
          32.69334496937263
        ],
        "new_ci99_ms": [
          29.367613229599403,
          31.34667248468632
        ],
        "new_times": [
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.04,
          0.03,
          0.03,
          0.03,
          0.03
        ],
        "old_times": [
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.05,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03,
          0.03
        ]
      },
      {
        "test_name": "decay_vector3_48",
        "is_significant": false,
        "p_value": 1.0,
        "is_pair_significant": false,
        "pair_p_value": 1.0,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999999393422746,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 1.0,
        "relative_improvement": 0.0,
        "absolute_improvement_ms": 0.0,
        "old_mean_ms": 20.0,
        "new_mean_ms": 20.0,
        "old_std_ms": 0.0,
        "new_std_ms": 0.0,
        "effect_size_cohens_d": "NaN",
        "old_ci95_ms": [
          20.0,
          20.0
        ],
        "new_ci95_ms": [
          20.0,
          20.0
        ],
        "old_ci99_ms": [
          20.0,
          20.0
        ],
        "new_ci99_ms": [
          20.0,
          20.0
        ],
        "new_times": [
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02
        ],
        "old_times": [
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02,
          0.02
        ]
      },
      {
        "test_name": "pack_vector3_XX",
        "is_significant": false,
        "p_value": 0.9999999998266862,
        "is_pair_significant": false,
        "pair_p_value": 1.0,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999999999882497,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.21709102671106334,
        "relative_improvement": 0.0007220795892168962,
        "absolute_improvement_ms": 22.881355932206304,
        "old_mean_ms": 31688.135593220344,
        "new_mean_ms": 31665.25423728814,
        "old_std_ms": 1260.1169548570385,
        "new_std_ms": 1271.5119372867762,
        "effect_size_cohens_d": 0.018076207160625326,
        "old_ci95_ms": [
          31359.747326234898,
          32016.523860205787
        ],
        "new_ci95_ms": [
          31333.89642170801,
          31996.612052868266
        ],
        "old_ci99_ms": [
          31251.214701993456,
          32125.05648444723
        ],
        "new_ci99_ms": [
          31224.38235892508,
          32106.1261156512
        ],
        "new_times": [
          32.95,
          30.39,
          32.97,
          30.4,
          32.91,
          30.39,
          32.93,
          30.46,
          32.95,
          30.41,
          32.84,
          30.39,
          32.82,
          30.39,
          32.91,
          30.39,
          32.89,
          30.42,
          32.96,
          30.4,
          32.92,
          30.38,
          32.9,
          30.35,
          32.83,
          30.4,
          32.91,
          30.39,
          32.93,
          30.33,
          32.94,
          30.36,
          32.95,
          30.41,
          32.9,
          30.41,
          32.93,
          30.48,
          32.92,
          30.39,
          32.93,
          30.45,
          32.91,
          30.47,
          32.93,
          30.43,
          32.95,
          30.33,
          32.84,
          30.4,
          32.92,
          30.23,
          32.52,
          30.39,
          32.92,
          30.15,
          32.92,
          30.38,
          32.98
        ],
        "old_times": [
          32.9,
          30.39,
          32.9,
          30.49,
          32.96,
          30.39,
          32.95,
          30.46,
          32.91,
          30.37,
          32.96,
          30.41,
          32.91,
          30.39,
          32.93,
          30.43,
          32.93,
          30.38,
          32.91,
          30.39,
          32.89,
          30.4,
          32.92,
          30.41,
          33.01,
          30.33,
          32.89,
          30.43,
          32.9,
          30.41,
          32.96,
          30.39,
          32.94,
          30.4,
          32.9,
          30.4,
          32.91,
          30.39,
          32.86,
          30.41,
          32.91,
          30.44,
          32.93,
          30.4,
          32.94,
          30.42,
          32.96,
          30.52,
          32.97,
          30.4,
          32.87,
          30.58,
          32.57,
          30.5,
          32.93,
          30.43,
          32.92,
          30.39,
          33.01
        ]
      },
      {
        "test_name": "decay_vector3_XX",
        "is_significant": false,
        "p_value": 1.0,
        "is_pair_significant": false,
        "pair_p_value": 1.0,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.999999010798294,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.7650237718455593,
        "relative_improvement": 0.0006761325219743325,
        "absolute_improvement_ms": 1.07142857142839,
        "old_mean_ms": 1584.642857142857,
        "new_mean_ms": 1583.5714285714287,
        "old_std_ms": 12.317450089997372,
        "new_std_ms": 6.784669927988105,
        "effect_size_cohens_d": 0.107750308590878,
        "old_ci95_ms": [
          1579.8666486091627,
          1589.4190656765516
        ],
        "new_ci95_ms": [
          1580.940608217249,
          1586.2022489256083
        ],
        "old_ci99_ms": [
          1578.193318802494,
          1591.09239548322
        ],
        "new_ci99_ms": [
          1580.0189084875194,
          1587.123948655338
        ],
        "new_times": [
          1.59,
          1.58,
          1.59,
          1.58,
          1.59,
          1.59,
          1.58,
          1.61,
          1.58,
          1.58,
          1.58,
          1.58,
          1.58,
          1.58,
          1.59,
          1.58,
          1.58,
          1.58,
          1.58,
          1.58,
          1.58,
          1.58,
          1.58,
          1.58,
          1.59,
          1.59,
          1.58,
          1.58
        ],
        "old_times": [
          1.58,
          1.58,
          1.58,
          1.58,
          1.58,
          1.59,
          1.58,
          1.58,
          1.58,
          1.58,
          1.58,
          1.63,
          1.59,
          1.58,
          1.58,
          1.58,
          1.58,
          1.58,
          1.6,
          1.58,
          1.58,
          1.58,
          1.58,
          1.58,
          1.58,
          1.58,
          1.58,
          1.62
        ]
      },
      {
        "test_name": "pack_vector2_XX",
        "is_significant": false,
        "p_value": 0.9999999933788483,
        "is_pair_significant": false,
        "pair_p_value": 1.0,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999999999882897,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.3751268217815173,
        "relative_improvement": 4.2325482963954615e-05,
        "absolute_improvement_ms": 1.1864406779693581,
        "old_mean_ms": 28031.355932203394,
        "new_mean_ms": 28030.169491525423,
        "old_std_ms": 1276.084336239953,
        "new_std_ms": 1273.315644056105,
        "effect_size_cohens_d": 0.000930760169040531,
        "old_ci95_ms": [
          27698.806542966224,
          28363.90532144056
        ],
        "new_ci95_ms": [
          27698.341627401114,
          28361.997355649735
        ],
        "old_ci99_ms": [
          27588.898663993805,
          28473.81320041298
        ],
        "new_ci99_ms": [
          27588.672213142047,
          28471.6667699088
        ],
        "new_times": [
          29.25,
          26.75,
          29.28,
          26.7,
          29.3,
          26.79,
          29.27,
          26.73,
          29.3,
          26.72,
          29.26,
          26.71,
          29.25,
          26.73,
          29.24,
          26.73,
          29.26,
          26.8,
          29.26,
          26.75,
          29.25,
          26.71,
          29.32,
          26.71,
          29.27,
          26.73,
          29.27,
          26.74,
          29.25,
          26.81,
          29.26,
          26.75,
          29.29,
          26.73,
          29.32,
          26.74,
          29.27,
          26.73,
          29.28,
          26.73,
          29.24,
          26.74,
          29.24,
          26.73,
          29.3,
          26.8,
          29.28,
          26.9,
          29.26,
          26.73,
          29.28,
          26.77,
          29.33,
          26.74,
          29.27,
          26.73,
          29.24,
          26.72,
          29.24
        ],
        "old_times": [
          29.32,
          26.78,
          29.24,
          26.78,
          29.27,
          26.72,
          29.28,
          26.75,
          29.29,
          26.76,
          29.29,
          26.74,
          29.25,
          26.73,
          29.26,
          26.75,
          29.28,
          26.73,
          29.27,
          26.72,
          29.27,
          26.72,
          29.27,
          26.77,
          29.33,
          26.77,
          29.33,
          26.73,
          29.25,
          26.74,
          29.25,
          26.75,
          29.27,
          26.71,
          29.24,
          26.71,
          29.3,
          26.74,
          29.26,
          26.72,
          29.36,
          26.75,
          29.26,
          26.76,
          29.25,
          26.76,
          29.35,
          26.77,
          29.29,
          26.76,
          29.26,
          26.79,
          29.22,
          26.72,
          29.25,
          26.74,
          29.24,
          26.73,
          29.25
        ]
      }
    ]
  },
  "logs": {
    "full_log_path": "/logs/full.log",
    "config_log_path": "/logs/config.log",
    "build_log_path": "/logs/build.log",
    "test_log_path": "/logs/test.log",
    "build_success": true,
    "test_success": true
  },
  "raw_timing_data": {
    "warmup_runs": 1,
    "measurement_runs": 30,
    "min_exec_time_improvement": 0.05,
    "min_p_value": 0.05
  }
}