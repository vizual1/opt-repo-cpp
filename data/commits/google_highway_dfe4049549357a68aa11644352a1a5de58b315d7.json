{
  "metadata": {
    "collection_date": "2026-02-03T20:01:54.799263",
    "repository": "https://github.com/google/highway",
    "repository_name": "google/highway"
  },
  "commit_info": {
    "old_sha": "16c4dd9b8e8453c820c816d583a7ffb717dd21f7",
    "new_sha": "dfe4049549357a68aa11644352a1a5de58b315d7",
    "commit_message": [
      "Pool: reduce false sharing, minor cleanup\n\nPragma pack not necessary because we anyway have static_assert on the size\nFewer configs for autotuning\nPass initial config via SendConfig (also ensures workers are ready)\nRemove separate ThreadPool::config_\nRemove unused Type()\nMove AdvanceWorkerEpoch to MainWakeAndBarrier - avoids extra load\n\nPiperOrigin-RevId: 810382947"
    ],
    "commit_date": "2025-09-23T11:15:51+00:00",
    "patch": [
      "--- hwy/contrib/thread_pool/thread_pool.h\n@@ -180,40 +180,42 @@ static inline const char* ToString(WaitType type) {\n   }\n }\n \n-// We want predictable struct/class sizes so we can reason about cache lines.\n-#pragma pack(push, 1)\n-\n // Parameters governing the main and worker thread behavior. Can be updated at\n-// runtime via `SetWaitMode`. Both have copies which are carefully synchronized\n-// (two-phase barrier). 32 bits leave room for two future fields. 64 bits would\n-// also be fine because this does not go through futex.\n+// runtime via `SetWaitMode`, which calls `SendConfig`. Both have copies which\n+// are carefully synchronized. 32 bits leave room for two future fields.\n+// 64 bits would also be fine because this does not go through futex.\n struct Config {  // 4 bytes\n   static std::vector<Config> AllCandidates(PoolWaitMode wait_mode) {\n-    std::vector<SpinType> spin_types(size_t{1}, DetectSpin());\n-    // Monitor-based spin may be slower, so also try Pause.\n-    if (spin_types[0] != SpinType::kPause) {\n-      spin_types.push_back(SpinType::kPause);\n-    }\n+    std::vector<Config> candidates;\n \n-    std::vector<WaitType> wait_types;\n     if (wait_mode == PoolWaitMode::kSpin) {\n+      std::vector<SpinType> spin_types;\n+      spin_types.reserve(2);\n+      spin_types.push_back(DetectSpin());\n+      // Monitor-based spin may be slower, so also try Pause.\n+      if (spin_types[0] != SpinType::kPause) {\n+        spin_types.push_back(SpinType::kPause);\n+      }\n+\n       // All except `kBlock`.\n+      std::vector<WaitType> wait_types;\n       for (size_t wait = 0;; ++wait) {\n         const WaitType wait_type = static_cast<WaitType>(wait);\n         if (wait_type == WaitType::kSentinel) break;\n         if (wait_type != WaitType::kBlock) wait_types.push_back(wait_type);\n       }\n-    } else {\n-      wait_types.push_back(WaitType::kBlock);\n-    }\n \n-    std::vector<Config> candidates;\n-    candidates.reserve(50);\n-    for (const SpinType spin_type : spin_types) {\n-      for (const WaitType wait_type : wait_types) {\n-        candidates.emplace_back(spin_type, wait_type);\n+      candidates.reserve(spin_types.size() * wait_types.size());\n+      for (const SpinType spin_type : spin_types) {\n+        for (const WaitType wait_type : wait_types) {\n+          candidates.emplace_back(spin_type, wait_type);\n+        }\n       }\n+    } else {\n+      // kBlock does not use spin, so there is only one candidate.\n+      candidates.emplace_back(SpinType::kPause, WaitType::kBlock);\n     }\n+\n     return candidates;\n   }\n \n@@ -224,9 +226,10 @@ struct Config {  // 4 bytes\n     return buf;\n   }\n \n-  Config() {}\n   Config(SpinType spin_type, WaitType wait_type)\n       : spin_type(spin_type), wait_type(wait_type) {}\n+  // Workers initially spin until ThreadPool sends them their actual config.\n+  Config() : Config(SpinType::kPause, WaitType::kSpinSeparate) {}\n \n   SpinType spin_type;\n   WaitType wait_type;\n@@ -270,14 +273,16 @@ class alignas(HWY_ALIGNMENT) Worker {  // HWY_ALIGNMENT bytes\n   Worker& operator=(const Worker&) = delete;\n \n   size_t Index() const { return worker_; }\n+  // For work stealing.\n   Worker* AllWorkers() { return workers_; }\n   const Worker* AllWorkers() const { return workers_; }\n   size_t NumThreads() const { return num_threads_; }\n \n   // ------------------------ Per-worker storage for `SendConfig`\n \n   Config NextConfig() const { return next_config_; }\n-  // For workers, but no harm if also called by main thread.\n+  // Called during `SendConfig` by workers and now also the main thread. This\n+  // avoids a separate `ThreadPool` member which risks going out of sync.\n   void SetNextConfig(Config copy) { next_config_ = copy; }\n \n   uint32_t GetExit() const { return exit_; }\n@@ -321,8 +326,9 @@ class alignas(HWY_ALIGNMENT) Worker {  // HWY_ALIGNMENT bytes\n \n   // ------------------------ Barrier: Main thread waits for workers\n \n-  // Used for loads and UntilEqual.\n+  // For use by `HasReached` and `UntilReached`.\n   const std::atomic<uint32_t>& Barrier() const { return barrier_epoch_; }\n+  // Setting to `epoch` signals that the worker has reached the barrier.\n   void StoreBarrier(uint32_t epoch) { barrier_epoch_.store(epoch, kRel); }\n \n  private:\n@@ -352,8 +358,6 @@ class alignas(HWY_ALIGNMENT) Worker {  // HWY_ALIGNMENT bytes\n };\n static_assert(sizeof(Worker) == HWY_ALIGNMENT, \"\");\n \n-#pragma pack(pop)\n-\n // Creates/destroys `Worker` using preallocated storage. See comment at\n // `ThreadPool::worker_bytes_` for why we do not dynamically allocate.\n class WorkerLifecycle {  // 0 bytes\n@@ -388,10 +392,9 @@ class WorkerLifecycle {  // 0 bytes\n   }\n };\n \n-#pragma pack(push, 1)\n // Stores arguments to `Run`: the function and range of task indices. Set by\n // the main thread, read by workers including the main thread.\n-class alignas(8) Tasks {\n+class Tasks {\n   static constexpr auto kAcq = std::memory_order_acquire;\n \n   // Signature of the (internal) function called from workers(s) for each\n@@ -414,7 +417,7 @@ class alignas(8) Tasks {\n   }\n \n   // Assigns workers their share of `[begin, end)`. Called from the main\n-  // thread; workers are initializing or spinning for a command.\n+  // thread; workers are initializing or waiting for a command.\n   static void DivideRangeAmongWorkers(const uint64_t begin, const uint64_t end,\n                                       const Divisor64& div_workers,\n                                       Worker* workers) {\n@@ -524,7 +527,6 @@ class alignas(8) Tasks {\n   std::atomic<const void*> opaque_;\n };\n static_assert(sizeof(Tasks) == 16 + 2 * sizeof(void*), \"\");\n-#pragma pack(pop)\n \n // ------------------------------ Threads wait, main wakes them\n \n@@ -550,8 +552,6 @@ static_assert(sizeof(Tasks) == 16 + 2 * sizeof(void*), \"\");\n \n // Futex: blocking reduces apparent CPU usage, but has higher wake latency.\n struct WaitBlock {\n-  WaitType Type() const { return WaitType::kBlock; }\n-\n   // Wakes all workers by storing the current `epoch`.\n   void WakeWorkers(Worker* workers, const uint32_t epoch) const {\n     HWY_DASSERT(epoch != 0);\n@@ -561,51 +561,47 @@ struct WaitBlock {\n \n   // Waits until `WakeWorkers(_, epoch)` has been called.\n   template <class Spin>\n-  void UntilWoken(const Worker& worker, const Spin& /*spin*/) const {\n+  size_t UntilWoken(const Worker& worker, const Spin& /*spin*/) const {\n     HWY_DASSERT(worker.Index() != 0);  // main is 0\n     const uint32_t epoch = worker.WorkerEpoch();\n     const Worker* workers = worker.AllWorkers();\n     BlockUntilDifferent(epoch - 1, workers[1].Waiter());\n+    return 1;  // iterations\n   }\n };\n \n // Single u32: single store by the main thread. All worker threads poll this\n // one cache line and thus have it in a shared state, which means the store\n // will invalidate each of them, leading to more transactions than SpinSeparate.\n struct WaitSpin1 {\n-  WaitType Type() const { return WaitType::kSpin1; }\n-\n   void WakeWorkers(Worker* workers, const uint32_t epoch) const {\n     workers[1].StoreWaiter(epoch);\n   }\n \n+  // Returns the number of spin-wait iterations.\n   template <class Spin>\n-  void UntilWoken(const Worker& worker, const Spin& spin) const {\n+  size_t UntilWoken(const Worker& worker, const Spin& spin) const {\n     HWY_DASSERT(worker.Index() != 0);  // main is 0\n     const Worker* workers = worker.AllWorkers();\n     const uint32_t epoch = worker.WorkerEpoch();\n-    (void)spin.UntilEqual(epoch, workers[1].Waiter());\n-    // TODO: store reps in stats.\n+    return spin.UntilEqual(epoch, workers[1].Waiter());\n   }\n };\n \n // Separate u32 per thread: more stores for the main thread, but each worker\n // only polls its own cache line, leading to fewer cache-coherency transactions.\n struct WaitSpinSeparate {\n-  WaitType Type() const { return WaitType::kSpinSeparate; }\n-\n   void WakeWorkers(Worker* workers, const uint32_t epoch) const {\n     for (size_t thread = 0; thread < workers->NumThreads(); ++thread) {\n       workers[1 + thread].StoreWaiter(epoch);\n     }\n   }\n \n   template <class Spin>\n-  void UntilWoken(const Worker& worker, const Spin& spin) const {\n+  size_t UntilWoken(const Worker& worker, const Spin& spin) const {\n     HWY_DASSERT(worker.Index() != 0);  // main is 0\n     const uint32_t epoch = worker.WorkerEpoch();\n-    (void)spin.UntilEqual(epoch, worker.Waiter());\n-    // TODO: store reps in stats.\n+    return spin.UntilEqual(epoch, worker.Waiter());\n   }\n };\n \n@@ -653,6 +649,7 @@ class Barrier {\n     workers[0].StoreBarrier(epoch);  // for main thread HasReached.\n \n     for (size_t i = 0; i < num_threads; ++i) {\n+      // TODO: log number of spin-wait iterations.\n       (void)spin.UntilEqual(epoch, workers[1 + i].Barrier());\n     }\n   }\n@@ -680,19 +677,6 @@ class Barrier {\n //\n // For load-balancing, we use work stealing in random order.\n class alignas(HWY_ALIGNMENT) ThreadPool {\n- public:\n-  // This typically includes hyperthreads, hence it is a loose upper bound.\n-  // -1 because these are in addition to the main thread.\n-  static size_t MaxThreads() {\n-    LogicalProcessorSet lps;\n-    // This is OS dependent, but more accurate if available because it takes\n-    // into account restrictions set by cgroups or numactl/taskset.\n-    if (GetThreadAffinity(lps)) {\n-      return lps.Count() - 1;\n-    }\n-    return static_cast<size_t>(std::thread::hardware_concurrency() - 1);\n-  }\n-\n   // Called by `std::thread`. Could also be a lambda, but annotating with\n   // `HWY_POOL_PROFILE` makes it easier to inspect the generated code.\n   class ThreadFunc {\n@@ -702,15 +686,14 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n       template <class Spin, class Wait>\n       void operator()(const Spin& spin, const Wait& wait,\n                       pool::Worker& worker) const {\n-        wait.UntilWoken(worker, spin);\n+        // TODO: log number of spin-wait iterations.\n+        (void)wait.UntilWoken(worker, spin);\n       }\n     };\n \n    public:\n-    ThreadFunc(pool::Worker& worker, pool::Tasks& tasks, pool::Config config)\n-        : worker_(worker), tasks_(tasks) {\n-      worker.SetNextConfig(config);\n-    }\n+    ThreadFunc(pool::Worker& worker, pool::Tasks& tasks)\n+        : worker_(worker), tasks_(tasks) {}\n \n     HWY_POOL_PROFILE void operator()() {\n       // Ensure main thread's writes are visible (synchronizes with fence in\n@@ -743,14 +726,38 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n     pool::Tasks& tasks_;\n   };\n \n+  // Used to initialize `num_threads_` from the ctor argument.\n+  static size_t ClampedNumThreads(size_t num_threads) {\n+    // Upper bound is required for `worker_bytes_`.\n+    if (HWY_UNLIKELY(num_threads > pool::kMaxThreads)) {\n+      HWY_WARN(\"ThreadPool: clamping num_threads %zu to %zu.\", num_threads,\n+               pool::kMaxThreads);\n+      num_threads = pool::kMaxThreads;\n+    }\n+    return num_threads;\n+  }\n+\n+ public:\n+  // This typically includes hyperthreads, hence it is a loose upper bound.\n+  // -1 because these are in addition to the main thread.\n+  static size_t MaxThreads() {\n+    LogicalProcessorSet lps;\n+    // This is OS dependent, but more accurate if available because it takes\n+    // into account restrictions set by cgroups or numactl/taskset.\n+    if (GetThreadAffinity(lps)) {\n+      return lps.Count() - 1;\n+    }\n+    return static_cast<size_t>(std::thread::hardware_concurrency() - 1);\n+  }\n+\n   // `num_threads` is the number of *additional* threads to spawn, which should\n   // not exceed `MaxThreads()`. Note that the main thread also performs work.\n   explicit ThreadPool(size_t num_threads)\n-      : have_timer_stop_(platform::HaveTimerStop(cpu100_)),\n-        num_threads_(ClampedNumThreads(num_threads)),\n+      : num_threads_(ClampedNumThreads(num_threads)),\n         div_workers_(1 + num_threads_),\n         workers_(pool::WorkerLifecycle::Init(worker_bytes_, num_threads_,\n-                                             div_workers_)) {\n+                                             div_workers_)),\n+        have_timer_stop_(platform::HaveTimerStop(cpu100_)) {\n     // Leaves the default wait mode as `kBlock`, which means futex, because\n     // spinning only makes sense when threads are pinned and wake latency is\n     // important, so it must explicitly be requested by calling `SetWaitMode`.\n@@ -759,26 +766,28 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n       AutoTuner().SetCandidates(\n           pool::Config::AllCandidates(mode));\n     }\n-    config_ = AutoTuner().Candidates()[0];\n \n     threads_.reserve(num_threads_);\n     for (size_t thread = 0; thread < num_threads_; ++thread) {\n-      threads_.emplace_back(ThreadFunc(workers_[1 + thread], tasks_, config_));\n+      threads_.emplace_back(ThreadFunc(workers_[1 + thread], tasks_));\n     }\n \n-    // No barrier is required here because wakeup works regardless of the\n-    // relative order of wake and wait.\n+    // Threads' `Config` defaults to spinning. Change to `kBlock` (see above).\n+    // This also ensures all threads have started before we return, so that\n+    // startup latency is billed to the ctor, not the first `Run`.\n+    SendConfig(AutoTuner().Candidates()[0]);\n   }\n \n   // If we created threads, waits for them all to exit.\n   ~ThreadPool() {\n     // There is no portable way to request threads to exit like `ExitThread` on\n     // Windows, otherwise we could call that from `Run`. Instead, we must cause\n     // the thread to wake up and exit. We can just use `Run`.\n-    (void)RunWithoutAutotune(0, NumWorkers(),\n-                             [this](uint64_t /*task*/, size_t worker) {\n-                               workers_[worker].SetExit(1);\n-                             });\n+    (void)RunWithoutAutotune(\n+        0, NumWorkers(), [this](HWY_MAYBE_UNUSED uint64_t task, size_t worker) {\n+          HWY_DASSERT(task == worker);\n+          workers_[worker].SetExit(1);\n+        });\n \n     for (std::thread& thread : threads_) {\n       HWY_DASSERT(thread.joinable());\n@@ -807,8 +816,8 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n                                   : AutoTuner().NextConfig());\n   }\n \n-  // For printing which are in use.\n-  pool::Config config() const { return config_; }\n+  // For printing which is in use.\n+  pool::Config config() const { return workers_[0].NextConfig(); }\n \n   bool AutoTuneComplete() const { return AutoTuner().Best(); }\n   Span<CostDistribution> AutoTuneCosts() { return AutoTuner().Costs(); }\n@@ -863,24 +872,13 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n     } else {\n       HWY_IF_CONSTEXPR(pool::kVerbosity >= 2) {\n         fprintf(stderr, \"Pool %3zu: %s %9lu\\n\", NumWorkers(),\n-                config_.ToString().c_str(), t1 - t0);\n+                config().ToString().c_str(), t1 - t0);\n       }\n       SendConfig(auto_tuner.NextConfig());\n     }\n   }\n \n  private:\n-  // Used to initialize ThreadPool::num_threads_ from its ctor argument.\n-  static size_t ClampedNumThreads(size_t num_threads) {\n-    // Upper bound is required for `worker_bytes_`.\n-    if (HWY_UNLIKELY(num_threads > pool::kMaxThreads)) {\n-      HWY_WARN(\"ThreadPool: clamping num_threads %zu to %zu.\", num_threads,\n-               pool::kMaxThreads);\n-      num_threads = pool::kMaxThreads;\n-    }\n-    return num_threads;\n-  }\n-\n   // Debug-only re-entrancy detection.\n   void SetBusy() { HWY_DASSERT(!busy_.test_and_set()); }\n   void ClearBusy() { HWY_IF_CONSTEXPR(HWY_IS_DEBUG_BUILD) busy_.clear(); }\n@@ -895,7 +893,7 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n       pool::Worker* workers = main.AllWorkers();\n       HWY_DASSERT(&main == main.AllWorkers());  // main is first.\n       const size_t num_threads = main.NumThreads();\n-      const uint32_t epoch = main.WorkerEpoch();\n+      const uint32_t epoch = main.AdvanceWorkerEpoch();\n \n       HWY_IF_CONSTEXPR(HWY_IS_DEBUG_BUILD) {\n         for (size_t i = 0; i < 1 + num_threads; ++i) {\n@@ -904,13 +902,11 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n       }\n \n       wait.WakeWorkers(workers, epoch);\n-      // Threads might still be starting up and wake up late, but we wait for\n-      // them at the barrier below.\n \n       // Also perform work on the main thread before the barrier.\n       tasks.WorkerRun(&main);\n \n-      // Spin-waits until all *threads* (not the main thread, because it already\n+      // Spin-waits until all worker *threads* (not `main`, because it already\n       // knows it is here) called `WorkerReached`.\n       barrier.UntilReached(num_threads, workers, spin, epoch);\n       HWY_IF_CONSTEXPR(HWY_IS_DEBUG_BUILD) {\n@@ -919,7 +915,7 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n         }\n       }\n \n-      // Threads may already be waiting `UntilWoken`, which serves as the\n+      // Threads are or will soon be waiting `UntilWoken`, which serves as the\n       // 'release' phase of the barrier.\n     }\n   };\n@@ -951,11 +947,9 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n       pool::Tasks::DivideRangeAmongWorkers(begin, end, div_workers_, workers_);\n     }\n \n-    pool::Worker& main = workers_[0];\n-    const HWY_MAYBE_UNUSED uint32_t epoch = main.AdvanceWorkerEpoch();\n+    // Runs `MainWakeAndBarrier` with the first worker slot.\n+    CallWithConfig(config(), MainWakeAndBarrier(), workers_[0], tasks_);\n \n-    // Assign main thread the first worker slot (it used to be the last).\n-    CallWithConfig(config_, MainWakeAndBarrier(), main, tasks_);\n     if (is_root) {\n       PROFILER_END_ROOT_RUN();\n     }\n@@ -966,8 +960,8 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n   // Sends `next_config` to workers:\n   // - Main wakes threads using the current config.\n   // - Threads copy `next_config` into their `Worker` during `WorkerRun`.\n-  // - Threads notify the (unchanged) barrier and already wait for the next\n-  //   wake using the new config.\n+  // - Threads notify the (same) barrier and already wait for the next wake\n+  //   using `next_config`.\n   HWY_NOINLINE void SendConfig(pool::Config next_config) {\n     (void)RunWithoutAutotune(\n         0, NumWorkers(),\n@@ -978,7 +972,7 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n \n     // All have woken and are, or will be, waiting per `next_config`. Now we\n     // can entirely switch the main thread's config for the next wake.\n-    config_ = next_config;\n+    workers_[0].SetNextConfig(next_config);\n   }\n \n   using AutoTuneT = AutoTune<pool::Config, 30>;\n@@ -990,15 +984,17 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n     return auto_tune_[static_cast<size_t>(wait_mode_) - 1];\n   }\n \n-  char cpu100_[100];\n-  const bool have_timer_stop_;\n   const size_t num_threads_;  // not including main thread\n   const Divisor64 div_workers_;\n   pool::Worker* const workers_;  // points into `worker_bytes_`\n+  const bool have_timer_stop_;\n+  char cpu100_[100];  // write-only for `HaveTimerStop` in ctor.\n \n-  // The only mutable state:\n-  pool::Tasks tasks_;    // written by `Run` and read by workers.\n-  pool::Config config_;  // for use by the next `Run`. Updated via `SendConfig`.\n+  // This is written by the main thread and read by workers, via reference\n+  // passed to `ThreadFunc`. Padding ensures that the workers' cache lines are\n+  // not unnecessarily invalidated when the main thread writes other members.\n+  alignas(HWY_ALIGNMENT) pool::Tasks tasks_;\n+  HWY_MAYBE_UNUSED char padding_[HWY_ALIGNMENT - sizeof(pool::Tasks)];\n \n   // In debug builds, detects if functions are re-entered.\n   std::atomic_flag busy_ = ATOMIC_FLAG_INIT;"
    ],
    "files_changed": [
      {
        "filename": "hwy/contrib/thread_pool/thread_pool.h",
        "status": "modified",
        "additions": 98,
        "deletions": 102,
        "changes": 200,
        "patch": "@@ -180,40 +180,42 @@ static inline const char* ToString(WaitType type) {\n   }\n }\n \n-// We want predictable struct/class sizes so we can reason about cache lines.\n-#pragma pack(push, 1)\n-\n // Parameters governing the main and worker thread behavior. Can be updated at\n-// runtime via `SetWaitMode`. Both have copies which are carefully synchronized\n-// (two-phase barrier). 32 bits leave room for two future fields. 64 bits would\n-// also be fine because this does not go through futex.\n+// runtime via `SetWaitMode`, which calls `SendConfig`. Both have copies which\n+// are carefully synchronized. 32 bits leave room for two future fields.\n+// 64 bits would also be fine because this does not go through futex.\n struct Config {  // 4 bytes\n   static std::vector<Config> AllCandidates(PoolWaitMode wait_mode) {\n-    std::vector<SpinType> spin_types(size_t{1}, DetectSpin());\n-    // Monitor-based spin may be slower, so also try Pause.\n-    if (spin_types[0] != SpinType::kPause) {\n-      spin_types.push_back(SpinType::kPause);\n-    }\n+    std::vector<Config> candidates;\n \n-    std::vector<WaitType> wait_types;\n     if (wait_mode == PoolWaitMode::kSpin) {\n+      std::vector<SpinType> spin_types;\n+      spin_types.reserve(2);\n+      spin_types.push_back(DetectSpin());\n+      // Monitor-based spin may be slower, so also try Pause.\n+      if (spin_types[0] != SpinType::kPause) {\n+        spin_types.push_back(SpinType::kPause);\n+      }\n+\n       // All except `kBlock`.\n+      std::vector<WaitType> wait_types;\n       for (size_t wait = 0;; ++wait) {\n         const WaitType wait_type = static_cast<WaitType>(wait);\n         if (wait_type == WaitType::kSentinel) break;\n         if (wait_type != WaitType::kBlock) wait_types.push_back(wait_type);\n       }\n-    } else {\n-      wait_types.push_back(WaitType::kBlock);\n-    }\n \n-    std::vector<Config> candidates;\n-    candidates.reserve(50);\n-    for (const SpinType spin_type : spin_types) {\n-      for (const WaitType wait_type : wait_types) {\n-        candidates.emplace_back(spin_type, wait_type);\n+      candidates.reserve(spin_types.size() * wait_types.size());\n+      for (const SpinType spin_type : spin_types) {\n+        for (const WaitType wait_type : wait_types) {\n+          candidates.emplace_back(spin_type, wait_type);\n+        }\n       }\n+    } else {\n+      // kBlock does not use spin, so there is only one candidate.\n+      candidates.emplace_back(SpinType::kPause, WaitType::kBlock);\n     }\n+\n     return candidates;\n   }\n \n@@ -224,9 +226,10 @@ struct Config {  // 4 bytes\n     return buf;\n   }\n \n-  Config() {}\n   Config(SpinType spin_type, WaitType wait_type)\n       : spin_type(spin_type), wait_type(wait_type) {}\n+  // Workers initially spin until ThreadPool sends them their actual config.\n+  Config() : Config(SpinType::kPause, WaitType::kSpinSeparate) {}\n \n   SpinType spin_type;\n   WaitType wait_type;\n@@ -270,14 +273,16 @@ class alignas(HWY_ALIGNMENT) Worker {  // HWY_ALIGNMENT bytes\n   Worker& operator=(const Worker&) = delete;\n \n   size_t Index() const { return worker_; }\n+  // For work stealing.\n   Worker* AllWorkers() { return workers_; }\n   const Worker* AllWorkers() const { return workers_; }\n   size_t NumThreads() const { return num_threads_; }\n \n   // ------------------------ Per-worker storage for `SendConfig`\n \n   Config NextConfig() const { return next_config_; }\n-  // For workers, but no harm if also called by main thread.\n+  // Called during `SendConfig` by workers and now also the main thread. This\n+  // avoids a separate `ThreadPool` member which risks going out of sync.\n   void SetNextConfig(Config copy) { next_config_ = copy; }\n \n   uint32_t GetExit() const { return exit_; }\n@@ -321,8 +326,9 @@ class alignas(HWY_ALIGNMENT) Worker {  // HWY_ALIGNMENT bytes\n \n   // ------------------------ Barrier: Main thread waits for workers\n \n-  // Used for loads and UntilEqual.\n+  // For use by `HasReached` and `UntilReached`.\n   const std::atomic<uint32_t>& Barrier() const { return barrier_epoch_; }\n+  // Setting to `epoch` signals that the worker has reached the barrier.\n   void StoreBarrier(uint32_t epoch) { barrier_epoch_.store(epoch, kRel); }\n \n  private:\n@@ -352,8 +358,6 @@ class alignas(HWY_ALIGNMENT) Worker {  // HWY_ALIGNMENT bytes\n };\n static_assert(sizeof(Worker) == HWY_ALIGNMENT, \"\");\n \n-#pragma pack(pop)\n-\n // Creates/destroys `Worker` using preallocated storage. See comment at\n // `ThreadPool::worker_bytes_` for why we do not dynamically allocate.\n class WorkerLifecycle {  // 0 bytes\n@@ -388,10 +392,9 @@ class WorkerLifecycle {  // 0 bytes\n   }\n };\n \n-#pragma pack(push, 1)\n // Stores arguments to `Run`: the function and range of task indices. Set by\n // the main thread, read by workers including the main thread.\n-class alignas(8) Tasks {\n+class Tasks {\n   static constexpr auto kAcq = std::memory_order_acquire;\n \n   // Signature of the (internal) function called from workers(s) for each\n@@ -414,7 +417,7 @@ class alignas(8) Tasks {\n   }\n \n   // Assigns workers their share of `[begin, end)`. Called from the main\n-  // thread; workers are initializing or spinning for a command.\n+  // thread; workers are initializing or waiting for a command.\n   static void DivideRangeAmongWorkers(const uint64_t begin, const uint64_t end,\n                                       const Divisor64& div_workers,\n                                       Worker* workers) {\n@@ -524,7 +527,6 @@ class alignas(8) Tasks {\n   std::atomic<const void*> opaque_;\n };\n static_assert(sizeof(Tasks) == 16 + 2 * sizeof(void*), \"\");\n-#pragma pack(pop)\n \n // ------------------------------ Threads wait, main wakes them\n \n@@ -550,8 +552,6 @@ static_assert(sizeof(Tasks) == 16 + 2 * sizeof(void*), \"\");\n \n // Futex: blocking reduces apparent CPU usage, but has higher wake latency.\n struct WaitBlock {\n-  WaitType Type() const { return WaitType::kBlock; }\n-\n   // Wakes all workers by storing the current `epoch`.\n   void WakeWorkers(Worker* workers, const uint32_t epoch) const {\n     HWY_DASSERT(epoch != 0);\n@@ -561,51 +561,47 @@ struct WaitBlock {\n \n   // Waits until `WakeWorkers(_, epoch)` has been called.\n   template <class Spin>\n-  void UntilWoken(const Worker& worker, const Spin& /*spin*/) const {\n+  size_t UntilWoken(const Worker& worker, const Spin& /*spin*/) const {\n     HWY_DASSERT(worker.Index() != 0);  // main is 0\n     const uint32_t epoch = worker.WorkerEpoch();\n     const Worker* workers = worker.AllWorkers();\n     BlockUntilDifferent(epoch - 1, workers[1].Waiter());\n+    return 1;  // iterations\n   }\n };\n \n // Single u32: single store by the main thread. All worker threads poll this\n // one cache line and thus have it in a shared state, which means the store\n // will invalidate each of them, leading to more transactions than SpinSeparate.\n struct WaitSpin1 {\n-  WaitType Type() const { return WaitType::kSpin1; }\n-\n   void WakeWorkers(Worker* workers, const uint32_t epoch) const {\n     workers[1].StoreWaiter(epoch);\n   }\n \n+  // Returns the number of spin-wait iterations.\n   template <class Spin>\n-  void UntilWoken(const Worker& worker, const Spin& spin) const {\n+  size_t UntilWoken(const Worker& worker, const Spin& spin) const {\n     HWY_DASSERT(worker.Index() != 0);  // main is 0\n     const Worker* workers = worker.AllWorkers();\n     const uint32_t epoch = worker.WorkerEpoch();\n-    (void)spin.UntilEqual(epoch, workers[1].Waiter());\n-    // TODO: store reps in stats.\n+    return spin.UntilEqual(epoch, workers[1].Waiter());\n   }\n };\n \n // Separate u32 per thread: more stores for the main thread, but each worker\n // only polls its own cache line, leading to fewer cache-coherency transactions.\n struct WaitSpinSeparate {\n-  WaitType Type() const { return WaitType::kSpinSeparate; }\n-\n   void WakeWorkers(Worker* workers, const uint32_t epoch) const {\n     for (size_t thread = 0; thread < workers->NumThreads(); ++thread) {\n       workers[1 + thread].StoreWaiter(epoch);\n     }\n   }\n \n   template <class Spin>\n-  void UntilWoken(const Worker& worker, const Spin& spin) const {\n+  size_t UntilWoken(const Worker& worker, const Spin& spin) const {\n     HWY_DASSERT(worker.Index() != 0);  // main is 0\n     const uint32_t epoch = worker.WorkerEpoch();\n-    (void)spin.UntilEqual(epoch, worker.Waiter());\n-    // TODO: store reps in stats.\n+    return spin.UntilEqual(epoch, worker.Waiter());\n   }\n };\n \n@@ -653,6 +649,7 @@ class Barrier {\n     workers[0].StoreBarrier(epoch);  // for main thread HasReached.\n \n     for (size_t i = 0; i < num_threads; ++i) {\n+      // TODO: log number of spin-wait iterations.\n       (void)spin.UntilEqual(epoch, workers[1 + i].Barrier());\n     }\n   }\n@@ -680,19 +677,6 @@ class Barrier {\n //\n // For load-balancing, we use work stealing in random order.\n class alignas(HWY_ALIGNMENT) ThreadPool {\n- public:\n-  // This typically includes hyperthreads, hence it is a loose upper bound.\n-  // -1 because these are in addition to the main thread.\n-  static size_t MaxThreads() {\n-    LogicalProcessorSet lps;\n-    // This is OS dependent, but more accurate if available because it takes\n-    // into account restrictions set by cgroups or numactl/taskset.\n-    if (GetThreadAffinity(lps)) {\n-      return lps.Count() - 1;\n-    }\n-    return static_cast<size_t>(std::thread::hardware_concurrency() - 1);\n-  }\n-\n   // Called by `std::thread`. Could also be a lambda, but annotating with\n   // `HWY_POOL_PROFILE` makes it easier to inspect the generated code.\n   class ThreadFunc {\n@@ -702,15 +686,14 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n       template <class Spin, class Wait>\n       void operator()(const Spin& spin, const Wait& wait,\n                       pool::Worker& worker) const {\n-        wait.UntilWoken(worker, spin);\n+        // TODO: log number of spin-wait iterations.\n+        (void)wait.UntilWoken(worker, spin);\n       }\n     };\n \n    public:\n-    ThreadFunc(pool::Worker& worker, pool::Tasks& tasks, pool::Config config)\n-        : worker_(worker), tasks_(tasks) {\n-      worker.SetNextConfig(config);\n-    }\n+    ThreadFunc(pool::Worker& worker, pool::Tasks& tasks)\n+        : worker_(worker), tasks_(tasks) {}\n \n     HWY_POOL_PROFILE void operator()() {\n       // Ensure main thread's writes are visible (synchronizes with fence in\n@@ -743,14 +726,38 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n     pool::Tasks& tasks_;\n   };\n \n+  // Used to initialize `num_threads_` from the ctor argument.\n+  static size_t ClampedNumThreads(size_t num_threads) {\n+    // Upper bound is required for `worker_bytes_`.\n+    if (HWY_UNLIKELY(num_threads > pool::kMaxThreads)) {\n+      HWY_WARN(\"ThreadPool: clamping num_threads %zu to %zu.\", num_threads,\n+               pool::kMaxThreads);\n+      num_threads = pool::kMaxThreads;\n+    }\n+    return num_threads;\n+  }\n+\n+ public:\n+  // This typically includes hyperthreads, hence it is a loose upper bound.\n+  // -1 because these are in addition to the main thread.\n+  static size_t MaxThreads() {\n+    LogicalProcessorSet lps;\n+    // This is OS dependent, but more accurate if available because it takes\n+    // into account restrictions set by cgroups or numactl/taskset.\n+    if (GetThreadAffinity(lps)) {\n+      return lps.Count() - 1;\n+    }\n+    return static_cast<size_t>(std::thread::hardware_concurrency() - 1);\n+  }\n+\n   // `num_threads` is the number of *additional* threads to spawn, which should\n   // not exceed `MaxThreads()`. Note that the main thread also performs work.\n   explicit ThreadPool(size_t num_threads)\n-      : have_timer_stop_(platform::HaveTimerStop(cpu100_)),\n-        num_threads_(ClampedNumThreads(num_threads)),\n+      : num_threads_(ClampedNumThreads(num_threads)),\n         div_workers_(1 + num_threads_),\n         workers_(pool::WorkerLifecycle::Init(worker_bytes_, num_threads_,\n-                                             div_workers_)) {\n+                                             div_workers_)),\n+        have_timer_stop_(platform::HaveTimerStop(cpu100_)) {\n     // Leaves the default wait mode as `kBlock`, which means futex, because\n     // spinning only makes sense when threads are pinned and wake latency is\n     // important, so it must explicitly be requested by calling `SetWaitMode`.\n@@ -759,26 +766,28 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n       AutoTuner().SetCandidates(\n           pool::Config::AllCandidates(mode));\n     }\n-    config_ = AutoTuner().Candidates()[0];\n \n     threads_.reserve(num_threads_);\n     for (size_t thread = 0; thread < num_threads_; ++thread) {\n-      threads_.emplace_back(ThreadFunc(workers_[1 + thread], tasks_, config_));\n+      threads_.emplace_back(ThreadFunc(workers_[1 + thread], tasks_));\n     }\n \n-    // No barrier is required here because wakeup works regardless of the\n-    // relative order of wake and wait.\n+    // Threads' `Config` defaults to spinning. Change to `kBlock` (see above).\n+    // This also ensures all threads have started before we return, so that\n+    // startup latency is billed to the ctor, not the first `Run`.\n+    SendConfig(AutoTuner().Candidates()[0]);\n   }\n \n   // If we created threads, waits for them all to exit.\n   ~ThreadPool() {\n     // There is no portable way to request threads to exit like `ExitThread` on\n     // Windows, otherwise we could call that from `Run`. Instead, we must cause\n     // the thread to wake up and exit. We can just use `Run`.\n-    (void)RunWithoutAutotune(0, NumWorkers(),\n-                             [this](uint64_t /*task*/, size_t worker) {\n-                               workers_[worker].SetExit(1);\n-                             });\n+    (void)RunWithoutAutotune(\n+        0, NumWorkers(), [this](HWY_MAYBE_UNUSED uint64_t task, size_t worker) {\n+          HWY_DASSERT(task == worker);\n+          workers_[worker].SetExit(1);\n+        });\n \n     for (std::thread& thread : threads_) {\n       HWY_DASSERT(thread.joinable());\n@@ -807,8 +816,8 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n                                   : AutoTuner().NextConfig());\n   }\n \n-  // For printing which are in use.\n-  pool::Config config() const { return config_; }\n+  // For printing which is in use.\n+  pool::Config config() const { return workers_[0].NextConfig(); }\n \n   bool AutoTuneComplete() const { return AutoTuner().Best(); }\n   Span<CostDistribution> AutoTuneCosts() { return AutoTuner().Costs(); }\n@@ -863,24 +872,13 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n     } else {\n       HWY_IF_CONSTEXPR(pool::kVerbosity >= 2) {\n         fprintf(stderr, \"Pool %3zu: %s %9lu\\n\", NumWorkers(),\n-                config_.ToString().c_str(), t1 - t0);\n+                config().ToString().c_str(), t1 - t0);\n       }\n       SendConfig(auto_tuner.NextConfig());\n     }\n   }\n \n  private:\n-  // Used to initialize ThreadPool::num_threads_ from its ctor argument.\n-  static size_t ClampedNumThreads(size_t num_threads) {\n-    // Upper bound is required for `worker_bytes_`.\n-    if (HWY_UNLIKELY(num_threads > pool::kMaxThreads)) {\n-      HWY_WARN(\"ThreadPool: clamping num_threads %zu to %zu.\", num_threads,\n-               pool::kMaxThreads);\n-      num_threads = pool::kMaxThreads;\n-    }\n-    return num_threads;\n-  }\n-\n   // Debug-only re-entrancy detection.\n   void SetBusy() { HWY_DASSERT(!busy_.test_and_set()); }\n   void ClearBusy() { HWY_IF_CONSTEXPR(HWY_IS_DEBUG_BUILD) busy_.clear(); }\n@@ -895,7 +893,7 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n       pool::Worker* workers = main.AllWorkers();\n       HWY_DASSERT(&main == main.AllWorkers());  // main is first.\n       const size_t num_threads = main.NumThreads();\n-      const uint32_t epoch = main.WorkerEpoch();\n+      const uint32_t epoch = main.AdvanceWorkerEpoch();\n \n       HWY_IF_CONSTEXPR(HWY_IS_DEBUG_BUILD) {\n         for (size_t i = 0; i < 1 + num_threads; ++i) {\n@@ -904,13 +902,11 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n       }\n \n       wait.WakeWorkers(workers, epoch);\n-      // Threads might still be starting up and wake up late, but we wait for\n-      // them at the barrier below.\n \n       // Also perform work on the main thread before the barrier.\n       tasks.WorkerRun(&main);\n \n-      // Spin-waits until all *threads* (not the main thread, because it already\n+      // Spin-waits until all worker *threads* (not `main`, because it already\n       // knows it is here) called `WorkerReached`.\n       barrier.UntilReached(num_threads, workers, spin, epoch);\n       HWY_IF_CONSTEXPR(HWY_IS_DEBUG_BUILD) {\n@@ -919,7 +915,7 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n         }\n       }\n \n-      // Threads may already be waiting `UntilWoken`, which serves as the\n+      // Threads are or will soon be waiting `UntilWoken`, which serves as the\n       // 'release' phase of the barrier.\n     }\n   };\n@@ -951,11 +947,9 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n       pool::Tasks::DivideRangeAmongWorkers(begin, end, div_workers_, workers_);\n     }\n \n-    pool::Worker& main = workers_[0];\n-    const HWY_MAYBE_UNUSED uint32_t epoch = main.AdvanceWorkerEpoch();\n+    // Runs `MainWakeAndBarrier` with the first worker slot.\n+    CallWithConfig(config(), MainWakeAndBarrier(), workers_[0], tasks_);\n \n-    // Assign main thread the first worker slot (it used to be the last).\n-    CallWithConfig(config_, MainWakeAndBarrier(), main, tasks_);\n     if (is_root) {\n       PROFILER_END_ROOT_RUN();\n     }\n@@ -966,8 +960,8 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n   // Sends `next_config` to workers:\n   // - Main wakes threads using the current config.\n   // - Threads copy `next_config` into their `Worker` during `WorkerRun`.\n-  // - Threads notify the (unchanged) barrier and already wait for the next\n-  //   wake using the new config.\n+  // - Threads notify the (same) barrier and already wait for the next wake\n+  //   using `next_config`.\n   HWY_NOINLINE void SendConfig(pool::Config next_config) {\n     (void)RunWithoutAutotune(\n         0, NumWorkers(),\n@@ -978,7 +972,7 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n \n     // All have woken and are, or will be, waiting per `next_config`. Now we\n     // can entirely switch the main thread's config for the next wake.\n-    config_ = next_config;\n+    workers_[0].SetNextConfig(next_config);\n   }\n \n   using AutoTuneT = AutoTune<pool::Config, 30>;\n@@ -990,15 +984,17 @@ class alignas(HWY_ALIGNMENT) ThreadPool {\n     return auto_tune_[static_cast<size_t>(wait_mode_) - 1];\n   }\n \n-  char cpu100_[100];\n-  const bool have_timer_stop_;\n   const size_t num_threads_;  // not including main thread\n   const Divisor64 div_workers_;\n   pool::Worker* const workers_;  // points into `worker_bytes_`\n+  const bool have_timer_stop_;\n+  char cpu100_[100];  // write-only for `HaveTimerStop` in ctor.\n \n-  // The only mutable state:\n-  pool::Tasks tasks_;    // written by `Run` and read by workers.\n-  pool::Config config_;  // for use by the next `Run`. Updated via `SendConfig`.\n+  // This is written by the main thread and read by workers, via reference\n+  // passed to `ThreadFunc`. Padding ensures that the workers' cache lines are\n+  // not unnecessarily invalidated when the main thread writes other members.\n+  alignas(HWY_ALIGNMENT) pool::Tasks tasks_;\n+  HWY_MAYBE_UNUSED char padding_[HWY_ALIGNMENT - sizeof(pool::Tasks)];\n \n   // In debug builds, detects if functions are re-entered.\n   std::atomic_flag busy_ = ATOMIC_FLAG_INIT;"
      }
    ],
    "lines_added": 98,
    "lines_removed": 102
  },
  "issues": [],
  "pull_requests": [],
  "build_info": {
    "old_build_script": [
      "apt-get update",
      "cmake -S /test_workspace/workspace/old -B /test_workspace/workspace/old/build -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=ON -DBUILD_TESTING=ON -DHWY_ENABLE_TESTS=ON",
      "cmake --build /test_workspace/workspace/old/build -- -j 1"
    ],
    "new_build_script": [
      "apt-get update",
      "cmake -S /test_workspace/workspace/new -B /test_workspace/workspace/new/build -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=ON -DBUILD_TESTING=ON -DHWY_ENABLE_TESTS=ON",
      "cmake --build /test_workspace/workspace/new/build -- -j 1"
    ],
    "old_test_script": [
      "cd /test_workspace/workspace/old/build",
      "ctest --output-on-failure"
    ],
    "new_test_script": [
      "cd /test_workspace/workspace/new/build",
      "ctest --output-on-failure"
    ],
    "build_system": "cmake"
  },
  "performance_analysis": {
    "is_significant": false,
    "p_value": 0.9999999999999969,
    "is_pair_significant": false,
    "pair_p_value": 0.9999999999999998,
    "is_binom_significant": false,
    "binom_p_value": 1.0,
    "is_wilcoxon_significant": false,
    "wilcoxon_p_value": 0.9999991333466779,
    "is_mannwhitney_significant": false,
    "mannwhitney_p_value": 0.6162942603765319,
    "relative_improvement": -0.0013369473645654338,
    "absolute_improvement_ms": -48.6666666666693,
    "old_mean_ms": 36401.333333333336,
    "new_mean_ms": 36450.0,
    "old_std_ms": 690.8502174773533,
    "new_std_ms": 724.6164264748904,
    "effect_size_cohens_d": -0.06874457328028316,
    "old_ci95_ms": [
      36143.365622546626,
      36659.30104412004
    ],
    "new_ci95_ms": [
      36179.42377955856,
      36720.57622044145
    ],
    "old_ci99_ms": [
      36053.666476288796,
      36749.00019037787
    ],
    "new_ci99_ms": [
      36085.34047007284,
      36814.659529927165
    ],
    "new_times_s": [
      35.08,
      35.86,
      35.56,
      36.0,
      36.24,
      35.53,
      35.86,
      36.16,
      35.92,
      36.12,
      36.71,
      36.91,
      35.81,
      35.59,
      36.45,
      36.05,
      35.92,
      35.92,
      36.45,
      36.61,
      36.77,
      35.84,
      35.92,
      38.3,
      36.92,
      37.26,
      37.35,
      37.99,
      37.3,
      37.42,
      36.76
    ],
    "old_times_s": [
      35.28,
      35.81,
      35.91,
      35.97,
      35.38,
      35.81,
      35.85,
      36.06,
      35.71,
      36.14,
      36.16,
      35.93,
      37.24,
      35.83,
      36.4,
      37.05,
      36.63,
      35.57,
      35.85,
      36.22,
      36.17,
      36.5,
      35.66,
      36.53,
      37.67,
      37.03,
      37.31,
      37.61,
      37.78,
      37.2,
      37.06
    ]
  },
  "tests": {
    "total_tests": 9,
    "significant_improvements": 0,
    "significant_improvements_tests": [],
    "significant_regressions": 0,
    "significant_regressions_tests": [],
    "significant_pair_improvements": 0,
    "significant_pair_improvements_tests": [],
    "significant_pair_regressions": 0,
    "significant_pair_regressions_tests": [],
    "significant_binom_improvements": 0,
    "significant_binom_improvements_tests": [],
    "significant_binom_regressions": 0,
    "significant_binom_regressions_tests": [],
    "significant_wilcoxon_improvements": 0,
    "significant_wilcoxon_improvements_tests": [],
    "significant_wilcoxon_regressions": 0,
    "significant_wilcoxon_regressions_tests": [],
    "significant_mannwhitney_improvements": 0,
    "significant_mannwhitney_improvements_tests": [],
    "significant_mannwhitney_regressions": 0,
    "significant_mannwhitney_regressions_tests": [],
    "tests": [
      {
        "test_name": "AbortDeathTest.AbortDefault",
        "is_significant": false,
        "p_value": 0.9882205006869862,
        "is_pair_significant": false,
        "pair_p_value": 0.9882205006869862,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999999048408935,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.8498322721616629,
        "relative_improvement": -0.035714285714285546,
        "absolute_improvement_ms": -0.357142857142858,
        "old_mean_ms": 10.0,
        "new_mean_ms": 10.357142857142858,
        "old_std_ms": 0.0,
        "new_std_ms": 1.8898223650461365,
        "effect_size_cohens_d": -0.26726124191242495,
        "old_ci95_ms": [
          10.0,
          10.0
        ],
        "new_ci95_ms": [
          9.624346244114186,
          11.08993947017153
        ],
        "old_ci99_ms": [
          10.0,
          10.0
        ],
        "new_ci99_ms": [
          9.367613229599403,
          11.346672484686314
        ],
        "new_times": [
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.02,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01
        ],
        "old_times": [
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01
        ]
      },
      {
        "test_name": "NanobenchmarkTest.RunTest",
        "is_significant": false,
        "p_value": 0.9119547255126291,
        "is_pair_significant": false,
        "pair_p_value": 0.9104369380596341,
        "is_binom_significant": false,
        "binom_p_value": 0.9389609396457672,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.94454929818726,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.7003736435423464,
        "relative_improvement": -0.009632224168126044,
        "absolute_improvement_ms": -3.928571428571337,
        "old_mean_ms": 407.8571428571429,
        "new_mean_ms": 411.7857142857142,
        "old_std_ms": 70.04533679231764,
        "new_std_ms": 66.2237269457255,
        "effect_size_cohens_d": -0.05763637501996557,
        "old_ci95_ms": [
          380.69639668901823,
          435.0178890252675
        ],
        "new_ci95_ms": [
          386.10683371707484,
          437.46459485435355
        ],
        "old_ci99_ms": [
          371.1807137338343,
          444.5335719804514
        ],
        "new_ci99_ms": [
          377.1103177663469,
          446.4611108050815
        ],
        "new_times": [
          0.42,
          0.55,
          0.42,
          0.32,
          0.32,
          0.41,
          0.48,
          0.5,
          0.31,
          0.35,
          0.39,
          0.46,
          0.45,
          0.44,
          0.38,
          0.34,
          0.43,
          0.54,
          0.42,
          0.43,
          0.5,
          0.38,
          0.46,
          0.35,
          0.36,
          0.43,
          0.36,
          0.33
        ],
        "old_times": [
          0.37,
          0.42,
          0.41,
          0.42,
          0.4,
          0.37,
          0.42,
          0.37,
          0.36,
          0.34,
          0.38,
          0.36,
          0.36,
          0.63,
          0.42,
          0.4,
          0.48,
          0.4,
          0.49,
          0.43,
          0.47,
          0.4,
          0.35,
          0.32,
          0.44,
          0.31,
          0.34,
          0.56
        ]
      },
      {
        "test_name": "AutoTuneTest.TestCostDistribution",
        "is_significant": false,
        "p_value": 0.9999997051169552,
        "is_pair_significant": false,
        "pair_p_value": 0.9999998195484014,
        "is_binom_significant": false,
        "binom_p_value": 0.9999998919665813,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999996040051407,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.6786522311668598,
        "relative_improvement": -0.0029498525073746997,
        "absolute_improvement_ms": -0.35714285714284755,
        "old_mean_ms": 121.0714285714286,
        "new_mean_ms": 121.42857142857144,
        "old_std_ms": 4.1626965212518625,
        "new_std_ms": 4.483951394230333,
        "effect_size_cohens_d": -0.0825514386930195,
        "old_ci95_ms": [
          119.45730336672177,
          122.68555377613541
        ],
        "new_ci95_ms": [
          119.6898765885424,
          123.16726626860047
        ],
        "old_ci99_ms": [
          118.89179962087893,
          123.25105752197827
        ],
        "new_ci99_ms": [
          119.08073025835259,
          123.7764125987903
        ],
        "new_times": [
          0.13,
          0.12,
          0.12,
          0.12,
          0.12,
          0.14,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.13,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12
        ],
        "old_times": [
          0.14,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.13,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12,
          0.12
        ]
      },
      {
        "test_name": "SpinTest.TestPingPong",
        "is_significant": false,
        "p_value": 0.9999388964089684,
        "is_pair_significant": false,
        "pair_p_value": 0.9999999962696131,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999997306132129,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.8271360368552603,
        "relative_improvement": -0.01731601731601733,
        "absolute_improvement_ms": -1.428571428571432,
        "old_mean_ms": 82.49999999999999,
        "new_mean_ms": 83.92857142857142,
        "old_std_ms": 4.4095855184409825,
        "new_std_ms": 5.669467095138407,
        "effect_size_cohens_d": -0.281284338563098,
        "old_ci95_ms": [
          80.79014123626642,
          84.20985876373356
        ],
        "new_ci95_ms": [
          81.7301815894854,
          86.12696126765744
        ],
        "old_ci99_ms": [
          80.19109753573193,
          84.80890246426804
        ],
        "new_ci99_ms": [
          80.95998254594106,
          86.89716031120179
        ],
        "new_times": [
          0.08,
          0.08,
          0.08,
          0.09,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.09,
          0.09,
          0.09,
          0.09,
          0.09,
          0.1,
          0.09,
          0.09,
          0.09
        ],
        "old_times": [
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.08,
          0.09,
          0.09,
          0.09,
          0.09,
          0.09,
          0.09,
          0.09
        ]
      },
      {
        "test_name": "ThreadPoolTest.TestPool",
        "is_significant": false,
        "p_value": 0.7376997495802053,
        "is_pair_significant": false,
        "pair_p_value": 0.8927163569857172,
        "is_binom_significant": false,
        "binom_p_value": 0.9999998919665813,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9998780048576359,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.6590683582230072,
        "relative_improvement": -0.31009615384615385,
        "absolute_improvement_ms": -46.07142857142857,
        "old_mean_ms": 148.57142857142858,
        "new_mean_ms": 194.64285714285714,
        "old_std_ms": 271.998288198784,
        "new_std_ms": 358.29309482453306,
        "effect_size_cohens_d": -0.14483967755500596,
        "old_ci95_ms": [
          43.10150291690829,
          254.04135422594888
        ],
        "new_ci95_ms": [
          55.71129869843738,
          333.5744155872769
        ],
        "old_ci99_ms": [
          6.1504424555036135,
          290.9924146873535
        ],
        "new_ci99_ms": [
          7.037059248483746,
          382.24865503723055
        ],
        "new_times": [
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.68,
          0.31,
          0.5,
          0.65,
          1.32,
          0.85,
          0.91,
          0.03
        ],
        "old_times": [
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.89,
          0.27,
          0.52,
          0.66,
          0.77,
          0.64,
          0.2
        ]
      },
      {
        "test_name": "ThreadPoolTest.TestWaitMode",
        "is_significant": false,
        "p_value": 0.7879248000227934,
        "is_pair_significant": false,
        "pair_p_value": 0.9714411208737005,
        "is_binom_significant": false,
        "binom_p_value": 0.9999862797558308,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.998682059894328,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.7497394770061474,
        "relative_improvement": -0.01822675316651231,
        "absolute_improvement_ms": -21.07142857142863,
        "old_mean_ms": 1156.0714285714287,
        "new_mean_ms": 1177.1428571428573,
        "old_std_ms": 378.44065326326665,
        "new_std_ms": 373.2525422786298,
        "effect_size_cohens_d": -0.05606257135953336,
        "old_ci95_ms": [
          1009.3274625389863,
          1302.815394603871
        ],
        "new_ci95_ms": [
          1032.410630535176,
          1321.8750837505384
        ],
        "old_ci99_ms": [
          957.916170385689,
          1354.2266867571682
        ],
        "new_ci99_ms": [
          981.7041450332123,
          1372.5815692525023
        ],
        "new_times": [
          0.94,
          0.93,
          0.95,
          0.91,
          0.9,
          0.93,
          0.96,
          0.97,
          0.93,
          1.0,
          0.94,
          0.99,
          0.94,
          0.92,
          1.0,
          0.95,
          0.94,
          1.05,
          0.92,
          0.92,
          1.98,
          1.75,
          1.84,
          1.79,
          1.7,
          1.63,
          1.59,
          1.69
        ],
        "old_times": [
          0.93,
          0.94,
          0.9,
          0.9,
          0.92,
          0.92,
          1.0,
          0.92,
          0.97,
          1.02,
          0.9,
          0.96,
          0.98,
          0.92,
          0.9,
          0.89,
          0.93,
          1.07,
          0.99,
          0.92,
          0.99,
          1.9,
          1.7,
          1.81,
          1.92,
          1.94,
          1.6,
          1.63
        ]
      },
      {
        "test_name": "ThreadPoolTest.TestCounter",
        "is_significant": false,
        "p_value": 0.7568312316435137,
        "is_pair_significant": false,
        "pair_p_value": 0.8684263148967662,
        "is_binom_significant": false,
        "binom_p_value": 0.9075333289802074,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.906856362595756,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 0.6808507970377156,
        "relative_improvement": -0.016949152542372895,
        "absolute_improvement_ms": -2.1428571428571686,
        "old_mean_ms": 126.42857142857142,
        "new_mean_ms": 128.57142857142858,
        "old_std_ms": 47.54836023299395,
        "new_std_ms": 45.192123675791585,
        "effect_size_cohens_d": -0.04619699565041504,
        "old_ci95_ms": [
          107.99124209103097,
          144.86590076611185
        ],
        "new_ci95_ms": [
          111.04775239015719,
          146.0951047527
        ],
        "old_ci99_ms": [
          101.53178109425451,
          151.32536176288832
        ],
        "new_ci99_ms": [
          104.9083869353899,
          152.23447020746727
        ],
        "new_times": [
          0.12,
          0.1,
          0.13,
          0.1,
          0.11,
          0.11,
          0.11,
          0.08,
          0.09,
          0.12,
          0.11,
          0.08,
          0.1,
          0.09,
          0.09,
          0.11,
          0.08,
          0.13,
          0.12,
          0.09,
          0.21,
          0.22,
          0.21,
          0.17,
          0.21,
          0.14,
          0.16,
          0.21
        ],
        "old_times": [
          0.1,
          0.08,
          0.09,
          0.1,
          0.08,
          0.12,
          0.1,
          0.12,
          0.09,
          0.12,
          0.08,
          0.09,
          0.1,
          0.11,
          0.1,
          0.1,
          0.14,
          0.11,
          0.16,
          0.08,
          0.09,
          0.25,
          0.18,
          0.21,
          0.17,
          0.22,
          0.19,
          0.16
        ]
      },
      {
        "test_name": "TopologyTest.TestTopology",
        "is_significant": false,
        "p_value": 1.0,
        "is_pair_significant": false,
        "pair_p_value": 1.0,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999999393422746,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 1.0,
        "relative_improvement": 0.0,
        "absolute_improvement_ms": 0.0,
        "old_mean_ms": 10.0,
        "new_mean_ms": 10.0,
        "old_std_ms": 0.0,
        "new_std_ms": 0.0,
        "effect_size_cohens_d": "NaN",
        "old_ci95_ms": [
          10.0,
          10.0
        ],
        "new_ci95_ms": [
          10.0,
          10.0
        ],
        "old_ci99_ms": [
          10.0,
          10.0
        ],
        "new_ci99_ms": [
          10.0,
          10.0
        ],
        "new_times": [
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01
        ],
        "old_times": [
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01
        ]
      },
      {
        "test_name": "TopologyTest.TestCaches",
        "is_significant": false,
        "p_value": 1.0,
        "is_pair_significant": false,
        "pair_p_value": 1.0,
        "is_binom_significant": false,
        "binom_p_value": 1.0,
        "is_wilcoxon_significant": false,
        "wilcoxon_p_value": 0.9999999393422746,
        "is_mannwhitney_significant": false,
        "mannwhitney_p_value": 1.0,
        "relative_improvement": 0.0,
        "absolute_improvement_ms": 0.0,
        "old_mean_ms": 10.0,
        "new_mean_ms": 10.0,
        "old_std_ms": 0.0,
        "new_std_ms": 0.0,
        "effect_size_cohens_d": "NaN",
        "old_ci95_ms": [
          10.0,
          10.0
        ],
        "new_ci95_ms": [
          10.0,
          10.0
        ],
        "old_ci99_ms": [
          10.0,
          10.0
        ],
        "new_ci99_ms": [
          10.0,
          10.0
        ],
        "new_times": [
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01
        ],
        "old_times": [
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01
        ]
      }
    ]
  },
  "logs": {
    "full_log_path": "/logs/full.log",
    "config_log_path": "/logs/config.log",
    "build_log_path": "/logs/build.log",
    "test_log_path": "/logs/test.log",
    "build_success": true,
    "test_success": true
  },
  "raw_timing_data": {
    "warmup_runs": 1,
    "measurement_runs": 30,
    "min_exec_time_improvement": 0.05,
    "min_p_value": 0.05
  }
}